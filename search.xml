<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>GroundingDINO笔记</title>
    <url>/post/b198a1c8.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>把自己对于 groundingdino 的理解记录下来。</p>

</blockquote>
<span id="more"></span>

<h1 id="什么是开放集目标检测"><a href="#什么是开放集目标检测" class="headerlink" title="什么是开放集目标检测"></a>什么是开放集目标检测</h1><p><img data-src="./../images/GroundingDINO%E7%AC%94%E8%AE%B0/image-20240328145159760.png" alt="image-20240328145159760"></p>
<p>首先，相比closed set目标检测，open set目标检测在步骤上看起来少了很多，一般最费人工和时间的数据阶段直接省略了；</p>
<p>其次，视觉大模型希望不需要再重新训练和微调模型，一个模型就可以检测万物，<font face="黑体" color="red" size="5">这里注意万物包含2层意思：任意图像、任意目标，不管是真实世界图像，还是虚拟图像、动漫、素描、抽象画等，其中任何图像内容内的任何实体。</font></p>
<h1 id="视觉大模型实现思路"><a href="#视觉大模型实现思路" class="headerlink" title="视觉大模型实现思路"></a>视觉大模型实现思路</h1><p>作者总结了2中实现开放集目标检测的思路</p>
<p><img data-src="./../images/GroundingDINO%E7%AC%94%E8%AE%B0/image-20240328151428590.png" alt="image-20240328151428590"></p>
<h2 id="基于CLIP"><a href="#基于CLIP" class="headerlink" title="基于CLIP"></a>基于CLIP</h2><h3 id="回顾CLIP"><a href="#回顾CLIP" class="headerlink" title="回顾CLIP"></a>回顾CLIP</h3><p><img data-src="./../images/GroundingDINO%E7%AC%94%E8%AE%B0/image-20240328152004677.png" alt="image-20240328152004677"></p>
<p>CLIP中心思想：</p>
<p><img data-src="./../images/GroundingDINO%E7%AC%94%E8%AE%B0/image-20240328151619346.png" alt="image-20240328151619346"></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>目标检测 视觉大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorRT成功测试自己的数据集SSD模型一</title>
    <url>/post/c02a3ba5.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>经过好几个月的摸索，终于成功调用起TensorRT测试自己的数据集训练得到的SSD模型。期间遇到的坑也是一个接一个，不断的调整环境，一遍又一遍的训练，现在总算是有了结果，开心。并且介于自己在实践期间在网上并没有找到很新很全的资料，现在就想把这些日子总结的经(xue)验(lei)写出来，从一开始的环境配置再到训练模型，再到tensorrt测试模型，以及一些error的解决办法，都做一个全面的整理，希望能帮助到有同样需求的同学。</p>

</blockquote>

<span id="more"></span>

<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/c02a3ba5.html"><font color="red">TensorRT成功测试自己的数据集SSD模型一</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/fbaa150c.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型二</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/b9f68301.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型三</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/f524ef1f.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型四</font></a> </p>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>首先，给出我自己的软件环境及各个版本号。</p>
<table>
<thead>
<tr>
<th>Ubuntu</th>
<th>20.04</th>
</tr>
</thead>
<tbody><tr>
<td>CUDA</td>
<td>10.0.130</td>
</tr>
<tr>
<td>CUDNN</td>
<td>7.6.5</td>
</tr>
<tr>
<td>TensorFlow</td>
<td>1.14.0</td>
</tr>
<tr>
<td>Keras</td>
<td>2.2.5</td>
</tr>
<tr>
<td>TensorRT</td>
<td>7.0.0</td>
</tr>
<tr>
<td>Python</td>
<td>3.7.0</td>
</tr>
</tbody></table>
<div class="note danger"><p>根据经验，推荐先确定tensorrt安装版本，再回溯到cuda、cudnn、以及python版本进行安装，如果你现在已经装好了cuda以及cudnn等，这里有两个办法解决，一个就是另外装一套cuda等覆盖掉之前的版本，另一个办法就是利用虚拟环境设置一个专门针对tensorrt的环境，我自己也是先前就已经有了一套环境，后来为了配合TensorRT，就将原先的cuda以及cudnn等删除，然后再装了一套环境。</p></div>

<p>另外，这里关于TensorFlow版本需要说明一点，选择1.14是因为根据Tensorrt的样例有说，在tf1.14上通过验证的，所以最后适配了这个版本。</p>
<p>对于cuda cudnn的安装就按照一般方法装就好了。然后装好anaconda。现在从tensorrt的安装说起。</p>
<h3 id="下载安装包并解压"><a href="#下载安装包并解压" class="headerlink" title="下载安装包并解压"></a>下载安装包并解压</h3><p>进入<a href="https://developer.nvidia.com/tensorrt%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E7%89%88%E6%9C%AC%E8%BF%9B%E8%A1%8C%E4%B8%8B%E8%BD%BD">https://developer.nvidia.com/tensorrt选择合适的版本进行下载</a></p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B/v2-148078235d66d2480f6c503d8ea398a8_r.jpg" alt="preview"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xzvf /Downloads/TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.2.cudnn7.6.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="安装python的tensorRT包"><a href="#安装python的tensorRT包" class="headerlink" title="安装python的tensorRT包"></a>安装python的tensorRT包</h3><p>进入tensorRT目录下的Python目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /TensorRT-7.0.0.11/python</span><br><span class="line"><span class="comment"># 对于python3</span></span><br><span class="line">$ sudo pip3 install tensorrt-7.0.0.11-cp37-none-linux_x86_64.whl</span><br></pre></td></tr></table></figure>

<p>这里注意可能会遇到两个问题：</p>
<h4 id="sudo-pip3-command-not-found"><a href="#sudo-pip3-command-not-found" class="headerlink" title="sudo: pip3 :command not found"></a><font color="red">sudo: pip3 :command not found</font></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install python3-pip</span><br></pre></td></tr></table></figure>

<h4 id="ERROR-tensorrt-7-0-0-11-cp37-none-linux-x86-64-whl-is-not-a-supported-wheel-on-this-platform"><a href="#ERROR-tensorrt-7-0-0-11-cp37-none-linux-x86-64-whl-is-not-a-supported-wheel-on-this-platform" class="headerlink" title="ERROR: tensorrt-7.0.0.11-cp37-none-linux_x86_64.whl is not a supported wheel on this platform"></a><font color="red">ERROR: tensorrt-7.0.0.11-cp37-none-linux_x86_64.whl is not a supported wheel on this platform</font></h4><p>原因是cp37即python=3.7.0,如果你的anaconda下的python版本不是3.7.0就会报错。所以这里我使用创建虚拟环境解决</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create --name python370 python=3.7.0</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B/v2-87374487a31bae782989d1c0bcaeaca4_r.jpg" alt="preview"></p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B/v2-86d66326888b51bbb37372e7fec9f5c0_r.jpg" alt="preview"></p>
<p>虚拟环境创建成功后进行激活再安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda activate python370</span><br><span class="line"><span class="built_in">cd</span> /TensorRT-7.0.0.11/python</span><br><span class="line">python -m pip install tensorrt-7.0.0.11-cp37-none-linux_x86_64.whl </span><br></pre></td></tr></table></figure>

<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B/v2-39b61e60e7a07ae33c66b0b70609f4f3_r.jpg" alt="preview"></p>
<p>进入python输入tensorRT即可验证tensorRT是否安装成功</p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B/v2-f3c225f88d9c5b2d0d733e9ea3b9670c_r.jpg" alt="preview"></p>
<p>不报错即成功</p>
<p>接着进入uff与graphsurgeon文件夹安装whl</p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B/v2-de798d43241203c3948b2ddbf3ca2a6d_r.jpg" alt="preview"></p>
<p>至此，TensorRT安装成功！</p>
]]></content>
      <categories>
        <category>TensorRT实战记</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>Next 8.0 进阶美化篇一</title>
    <url>/post/74c4f787.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本篇教程主要讲解在markdown下对文本的部分美化效果，包括块状标签，文字色块，居中，自定义数字块等, 对初学者友好易上手。</p>

</blockquote>

<span id="more"></span>

<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/74c4f787.html"><font color="red">Next 8.0 进阶美化篇一</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/4f44d92e.html"><font color="blue">Next 8.0 进阶美化篇二</font></a> </p>
<h3 id="笔记标签"><a href="#笔记标签" class="headerlink" title="笔记标签"></a>笔记标签</h3><p>效果：</p>
<div class="note default"><p>这里输入文字</p></div>

<!--more-->

<h4 id="先修改主题配置文件-blog-themes-next-config-yml"><a href="#先修改主题配置文件-blog-themes-next-config-yml" class="headerlink" title="先修改主题配置文件/blog/themes/next/_config.yml"></a>先修改主题配置文件/blog/themes/next/_config.yml</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Note tag (bs-callout)</span></span><br><span class="line"><span class="attr">note:</span></span><br><span class="line">  <span class="comment"># 风格</span></span><br><span class="line">  <span class="attr">style:</span> <span class="string">flat</span></span><br><span class="line">  <span class="comment"># 要不要图标</span></span><br><span class="line">  <span class="attr">icons:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">light_bg_offset:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><p>default效果：</p>
<div class="note default"><p>这里输入文字</p></div>
用法：在你要编辑的markdown文件里键入以下内容
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;note default&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
或者：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;note default&quot;&gt;&lt;p&gt;这里输入文字&lt;/p&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>primary效果：</p>
<div class="note primary"><p>这里输入文字</p></div>
用法：在你要编辑的markdown文件里键入以下内容
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;note primary&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
或者：
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% note primary %&#125; 这里输入文字 &#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>

<p>success效果：</p>
<div class="note success"><p>这里输入文字</p></div>
用法：在你要编辑的markdown文件里键入以下内容
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;note success&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
或者：
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% note success %&#125; 这里输入文字 &#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>

<p>info效果：</p>
<div class="note info"><p>这里输入文字</p></div>
用法：在你要编辑的markdown文件里键入以下内容
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;note info&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
或者：
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% note info %&#125; 这里输入文字 &#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>

<p>warning效果：</p>
<div class="note warning"><p>这里输入文字</p></div>
用法：在你要编辑的markdown文件里键入以下内容
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;note warning&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
或者：
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% note warning %&#125; 这里输入文字 &#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>

<p>danger效果：</p>
<div class="note danger"><p>这里输入文字</p></div>
用法：在你要编辑的markdown文件里键入以下内容
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;note danger&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
或者：
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% note danger %&#125; 这里输入文字 &#123;% endnote %&#125;</span><br></pre></td></tr></table></figure>

<h3 id="文字背景色块"><a href="#文字背景色块" class="headerlink" title="文字背景色块"></a>文字背景色块</h3><p>效果：<span id="inline-red"> 红色背景色块 </span></p>
<h4 id="更改主题配置文件-Bolg-themes-next-config-yml"><a href="#更改主题配置文件-Bolg-themes-next-config-yml" class="headerlink" title="更改主题配置文件/Bolg/themes/next/_config.yml"></a>更改主题配置文件/Bolg/themes/next/_config.yml</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">custom_file_path:</span><br><span class="line">  #head: source/_data/head.njk</span><br><span class="line">  #header: source/_data/header.njk</span><br><span class="line">  #sidebar: source/_data/sidebar.njk</span><br><span class="line">  #postMeta: source/_data/post-meta.njk</span><br><span class="line">  #postBodyEnd: source/_data/post-body-end.njk</span><br><span class="line">  #footer: source/_data/footer.njk</span><br><span class="line">  #bodyEnd: source/_data/body-end.njk</span><br><span class="line">  #variable: source/_data/variables.styl</span><br><span class="line">  #mixin: source/_data/mixins.styl</span><br><span class="line">//开启自定义style</span><br><span class="line">  style: source/_data/styles.styl</span><br></pre></td></tr></table></figure>

<h4 id="然后在主目录下的source下新建-data子文件夹和styles-styl文件，键入以下内容"><a href="#然后在主目录下的source下新建-data子文件夹和styles-styl文件，键入以下内容" class="headerlink" title="然后在主目录下的source下新建_data子文件夹和styles.styl文件，键入以下内容"></a>然后在主目录下的source下新建_data子文件夹和styles.styl文件，键入以下内容</h4><p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%B8%80/Screenshot%20from%202020-09-11%2013-24-06.png"></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">下载样式</span></span><br><span class="line"><span class="string">a#download</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">inline-block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="number">0</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">color:</span> <span class="comment">#000;</span></span><br><span class="line"><span class="attr">background:</span> <span class="string">transparent;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">2px</span> <span class="string">solid</span> <span class="comment">#000;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">2px;</span></span><br><span class="line"><span class="attr">transition:</span> <span class="string">all</span> <span class="string">.5s</span> <span class="string">ease;</span></span><br><span class="line"><span class="attr">font-weight:</span> <span class="string">bold;</span></span><br><span class="line"><span class="string">&amp;:hover</span> &#123;</span><br><span class="line"><span class="attr">background:</span> <span class="comment">#000;</span></span><br><span class="line"><span class="attr">color:</span> <span class="comment">#fff;</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">颜色块-黄</span></span><br><span class="line"><span class="string">span#inline-yellow</span> &#123;</span><br><span class="line"><span class="string">display:inline;</span></span><br><span class="line"><span class="string">padding:.2em</span> <span class="string">.6em</span> <span class="string">.3em;</span></span><br><span class="line"><span class="string">font-size:80%;</span></span><br><span class="line"><span class="string">font-weight:bold;</span></span><br><span class="line"><span class="string">line-height:1;</span></span><br><span class="line"><span class="string">color:#fff;</span></span><br><span class="line"><span class="string">text-align:center;</span></span><br><span class="line"><span class="string">white-space:nowrap;</span></span><br><span class="line"><span class="string">vertical-align:baseline;</span></span><br><span class="line"><span class="string">border-radius:0;</span></span><br><span class="line"><span class="attr">background-color:</span> <span class="comment">#f0ad4e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">颜色块-绿</span></span><br><span class="line"><span class="string">span#inline-green</span> &#123;</span><br><span class="line"><span class="string">display:inline;</span></span><br><span class="line"><span class="string">padding:.2em</span> <span class="string">.6em</span> <span class="string">.3em;</span></span><br><span class="line"><span class="string">font-size:80%;</span></span><br><span class="line"><span class="string">font-weight:bold;</span></span><br><span class="line"><span class="string">line-height:1;</span></span><br><span class="line"><span class="string">color:#fff;</span></span><br><span class="line"><span class="string">text-align:center;</span></span><br><span class="line"><span class="string">white-space:nowrap;</span></span><br><span class="line"><span class="string">vertical-align:baseline;</span></span><br><span class="line"><span class="string">border-radius:0;</span></span><br><span class="line"><span class="attr">background-color:</span> <span class="comment">#5cb85c;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">颜色块-蓝</span></span><br><span class="line"><span class="string">span#inline-blue</span> &#123;</span><br><span class="line"><span class="string">display:inline;</span></span><br><span class="line"><span class="string">padding:.2em</span> <span class="string">.6em</span> <span class="string">.3em;</span></span><br><span class="line"><span class="string">font-size:80%;</span></span><br><span class="line"><span class="string">font-weight:bold;</span></span><br><span class="line"><span class="string">line-height:1;</span></span><br><span class="line"><span class="string">color:#fff;</span></span><br><span class="line"><span class="string">text-align:center;</span></span><br><span class="line"><span class="string">white-space:nowrap;</span></span><br><span class="line"><span class="string">vertical-align:baseline;</span></span><br><span class="line"><span class="string">border-radius:0;</span></span><br><span class="line"><span class="attr">background-color:</span> <span class="comment">#2780e3;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">颜色块-紫</span></span><br><span class="line"><span class="string">span#inline-purple</span> &#123;</span><br><span class="line"><span class="string">display:inline;</span></span><br><span class="line"><span class="string">padding:.2em</span> <span class="string">.6em</span> <span class="string">.3em;</span></span><br><span class="line"><span class="string">font-size:80%;</span></span><br><span class="line"><span class="string">font-weight:bold;</span></span><br><span class="line"><span class="string">line-height:1;</span></span><br><span class="line"><span class="string">color:#fff;</span></span><br><span class="line"><span class="string">text-align:center;</span></span><br><span class="line"><span class="string">white-space:nowrap;</span></span><br><span class="line"><span class="string">vertical-align:baseline;</span></span><br><span class="line"><span class="string">border-radius:0;</span></span><br><span class="line"><span class="attr">background-color:</span> <span class="comment">#9954bb;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">颜色块-红</span></span><br><span class="line"><span class="string">span#inline-red</span> &#123;</span><br><span class="line"><span class="string">display:inline;</span></span><br><span class="line"><span class="string">padding:.2em</span> <span class="string">.6em</span> <span class="string">.3em;</span></span><br><span class="line"><span class="string">font-size:80%;</span></span><br><span class="line"><span class="string">font-weight:bold;</span></span><br><span class="line"><span class="string">line-height:1;</span></span><br><span class="line"><span class="string">color:#fff;</span></span><br><span class="line"><span class="string">text-align:center;</span></span><br><span class="line"><span class="string">white-space:nowrap;</span></span><br><span class="line"><span class="string">vertical-align:baseline;</span></span><br><span class="line"><span class="string">border-radius:0;</span></span><br><span class="line"><span class="attr">background-color:</span> <span class="comment">#df3e3e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">左侧边框红色块级</span></span><br><span class="line"><span class="string">p#div-border-left-red</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-left-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-left-color:</span> <span class="comment">#df3e3e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">左侧边框黄色块级</span></span><br><span class="line"><span class="string">p#div-border-left-yellow</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-left-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-left-color:</span> <span class="comment">#f0ad4e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">左侧边框绿色块级</span></span><br><span class="line"><span class="string">p#div-border-left-green</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-left-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-left-color:</span> <span class="comment">#5cb85c;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">左侧边框蓝色块级</span></span><br><span class="line"><span class="string">p#div-border-left-blue</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-left-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-left-color:</span> <span class="comment">#2780e3;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">左侧边框紫色块级</span></span><br><span class="line"><span class="string">p#div-border-left-purple</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-left-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-left-color:</span> <span class="comment">#9954bb;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">右侧边框红色块级</span></span><br><span class="line"><span class="string">p#div-border-right-red</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-right-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-right-color:</span> <span class="comment">#df3e3e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">右侧边框黄色块级</span></span><br><span class="line"><span class="string">p#div-border-right-yellow</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-right-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-right-color:</span> <span class="comment">#f0ad4e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">右侧边框绿色块级</span></span><br><span class="line"><span class="string">p#div-border-right-green</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-right-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-right-color:</span> <span class="comment">#5cb85c;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">右侧边框蓝色块级</span></span><br><span class="line"><span class="string">p#div-border-right-blue</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-right-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-right-color:</span> <span class="comment">#2780e3;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">右侧边框紫色块级</span></span><br><span class="line"><span class="string">p#div-border-right-purple</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-right-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-right-color:</span> <span class="comment">#9954bb;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">上侧边框红色</span></span><br><span class="line"><span class="string">p#div-border-top-red</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-top-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-top-color:</span> <span class="comment">#df3e3e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">上侧边框黄色</span></span><br><span class="line"><span class="string">p#div-border-top-yellow</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-top-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-top-color:</span> <span class="comment">#f0ad4e;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">上侧边框绿色</span></span><br><span class="line"><span class="string">p#div-border-top-green</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-top-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-top-color:</span> <span class="comment">#5cb85c;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">上侧边框蓝色</span></span><br><span class="line"><span class="string">p#div-border-top-blue</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-top-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-top-color:</span> <span class="comment">#2780e3;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">//</span> <span class="string">上侧边框紫色</span></span><br><span class="line"><span class="string">p#div-border-top-purple</span> &#123;</span><br><span class="line"><span class="attr">display:</span> <span class="string">block;</span></span><br><span class="line"><span class="attr">padding:</span> <span class="string">10px;</span></span><br><span class="line"><span class="attr">margin:</span> <span class="string">10px</span> <span class="number">0</span><span class="string">;</span></span><br><span class="line"><span class="attr">border:</span> <span class="string">1px</span> <span class="string">solid</span> <span class="comment">#ccc;</span></span><br><span class="line"><span class="attr">border-top-width:</span> <span class="string">5px;</span></span><br><span class="line"><span class="attr">border-radius:</span> <span class="string">3px;</span></span><br><span class="line"><span class="attr">border-top-color:</span> <span class="comment">#9954bb;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用方法-在你要编辑的markdown文件里键入以下内容"><a href="#使用方法-在你要编辑的markdown文件里键入以下内容" class="headerlink" title="使用方法: 在你要编辑的markdown文件里键入以下内容"></a>使用方法: 在你要编辑的markdown文件里键入以下内容</h4><p><span id="inline-red"> 红色背景色块 </span></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-red&quot;</span>&gt;</span> 这里输入文字 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><span id="inline-blue"> 蓝色背景色块 </span></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-blue&quot;</span>&gt;</span> 这里输入文字 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><span id="inline-purple"> 紫色背景色块 </span></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-purple&quot;</span>&gt;</span> 这里输入文字 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><span id="inline-yellow"> 黄色背景色块 </span></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-yellow&quot;</span>&gt;</span> 这里输入文字 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><span id="inline-green"> 绿色背景色块 </span></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-green&quot;</span>&gt;</span> 这里输入文字 <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="背景自定义效果"><a href="#背景自定义效果" class="headerlink" title="背景自定义效果"></a>背景自定义效果</h3><p>效果：<br><span id="inline-toc">这里输入文字</span></p>
<h4 id="在styles-styl里键入自定义形状色块"><a href="#在styles-styl里键入自定义形状色块" class="headerlink" title="在styles.styl里键入自定义形状色块"></a>在styles.styl里键入自定义形状色块</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">自定义形状色块</span></span><br><span class="line"><span class="string">span#inline-toc</span> &#123;</span><br><span class="line">    <span class="attr">display:</span> <span class="string">inline-block;</span></span><br><span class="line">    <span class="attr">border-radius:</span> <span class="number">80</span><span class="string">%</span> <span class="number">100</span><span class="string">%</span> <span class="number">90</span><span class="string">%</span> <span class="number">20</span><span class="string">%;</span></span><br><span class="line">    <span class="attr">background-color:</span> <span class="string">rgb(237</span>, <span class="number">237</span>, <span class="number">237</span><span class="string">);</span></span><br><span class="line">    <span class="attr">color:</span> <span class="comment">#555;</span></span><br><span class="line">    <span class="attr">padding:</span> <span class="number">0.</span><span class="string">05em</span> <span class="number">0.</span><span class="string">4em;</span></span><br><span class="line">    <span class="attr">margin:</span> <span class="string">2px</span> <span class="string">5px</span> <span class="string">2px</span> <span class="string">0px;</span></span><br><span class="line">    <span class="attr">line-height:</span> <span class="number">1.5</span><span class="string">;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="使用方法-在你要编辑的markdown文件里键入以下内容-1"><a href="#使用方法-在你要编辑的markdown文件里键入以下内容-1" class="headerlink" title="使用方法: 在你要编辑的markdown文件里键入以下内容"></a>使用方法: 在你要编辑的markdown文件里键入以下内容</h4><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-toc&quot;</span>&gt;</span>这里输入文字<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="图标边框效果"><a href="#图标边框效果" class="headerlink" title="图标边框效果"></a>图标边框效果</h3><p>效果：</p>
<p><a id="download" href="/download/model_infer.py"><i class="fas fa-book-reader"></i><span> 查看内容</span><br></a></p>
<p>使用方法: 在你要编辑的markdown文件里键入以下内容</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">id</span>=<span class="string">&quot;download&quot;</span> <span class="attr">href</span>=<span class="string">&quot;/download/model_infer.py&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fas fa-book-reader&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">span</span>&gt;</span> 查看内容<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>附注：<a href="https://fontawesome.com/icons?d=gallery"><font color="blue">图标整理网站</font></a> 可以在其中选中想要实现的图标效果，获取相应的名称进行替换即可。</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%B8%80/FireShot%20Capture%20075%20-%20File%20Download%20Icon%20-%20Font%20Awesome%20-%20fontawesome.com.png" alt="FireShot Capture 075 - File Download Icon - Font Awesome - fontawesome.com"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">id</span>=<span class="string">&quot;download&quot;</span> <span class="attr">href</span>=<span class="string">&quot;/download/model_infer.py&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fas fa-file-download&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">span</span>&gt;</span> <span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">&quot;blue&quot;</span>&gt;</span>下载内容<span class="tag">&lt;/<span class="name">font</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><a id="download" href="/download/model_infer.py"><i class="fas fa-file-download"></i><span> <font color="blue">下载内容</font></span></a></p>
<h3 id="文本居中"><a href="#文本居中" class="headerlink" title="文本居中"></a>文本居中</h3><p>效果：</p>
<blockquote class="blockquote-center">
<p>Szabadság，Szerelem!<br>E kettő kell nekem<br>Szerelmemért föláldozom<br>Az életet<br>Szabadságért föláldozom<br>Szerelmemet.</p>

</blockquote>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">%cq%</span>&#125;</span><br><span class="line"><span class="string">Szabadság，Szerelem!</span></span><br><span class="line"><span class="string">E</span> <span class="string">kettő</span> <span class="string">kell</span> <span class="string">nekem</span></span><br><span class="line"><span class="string">Szerelmemért</span> <span class="string">föláldozom</span></span><br><span class="line"><span class="string">Az</span> <span class="string">életet</span></span><br><span class="line"><span class="string">Szabadságért</span> <span class="string">föláldozom</span></span><br><span class="line"><span class="string">Szerelmemet.</span></span><br><span class="line">&#123;<span class="string">%endcq%</span>&#125;</span><br></pre></td></tr></table></figure>

<h3 id="自定义数字块"><a href="#自定义数字块" class="headerlink" title="自定义数字块"></a>自定义数字块</h3><p>效果：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">/* 自定义的数字块 *<span class="regexp">/</span></span><br><span class="line"><span class="regexp">span#inline-toc &#123;</span></span><br><span class="line"><span class="regexp">    display: inline-block;</span></span><br><span class="line"><span class="regexp">    border-radius: 80% 100% 90% 20%;</span></span><br><span class="line"><span class="regexp">    background-color: rgb(227, 242, 253);</span></span><br><span class="line"><span class="regexp">    color: #555;</span></span><br><span class="line"><span class="regexp">    padding: 0.05em 0.4em;</span></span><br><span class="line"><span class="regexp">    margin: 2px 5px 2px 0px;</span></span><br><span class="line"><span class="regexp">    line-height: 1.5;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure>

<p>使用方法：</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%B8%80/Screenshot%20from%202020-09-22%2016-18-47.png"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;inline-toc&quot;</span>&gt;</span>1.<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>小白学搭Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorRT成功测试自己的数据集SSD模型二</title>
    <url>/post/fbaa150c.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>经过前面的指导我们安装好环境后，现在就准备训练我自己的数据集的SSD模型，这里我跟TensorRT的例子保持一致，都用TensorFlow Object Detection API训练获取模型。那么开始详细介绍TensorFlow Object Detection API的安装以及SSD inception V2训练我自己的数据集。</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/c02a3ba5.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型一</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/fbaa150c.html"><font color="red">TensorRT成功测试自己的数据集SSD模型二</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/b9f68301.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型三</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/f524ef1f.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型四</font></a> </p>
<h3 id="首先新建一个名为TensorFlow文件夹"><a href="#首先新建一个名为TensorFlow文件夹" class="headerlink" title="首先新建一个名为TensorFlow文件夹"></a>首先新建一个名为TensorFlow文件夹</h3><p>然后定位到该文件夹内</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> TensorFlow</span><br></pre></td></tr></table></figure>

<h3 id="下载TensorFlow-Models"><a href="#下载TensorFlow-Models" class="headerlink" title="下载TensorFlow Models"></a>下载TensorFlow Models</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/tensorflow/models.git</span><br></pre></td></tr></table></figure>

<div class="note danger">这里切记下载成功后要切换分支，为什么要切换，我自己实践的经验是用直接下载的model训练和测试是没有问题的，但是在用pb转uff的时候会出现_Cast node 错误，根据网上查到的解决办法将create_node_map中的Tofloat改成Cast,但是有会在create_engine时又会出现index error,就是用自己的五类目标训练得到的模型竟然出现预测的目标class_index为coco label中的index,真的很诡异。一直没能解决是哪里的问题，之后切换分支后就一切正常，所以<font color="red">一定要切换分支</font>。</div>

<p><span id="inline-red"> 切换分支方法 </span></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout ae0a9409212d0072938fa60c9f85740bb89ced7e</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E4%BA%8C/Screenshot%20from%202020-09-04%2017-40-24.png"></p>
<p>到现在TensorFlow形式如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow</span></span><br><span class="line"><span class="string">└─</span> <span class="string">models</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">official</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">research</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">samples</span></span><br><span class="line">    <span class="string">└──</span> <span class="string">tutorials</span></span><br></pre></td></tr></table></figure>

<h3 id="安装Protobuf"><a href="#安装Protobuf" class="headerlink" title="安装Protobuf"></a>安装Protobuf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install protobuf</span><br><span class="line"><span class="built_in">cd</span> models/research/</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>

<h3 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># From within TensorFlow/models/research/</span></span><br><span class="line">pip install .</span><br></pre></td></tr></table></figure>

<p>添加research/slim 到PYTHONPATH</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gedit ~/.bashrc</span><br><span class="line"><span class="comment"># From within tensorflow/models/research/</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$PYTHONPATH</span>:&lt;PATH_TO_TF&gt;/TensorFlow/models/research/slim</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>至此环境变量起作用了</p>
<h3 id="安装COCO-API"><a href="#安装COCO-API" class="headerlink" title="安装COCO API"></a>安装COCO API</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> Tensorflow/models/research</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/cocodataset/cocoapi.git</span><br><span class="line"><span class="built_in">cd</span> cocoapi/PythonAPI</span><br><span class="line">make</span><br><span class="line"><span class="built_in">cp</span> -r pycocotools &lt;PATH_TO_TF&gt;/TensorFlow/models/research/</span><br></pre></td></tr></table></figure>

<h3 id="验证安装是否成功"><a href="#验证安装是否成功" class="headerlink" title="验证安装是否成功"></a>验证安装是否成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> TensorFlow\models\research\object_detection</span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<p>运行object_detection_tutorial.ipynb</p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E4%BA%8C/FireShot%20Capture%20036%20-%20object_detection_tutorial%20-%20Jupyter%20Notebook%20-%20localhost.png"></p>
<p>运行无误说明安装成功。</p>
<p><font color="red">这里说明一点，如果你要运行model_builder_test，可能会出现有些例子运行失败，这里不用care这些失败，无视就好了，不影响接下来的训练。</font></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python object_detection/builders/model_builder_test.py</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E4%BA%8C/Screenshot%20from%202020-09-14%2015-06-02.png"></p>
<hr>
<center><font face="黑体" color="blue" size="8">接着正式开始我们的训练</font></center>

<h3 id="首先，在TensorFlow下新建workspace-training-demo文件夹"><a href="#首先，在TensorFlow下新建workspace-training-demo文件夹" class="headerlink" title="首先，在TensorFlow下新建workspace/training_demo文件夹"></a>首先，在TensorFlow下新建workspace/training_demo文件夹</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models</span></span><br><span class="line"><span class="string">│</span>   <span class="string">├─</span> <span class="string">official</span></span><br><span class="line"><span class="string">│</span>   <span class="string">├─</span> <span class="string">research</span></span><br><span class="line"><span class="string">│</span>   <span class="string">├─</span> <span class="string">samples</span></span><br><span class="line"><span class="string">│</span>   <span class="string">└─</span> <span class="string">tutorials</span></span><br><span class="line"><span class="string">└─</span> <span class="string">workspace</span></span><br><span class="line">    <span class="string">└─</span> <span class="string">training_demo</span></span><br><span class="line">    	<span class="string">├─</span> <span class="string">annotations</span></span><br><span class="line">		<span class="string">├─</span> <span class="string">images</span></span><br><span class="line">		<span class="string">│</span>   <span class="string">├─</span> <span class="string">test</span></span><br><span class="line">		<span class="string">│</span>   <span class="string">└─</span> <span class="string">train</span></span><br><span class="line">		<span class="string">├─</span> <span class="string">pre-trained-model</span></span><br><span class="line">		<span class="string">├─</span> <span class="string">training</span></span><br></pre></td></tr></table></figure>

<p>至于training_demo下的内容不需要新建，根据下面的步骤需要什么补充什么就行。</p>
<p>images是用来保存你的原始数据图像样本与注释文件的，现在要将其分类train和test，可以通过以下代码实现，9：1的比例也可以根据自身需要进行更改。</p>
<figure class="highlight ruby"><figcaption><span>partition_dataset.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot; usage: partition_dataset.py [-h] [-i IMAGEDIR] [-o OUTPUTDIR] [-r RATIO] [-x]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Partition dataset of images into training and testing sets</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help            show this help message and exit</span></span><br><span class="line"><span class="string">  -i IMAGEDIR, --imageDir IMAGEDIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the image dataset is stored. If not specified, the CWD will be used.</span></span><br><span class="line"><span class="string">  -o OUTPUTDIR, --outputDir OUTPUTDIR</span></span><br><span class="line"><span class="string">                        Path to the output folder where the train and test dirs should be created. Defaults to the same directory as IMAGEDIR.</span></span><br><span class="line"><span class="string">  -r RATIO, --ratio RATIO</span></span><br><span class="line"><span class="string">                        The ratio of the number of test images over the total number of images. The default is 0.1.</span></span><br><span class="line"><span class="string">  -x, --xml             Set this flag if you want the xml annotation files to be processed and copied over.</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">import os</span><br><span class="line">import re</span><br><span class="line">import shutil</span><br><span class="line">from <span class="variable constant_">PIL</span> import <span class="title class_">Image</span></span><br><span class="line">from shutil import copyfile</span><br><span class="line">import argparse</span><br><span class="line">import glob</span><br><span class="line">import math</span><br><span class="line">import random</span><br><span class="line">import xml.etree.<span class="title class_">ElementTree</span> as <span class="variable constant_">ET</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">iterate_dir</span>(<span class="params">source, dest, ratio, copy_xml</span>):</span><br><span class="line">    source = source.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    dest = dest.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    train_dir = os.path.join(dest, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    test_dir = os.path.join(dest, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_dir):</span><br><span class="line">        os.makedirs(train_dir)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(test_dir):</span><br><span class="line">        os.makedirs(test_dir)</span><br><span class="line"></span><br><span class="line">    images = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(source)</span><br><span class="line">              <span class="keyword">if</span> re.search(r<span class="string">&#x27;([a-zA-Z0-9\s_\\.\-\(\):])+(.jpg|.jpeg|.png)$&#x27;</span>, f)]</span><br><span class="line"></span><br><span class="line">    num_images = len(images)</span><br><span class="line">    num_test_images = math.ceil(ratio*num_images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test_images):</span><br><span class="line">        idx = random.randint(<span class="number">0</span>, len(images)-<span class="number">1</span>)</span><br><span class="line">        filename = images[idx]</span><br><span class="line">        copyfile(os.path.join(source, filename),</span><br><span class="line">                 os.path.join(test_dir, filename))</span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">copy_xml:</span></span><br><span class="line">            xml_filename = os.path.splitext(filename)[<span class="number">0</span>]+<span class="string">&#x27;.xml&#x27;</span></span><br><span class="line">            copyfile(os.path.join(source, xml_filename),</span><br><span class="line">                     os.path.join(test_dir,xml_filename))</span><br><span class="line">        images.remove(images[idx])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> <span class="symbol">images:</span></span><br><span class="line">        copyfile(os.path.join(source, filename),</span><br><span class="line">                 os.path.join(train_dir, filename))</span><br><span class="line">        <span class="keyword">if</span> <span class="symbol">copy_xml:</span></span><br><span class="line">            xml_filename = os.path.splitext(filename)[<span class="number">0</span>]+<span class="string">&#x27;.xml&#x27;</span></span><br><span class="line">            copyfile(os.path.join(source, xml_filename),</span><br><span class="line">                     os.path.join(train_dir, xml_filename))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initiate argument parser</span></span><br><span class="line">    parser = argparse.<span class="title class_">ArgumentParser</span>(description=<span class="string">&quot;Partition dataset of images into training and testing sets&quot;</span>,</span><br><span class="line">                                     formatter_class=argparse.<span class="title class_">RawTextHelpFormatter</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-i&#x27;</span>, <span class="string">&#x27;--imageDir&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;Path to the folder where the image dataset is stored. If not specified, the CWD will be used.&#x27;</span>,</span><br><span class="line">        type=str,</span><br><span class="line">        default=os.getcwd()</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;--outputDir&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;Path to the output folder where the train and test dirs should be created. &#x27;</span></span><br><span class="line">             <span class="string">&#x27;Defaults to the same directory as IMAGEDIR.&#x27;</span>,</span><br><span class="line">        type=str,</span><br><span class="line">        default=<span class="title class_">None</span></span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-r&#x27;</span>, <span class="string">&#x27;--ratio&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;The ratio of the number of test images over the total number of images. The default is 0.1.&#x27;</span>,</span><br><span class="line">        default=<span class="number">0.1</span>,</span><br><span class="line">        type=float)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-x&#x27;</span>, <span class="string">&#x27;--xml&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;Set this flag if you want the xml annotation files to be processed and copied over.&#x27;</span>,</span><br><span class="line">        action=<span class="string">&#x27;store_true&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.outputDir is <span class="title class_">None</span>:</span><br><span class="line">        args.outputDir = args.imageDir</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Now we are ready to start the iteration</span></span><br><span class="line">    iterate_dir(args.imageDir, args.outputDir, args.ratio, args.xml)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python partition_dataser.py -x -i training_demo\images -r 0.1</span><br></pre></td></tr></table></figure>

<h3 id="创建标签文件"><a href="#创建标签文件" class="headerlink" title="创建标签文件"></a>创建标签文件</h3><figure class="highlight ruby"><figcaption><span>training_demo\annotations\label_map.pbtxt</span></figcaption><table><tr><td class="code"><pre><span class="line">item &#123;</span><br><span class="line">    <span class="symbol">id:</span> <span class="number">1</span></span><br><span class="line">    <span class="symbol">name:</span> <span class="string">&#x27;dirty&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">item &#123;</span><br><span class="line">    <span class="symbol">id:</span> <span class="number">2</span></span><br><span class="line">    <span class="symbol">name:</span> <span class="string">&#x27;oil&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">item &#123;</span><br><span class="line">    <span class="symbol">id:</span> <span class="number">3</span></span><br><span class="line">    <span class="symbol">name:</span> <span class="string">&#x27;pit&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">item &#123;</span><br><span class="line">    <span class="symbol">id:</span> <span class="number">4</span></span><br><span class="line">    <span class="symbol">name:</span> <span class="string">&#x27;scratch&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">item &#123;</span><br><span class="line">    <span class="symbol">id:</span> <span class="number">5</span></span><br><span class="line">    <span class="symbol">name:</span> <span class="string">&#x27;wire_drawing&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="生成TensorFlow-Records"><a href="#生成TensorFlow-Records" class="headerlink" title="生成TensorFlow Records"></a>生成TensorFlow Records</h3><p>在TensorFlow下新建scripts\preprocessing文件夹</p>
<h4 id="xml-转-csv"><a href="#xml-转-csv" class="headerlink" title="xml 转 csv"></a>xml 转 csv</h4><figure class="highlight ruby"><figcaption><span>scripts\preprocessing\xml_to_csv.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string"># Create train data:</span></span><br><span class="line"><span class="string">python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/train -o [PATH_TO_ANNOTATIONS_FOLDER]/train_labels.csv</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Create test data:</span></span><br><span class="line"><span class="string">python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/test -o [PATH_TO_ANNOTATIONS_FOLDER]/test_labels.csv</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import pandas as pd</span><br><span class="line">import argparse</span><br><span class="line">import xml.etree.<span class="title class_">ElementTree</span> as <span class="variable constant_">ET</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xml_to_csv</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;Iterates through all .xml files (generated by labelImg) in a given directory and combines them in a single Pandas datagrame.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    path : &#123;str&#125;</span></span><br><span class="line"><span class="string">        The path containing the .xml files</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    Pandas DataFrame</span></span><br><span class="line"><span class="string">        The produced dataframe</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">&#x27;/*.xml&#x27;</span>):</span><br><span class="line">        tree = <span class="variable constant_">ET</span>.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">            value = (root.find(<span class="string">&#x27;filename&#x27;</span>).text,</span><br><span class="line">                    int(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">0</span>].text),</span><br><span class="line">                    int(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">1</span>].text),</span><br><span class="line">                    member[<span class="number">0</span>].text,</span><br><span class="line">                    int(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                    int(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                    int(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                    int(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                    )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;width&#x27;</span>, <span class="string">&#x27;height&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;xmin&#x27;</span>, <span class="string">&#x27;ymin&#x27;</span>, <span class="string">&#x27;xmax&#x27;</span>, <span class="string">&#x27;ymax&#x27;</span>]</span><br><span class="line">    xml_df = pd.<span class="title class_">DataFrame</span>(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># Initiate argument parser</span></span><br><span class="line">    parser = argparse.<span class="title class_">ArgumentParser</span>(</span><br><span class="line">        description=<span class="string">&quot;Sample TensorFlow XML-to-CSV converter&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;-i&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;--inputDir&quot;</span>,</span><br><span class="line">                        help=<span class="string">&quot;Path to the folder where the input .xml files are stored&quot;</span>,</span><br><span class="line">                        type=str)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;-o&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;--outputFile&quot;</span>,</span><br><span class="line">                        help=<span class="string">&quot;Name of output .csv file (including path)&quot;</span>, type=str)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(args.inputDir is <span class="title class_">None</span>):</span><br><span class="line">        args.inputDir = os.getcwd()</span><br><span class="line">    <span class="keyword">if</span>(args.outputFile is <span class="title class_">None</span>):</span><br><span class="line">        args.outputFile = args.inputDir + <span class="string">&quot;/labels.csv&quot;</span></span><br><span class="line"></span><br><span class="line">    assert(os.path.isdir(args.inputDir))</span><br><span class="line"></span><br><span class="line">    xml_df = xml_to_csv(args.inputDir)</span><br><span class="line">    xml_df.to_csv(</span><br><span class="line">        args.outputFile, index=<span class="title class_">None</span>)</span><br><span class="line">    print(<span class="string">&#x27;Successfully converted xml to csv.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> TensorFlow/scripts/preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create train data:</span></span><br><span class="line">python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/train -o [PATH_TO_ANNOTATIONS_FOLDER]/train_labels.csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create test data:</span></span><br><span class="line">python xml_to_csv.py -i [PATH_TO_IMAGES_FOLDER]/test -o [PATH_TO_ANNOTATIONS_FOLDER]/test_labels.csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># For example</span></span><br><span class="line"><span class="comment"># python xml_to_csv.py -i C:\Users\sglvladi\Documents\TensorFlow\workspace\training_demo\images\train -o C:\Users\sglvladi\Documents\TensorFlow\workspace\training_demo\annotations\train_labels.csv</span></span><br><span class="line"><span class="comment"># python xml_to_csv.py -i C:\Users\sglvladi\Documents\TensorFlow\workspace\training_demo\images\test -o C:\Users\sglvladi\Documents\TensorFlow\workspace\training_demo\annotations\test_labels.csv</span></span><br></pre></td></tr></table></figure>

<h4 id="csv-转-record"><a href="#csv-转-record" class="headerlink" title="csv 转 record"></a>csv 转 record</h4><figure class="highlight ruby"><figcaption><span>TensorFlow\scripts\preprocessing\generate_tfrecord.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Create train data:</span></span><br><span class="line"><span class="string">python generate_tfrecord.py --label=&lt;LABEL&gt; --csv_input=&lt;PATH_TO_ANNOTATIONS_FOLDER&gt;/train_labels.csv  --output_path=&lt;PATH_TO_ANNOTATIONS_FOLDER&gt;/train.record</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Create test data:</span></span><br><span class="line"><span class="string">python generate_tfrecord.py --label=&lt;LABEL&gt; --csv_input=&lt;PATH_TO_ANNOTATIONS_FOLDER&gt;/test_labels.csv  --output_path=&lt;PATH_TO_ANNOTATIONS_FOLDER&gt;/test.record</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">from __future__ import division</span><br><span class="line">from __future__ import print_function</span><br><span class="line">from __future__ import absolute_import</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import io</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import sys</span><br><span class="line">sys.path.append(<span class="string">&quot;../../models/research&quot;</span>)</span><br><span class="line"></span><br><span class="line">from <span class="variable constant_">PIL</span> import <span class="title class_">Image</span></span><br><span class="line">from object_detection.utils import dataset_util</span><br><span class="line">from collections import namedtuple, <span class="title class_">OrderedDict</span></span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;csv_input&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Path to the CSV input&#x27;</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;output_path&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Path to output TFRecord&#x27;</span>)</span><br><span class="line"><span class="comment"># flags.DEFINE_string(&#x27;label0&#x27;, &#x27;&#x27;, &#x27;Name of class label&#x27;)</span></span><br><span class="line"><span class="comment"># if your image has more labels input them as</span></span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;label0&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Name of class[0] label&#x27;</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;label1&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Name of class[1] label&#x27;</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;label2&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Name of class[2] label&#x27;</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;label3&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Name of class[3] label&#x27;</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;label4&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Name of class[4] label&#x27;</span>)</span><br><span class="line"><span class="comment"># and so on.</span></span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;img_path&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Path to images&#x27;</span>)</span><br><span class="line"><span class="variable constant_">FLAGS</span> = flags.<span class="variable constant_">FLAGS</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># TO-DO replace this with label map</span></span><br><span class="line"><span class="comment"># for multiple labels add more else if statements</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">class_text_to_int</span>(<span class="params">row_label</span>):</span><br><span class="line">    <span class="comment"># if row_label == FLAGS.label:  # &#x27;ship&#x27;:</span></span><br><span class="line">    <span class="comment">#     return 1</span></span><br><span class="line">    <span class="comment"># comment upper if statement and uncomment these statements for multiple labelling</span></span><br><span class="line">    <span class="keyword">if</span> row_label == <span class="variable constant_">FLAGS</span>.<span class="symbol">label0:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    elif row_label == <span class="variable constant_">FLAGS</span>.<span class="symbol">label1:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">    elif row_label == <span class="variable constant_">FLAGS</span>.<span class="symbol">label2:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">3</span>      </span><br><span class="line">    elif row_label == <span class="variable constant_">FLAGS</span>.<span class="symbol">label3:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">4</span></span><br><span class="line">    elif row_label == <span class="variable constant_">FLAGS</span>.<span class="symbol">label4:</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">5</span></span><br><span class="line">    <span class="symbol">else:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split</span>(<span class="params">df, group</span>):</span><br><span class="line">    data = namedtuple(<span class="string">&#x27;data&#x27;</span>, [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;object&#x27;</span>])</span><br><span class="line">    gb = df.groupby(group)</span><br><span class="line">    <span class="keyword">return</span> [data(filename, gb.get_group(x)) <span class="keyword">for</span> filename, x <span class="keyword">in</span> zip(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_tf_example</span>(<span class="params">group, path</span>):</span><br><span class="line">    with tf.gfile.<span class="title class_">GFile</span>(os.path.join(path, <span class="string">&#x27;&#123;&#125;&#x27;</span>.format(group.filename)), <span class="string">&#x27;rb&#x27;</span>) as <span class="symbol">fid:</span></span><br><span class="line">        encoded_jpg = fid.read()</span><br><span class="line">    encoded_jpg_io = io.<span class="title class_">Bytes</span>IO(encoded_jpg)</span><br><span class="line">    image = <span class="title class_">Image</span>.open(encoded_jpg_io)</span><br><span class="line">    width, height = image.size</span><br><span class="line"></span><br><span class="line">    filename = group.filename.encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">    image_format = b<span class="string">&#x27;jpg&#x27;</span></span><br><span class="line">    <span class="comment"># check if the image format is matching with your images.</span></span><br><span class="line">    xmins = []</span><br><span class="line">    xmaxs = []</span><br><span class="line">    ymins = []</span><br><span class="line">    ymaxs = []</span><br><span class="line">    classes_text = []</span><br><span class="line">    classes = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> group.object.iterrows():</span><br><span class="line">        xmins.append(row[<span class="string">&#x27;xmin&#x27;</span>] / width)</span><br><span class="line">        xmaxs.append(row[<span class="string">&#x27;xmax&#x27;</span>] / width)</span><br><span class="line">        ymins.append(row[<span class="string">&#x27;ymin&#x27;</span>] / height)</span><br><span class="line">        ymaxs.append(row[<span class="string">&#x27;ymax&#x27;</span>] / height)</span><br><span class="line">        classes_text.append(row[<span class="string">&#x27;class&#x27;</span>].encode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        classes.append(class_text_to_int(row[<span class="string">&#x27;class&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.<span class="title class_">Example</span>(features=tf.train.<span class="title class_">Features</span>(feature=&#123;</span><br><span class="line">        <span class="string">&#x27;image/height&#x27;</span>: dataset_util.int64_feature(height),</span><br><span class="line">        <span class="string">&#x27;image/width&#x27;</span>: dataset_util.int64_feature(width),</span><br><span class="line">        <span class="string">&#x27;image/filename&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/source_id&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/encoded&#x27;</span>: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        <span class="string">&#x27;image/format&#x27;</span>: dataset_util.bytes_feature(image_format),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmin&#x27;</span>: dataset_util.float_list_feature(xmins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmax&#x27;</span>: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymin&#x27;</span>: dataset_util.float_list_feature(ymins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymax&#x27;</span>: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/class/text&#x27;</span>: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        <span class="string">&#x27;image/object/class/label&#x27;</span>: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    <span class="keyword">return</span> tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">_</span>):</span><br><span class="line">    writer = tf.python_io.<span class="title class_">TFRecordWriter</span>(<span class="variable constant_">FLAGS</span>.output_path)</span><br><span class="line">    path = os.path.join(os.getcwd(), <span class="variable constant_">FLAGS</span>.img_path)</span><br><span class="line">    examples = pd.read_csv(<span class="variable constant_">FLAGS</span>.csv_input)</span><br><span class="line">    grouped = split(examples, <span class="string">&#x27;filename&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> <span class="symbol">grouped:</span></span><br><span class="line">        tf_example = create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.<span class="title class_">SerializeToString</span>())</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    output_path = os.path.join(os.getcwd(), <span class="variable constant_">FLAGS</span>.output_path)</span><br><span class="line">    print(<span class="string">&#x27;Successfully created the TFRecords: &#123;&#125;&#x27;</span>.format(output_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> TensorFlow\scripts\preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create train data:</span></span><br><span class="line">python generate_tfrecord.py --label0=dirty --label1=oil --label2=pit --label3=scratch --label4=wire_drawing --csv_input=/home/xxx/Tensorflow_new/workspace/training_demo/annotations/train_labels.csv --output_path=/home/xxx/Tensorflow_new/workspace/training_demo/annotations/train.record --img_path=/home/xxx/Tensorflow_new/workspace/training_demo/images/train</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create test data:</span></span><br><span class="line">python generate_tfrecord.py --label0=dirty --label1=oil --label2=pit --label3=scratch --label4=wire_drawing --csv_input=/home/xxx/Tensorflow_new/workspace/training_demo/annotations/test_labels.csv --output_path=/home/xxx/Tensorflow_new/workspace/training_demo/annotations/test.record --img_path=/home/xxx/Tensorflow_new/workspace/training_demo/images/test</span><br></pre></td></tr></table></figure>

<p>之后会在training_demo/annotations文件夹下生成test.record 和 train.record 即为转换成功。</p>
<h3 id="创建训练Pipeline"><a href="#创建训练Pipeline" class="headerlink" title="创建训练Pipeline"></a>创建训练Pipeline</h3><h4 id="首先下载预训练模型选择ssd-inception-v2-coco下载"><a href="#首先下载预训练模型选择ssd-inception-v2-coco下载" class="headerlink" title="首先下载预训练模型选择ssd_inception_v2_coco下载"></a>首先下载预训练模型<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md"><font color="blue">选择ssd_inception_v2_coco下载</font></a></h4><p>将下载好的模型解压到 pre-trained-models</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">training_demo/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">...</span></span><br><span class="line"><span class="string">├─</span> <span class="string">pre-trained-models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">ssd_inception_v2_coco_2018_01_28/</span></span><br><span class="line"><span class="string">│</span>     <span class="string">├─</span> <span class="string">saved_model/</span></span><br><span class="line"><span class="string">│</span>       <span class="string">├─</span> <span class="string">pipeline.config</span></span><br><span class="line"><span class="string">│</span>     <span class="string">└─</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h4 id="创建pipeline-config"><a href="#创建pipeline-config" class="headerlink" title="创建pipeline.config"></a>创建pipeline.config</h4><p><span id="inline-toc">1.</span>复制training_demo/pre-trained-models/ssd_inception_v2_coco_2018_01_28/pipeline.config到training_demo/training</p>
<p><span id="inline-toc">2.</span>打开training_demo/training下的 <strong>pipeline.config</strong> ；</p>
<figure class="highlight ruby"><figcaption><span>training_demo/training/pipeline.config</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># SSD with Inception v2 configuration for MSCOCO Dataset.</span></span><br><span class="line"><span class="comment"># Users should configure the fine_tune_checkpoint field in the train config as</span></span><br><span class="line"><span class="comment"># well as the label_map_path and input_path fields in the train_input_reader and</span></span><br><span class="line"><span class="comment"># eval_input_reader. Search for &quot;PATH_TO_BE_CONFIGURED&quot; to find the fields that</span></span><br><span class="line"><span class="comment"># should be configured.</span></span><br><span class="line"></span><br><span class="line">model &#123;</span><br><span class="line">    ssd &#123;</span><br><span class="line">        <span class="symbol">num_classes:</span> <span class="number">5</span> <span class="comment"># Set this to the number of different label classes</span></span><br><span class="line">        box_coder &#123;</span><br><span class="line">            faster_rcnn_box_coder &#123;</span><br><span class="line">                <span class="symbol">y_scale:</span> <span class="number">10.0</span></span><br><span class="line">                <span class="symbol">x_scale:</span> <span class="number">10.0</span></span><br><span class="line">                <span class="symbol">height_scale:</span> <span class="number">5.0</span></span><br><span class="line">                <span class="symbol">width_scale:</span> <span class="number">5.0</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        matcher &#123;</span><br><span class="line">            argmax_matcher &#123;</span><br><span class="line">                <span class="symbol">matched_threshold:</span> <span class="number">0.5</span></span><br><span class="line">                <span class="symbol">unmatched_threshold:</span> <span class="number">0.5</span></span><br><span class="line">                <span class="symbol">ignore_thresholds:</span> <span class="literal">false</span></span><br><span class="line">                <span class="symbol">negatives_lower_than_unmatched:</span> <span class="literal">true</span></span><br><span class="line">                <span class="symbol">force_match_for_each_row:</span> <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        similarity_calculator &#123;</span><br><span class="line">            iou_similarity &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        anchor_generator &#123;</span><br><span class="line">            ssd_anchor_generator &#123;</span><br><span class="line">                <span class="symbol">num_layers:</span> <span class="number">6</span></span><br><span class="line">                <span class="symbol">min_scale:</span> <span class="number">0.2</span></span><br><span class="line">                <span class="symbol">max_scale:</span> <span class="number">0.95</span></span><br><span class="line">                <span class="symbol">aspect_ratios:</span> <span class="number">1.0</span></span><br><span class="line">                <span class="symbol">aspect_ratios:</span> <span class="number">2.0</span></span><br><span class="line">                <span class="symbol">aspect_ratios:</span> <span class="number">0.5</span></span><br><span class="line">                <span class="symbol">aspect_ratios:</span> <span class="number">3.0</span></span><br><span class="line">                <span class="symbol">aspect_ratios:</span> <span class="number">0.3333</span></span><br><span class="line">                <span class="symbol">reduce_boxes_in_lowest_layer:</span> <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        image_resizer &#123;</span><br><span class="line">            fixed_shape_resizer &#123;</span><br><span class="line">                <span class="symbol">height:</span> <span class="number">300</span></span><br><span class="line">                <span class="symbol">width:</span> <span class="number">300</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        box_predictor &#123;</span><br><span class="line">            convolutional_box_predictor &#123;</span><br><span class="line">                <span class="symbol">min_depth:</span> <span class="number">0</span></span><br><span class="line">                <span class="symbol">max_depth:</span> <span class="number">0</span></span><br><span class="line">                <span class="symbol">num_layers_before_predictor:</span> <span class="number">0</span></span><br><span class="line">                <span class="symbol">use_dropout:</span> <span class="literal">false</span></span><br><span class="line">                <span class="symbol">dropout_keep_probability:</span> <span class="number">0.8</span></span><br><span class="line">                <span class="symbol">kernel_size:</span> <span class="number">3</span></span><br><span class="line">                <span class="symbol">box_code_size:</span> <span class="number">4</span></span><br><span class="line">                <span class="symbol">apply_sigmoid_to_scores:</span> <span class="literal">false</span></span><br><span class="line">                conv_hyperparams &#123;</span><br><span class="line">                <span class="symbol">activation:</span> <span class="variable constant_">RELU_6</span>,</span><br><span class="line">                regularizer &#123;</span><br><span class="line">                    l2_regularizer &#123;</span><br><span class="line">                        <span class="symbol">weight:</span> <span class="number">0.00004</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                initializer &#123;</span><br><span class="line">                        truncated_normal_initializer &#123;</span><br><span class="line">                            <span class="symbol">stddev:</span> <span class="number">0.03</span></span><br><span class="line">                            <span class="symbol">mean:</span> <span class="number">0.0</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        feature_extractor &#123;</span><br><span class="line">            <span class="symbol">type:</span> <span class="string">&#x27;ssd_inception_v2&#x27;</span> <span class="comment"># Set to the name of your chosen pre-trained model</span></span><br><span class="line">            <span class="symbol">min_depth:</span> <span class="number">16</span></span><br><span class="line">            <span class="symbol">depth_multiplier:</span> <span class="number">1.0</span></span><br><span class="line">            conv_hyperparams &#123;</span><br><span class="line">                <span class="symbol">activation:</span> <span class="variable constant_">RELU_6</span>,</span><br><span class="line">                regularizer &#123;</span><br><span class="line">                    l2_regularizer &#123;</span><br><span class="line">                        <span class="symbol">weight:</span> <span class="number">0.00004</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                initializer &#123;</span><br><span class="line">                    truncated_normal_initializer &#123;</span><br><span class="line">                        <span class="symbol">stddev:</span> <span class="number">0.03</span></span><br><span class="line">                        <span class="symbol">mean:</span> <span class="number">0.0</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                batch_norm &#123;</span><br><span class="line">                    <span class="symbol">train:</span> <span class="literal">true</span>,</span><br><span class="line">                    <span class="symbol">scale:</span> <span class="literal">true</span>,</span><br><span class="line">                    <span class="symbol">center:</span> <span class="literal">true</span>,</span><br><span class="line">                    <span class="symbol">decay:</span> <span class="number">0.9997</span>,</span><br><span class="line">                    <span class="symbol">epsilon:</span> <span class="number">0.001</span>,</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="symbol">override_base_feature_extractor_hyperparams:</span> <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">        loss &#123;</span><br><span class="line">            classification_loss &#123;</span><br><span class="line">                weighted_sigmoid &#123;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            localization_loss &#123;</span><br><span class="line">                weighted_smooth_l1 &#123;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            hard_example_miner &#123;</span><br><span class="line">                <span class="symbol">num_hard_examples:</span> <span class="number">3000</span></span><br><span class="line">                <span class="symbol">iou_threshold:</span> <span class="number">0.99</span></span><br><span class="line">                <span class="symbol">loss_type:</span> <span class="variable constant_">CLASSIFICATION</span></span><br><span class="line">                <span class="symbol">max_negatives_per_positive:</span> <span class="number">3</span></span><br><span class="line">                <span class="symbol">min_negatives_per_image:</span> <span class="number">0</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="symbol">classification_weight:</span> <span class="number">1.0</span></span><br><span class="line">            <span class="symbol">localization_weight:</span> <span class="number">1.0</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="symbol">normalize_loss_by_num_matches:</span> <span class="literal">true</span></span><br><span class="line">        post_processing &#123;</span><br><span class="line">            batch_non_max_suppression &#123;</span><br><span class="line">                <span class="symbol">score_threshold:</span> <span class="number">1e-8</span></span><br><span class="line">                <span class="symbol">iou_threshold:</span> <span class="number">0.6</span></span><br><span class="line">                <span class="symbol">max_detections_per_class:</span> <span class="number">100</span></span><br><span class="line">                <span class="symbol">max_total_detections:</span> <span class="number">100</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="symbol">score_converter:</span> <span class="variable constant_">SIGMOID</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="symbol">train_config:</span> &#123;</span><br><span class="line">    <span class="symbol">batch_size:</span> <span class="number">24</span> <span class="comment"># Increase/Decrease this value depending on the available memory (Higher values require more memory and vice-versa)</span></span><br><span class="line">    optimizer &#123;</span><br><span class="line">        <span class="symbol">rms_prop_optimizer:</span> &#123;</span><br><span class="line">            <span class="symbol">learning_rate:</span> &#123;</span><br><span class="line">                exponential_decay_learning_rate &#123;</span><br><span class="line">                    <span class="symbol">initial_learning_rate:</span> <span class="number">0.004</span></span><br><span class="line">                    <span class="symbol">decay_steps:</span> <span class="number">800720</span></span><br><span class="line">                    <span class="symbol">decay_factor:</span> <span class="number">0.95</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="symbol">momentum_optimizer_value:</span> <span class="number">0.9</span></span><br><span class="line">            <span class="symbol">decay:</span> <span class="number">0.9</span></span><br><span class="line">            <span class="symbol">epsilon:</span> <span class="number">1.0</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="symbol">fine_tune_checkpoint:</span> <span class="string">&quot;pre-trained-model/model.ckpt&quot;</span> <span class="comment"># Path to extracted files of pre-trained model</span></span><br><span class="line">    <span class="symbol">from_detection_checkpoint:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Note: The below line limits the training process to 200K steps, which we</span></span><br><span class="line">    <span class="comment"># empirically found to be sufficient enough to train the pets dataset. This</span></span><br><span class="line">    <span class="comment"># effectively bypasses the learning rate schedule (the learning rate will</span></span><br><span class="line">    <span class="comment"># never decay). Remove the below line to train indefinitely.</span></span><br><span class="line">    <span class="symbol">num_steps:</span> <span class="number">200000</span></span><br><span class="line">    data_augmentation_options &#123;</span><br><span class="line">        random_horizontal_flip &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    data_augmentation_options &#123;</span><br><span class="line">        ssd_random_crop &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="symbol">train_input_reader:</span> &#123;</span><br><span class="line">    tf_record_input_reader &#123;</span><br><span class="line">        <span class="symbol">input_path:</span> <span class="string">&quot;annotations/train.record&quot;</span> <span class="comment"># Path to training TFRecord file</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="symbol">label_map_path:</span> <span class="string">&quot;annotations/label_map.pbtxt&quot;</span> <span class="comment"># Path to label map file</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="symbol">eval_config:</span> &#123;</span><br><span class="line">    <span class="comment"># (Optional): Uncomment the line below if you installed the Coco evaluation tools</span></span><br><span class="line">    <span class="comment"># and you want to also run evaluation</span></span><br><span class="line">    <span class="comment"># metrics_set: &quot;coco_detection_metrics&quot;</span></span><br><span class="line">    <span class="comment"># (Optional): Set this to the number of images in your &lt;PATH_TO_IMAGES_FOLDER&gt;/train</span></span><br><span class="line">    <span class="comment"># if you want to also run evaluation</span></span><br><span class="line">    <span class="symbol">num_examples:</span> <span class="number">8000</span></span><br><span class="line">    <span class="comment"># Note: The below line limits the evaluation process to 10 evaluations.</span></span><br><span class="line">    <span class="comment"># Remove the below line to evaluate indefinitely.</span></span><br><span class="line">    <span class="symbol">max_evals:</span> <span class="number">10</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="symbol">eval_input_reader:</span> &#123;</span><br><span class="line">    tf_record_input_reader &#123;</span><br><span class="line">        <span class="symbol">input_path:</span> <span class="string">&quot;annotations/test.record&quot;</span> <span class="comment"># Path to testing TFRecord</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="symbol">label_map_path:</span> <span class="string">&quot;annotations/label_map.pbtxt&quot;</span> <span class="comment"># Path to label map file</span></span><br><span class="line">    <span class="symbol">shuffle:</span> <span class="literal">false</span></span><br><span class="line">    <span class="symbol">num_readers:</span> <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h3><p><span id="inline-toc">1.</span>复制TensorFlow/models/research/object_detection/train.py到training_demo文件夹</p>
<p><span id="inline-toc">2.</span>cd training_demo, 运行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/pipeline.config</span><br></pre></td></tr></table></figure>

<p>最终在training文件夹保存到训练所得到的模型。</p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E4%BA%8C/Screenshot%20from%202020-09-17%2017-29-36.png"></p>
]]></content>
      <categories>
        <category>TensorRT实战记</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorRT成功测试自己的数据集SSD模型三</title>
    <url>/post/b9f68301.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>现在我们已经成功训练好了tensorflow object detection 模型，我们的数据集为5类缺陷目标，网络模型选用的是ssd inception V2。具体训练步骤见<a href="https://bella722.github.io/post/fbaa150c.html">TensorRT成功测试自己的数据集SSD模型二</a>，现在讲述在tensorrt中具体如何使用。</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/c02a3ba5.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型一</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/fbaa150c.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型二</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/b9f68301.html"><font color="red">TensorRT成功测试自己的数据集SSD模型三</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/f524ef1f.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型四</font></a> </p>
<h3 id="导出Trained-Inference-Graph"><a href="#导出Trained-Inference-Graph" class="headerlink" title="导出Trained Inference Graph"></a>导出Trained Inference Graph</h3><ul>
<li><h4 id="TensorFlow-models-research-object-detection-export-inference-graph-py复制到training-demo文件夹"><a href="#TensorFlow-models-research-object-detection-export-inference-graph-py复制到training-demo文件夹" class="headerlink" title="TensorFlow/models/research/object_detection/export_inference_graph.py复制到training_demo文件夹"></a>TensorFlow/models/research/object_detection/export_inference_graph.py复制到training_demo文件夹</h4></li>
<li><h4 id="找到training-demo-training下的model-ckpt-的-第一个index-比如model-ckpt-0"><a href="#找到training-demo-training下的model-ckpt-的-第一个index-比如model-ckpt-0" class="headerlink" title="找到training_demo/training下的model.ckpt-*的 第一个index , 比如model.ckpt-0"></a>找到training_demo/training下的model.ckpt-*的<span id="inline-red"> 第一个index </span>, 比如model.ckpt-0</h4></li>
<li><h4 id="cd-training-demo"><a href="#cd-training-demo" class="headerlink" title="cd training_demo"></a>cd training_demo</h4></li>
<li><h4 id="导出pb"><a href="#导出pb" class="headerlink" title="导出pb"></a>导出pb</h4></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_inception_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-0 --output_directory trained-inference-graphs/output_inference_graph_v1.pb</span><br></pre></td></tr></table></figure>

<h3 id="uff-ssd"><a href="#uff-ssd" class="headerlink" title="uff_ssd"></a>uff_ssd</h3><p>首先，定位到TensorRT-7.0.0.11/samples/python/uff_ssd</p>
<p><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E4%B8%89/Screenshot%20from%202020-09-21%2009-27-59.png"></p>
<p>打开<span id="inline-blue"> detect_object.py </span></p>
<ul>
<li><h4 id="COCO-label-list"><a href="#COCO-label-list" class="headerlink" title="COCO label list"></a>COCO label list</h4></li>
</ul>
<figure class="highlight ruby"><figcaption><span>utils/coco.py 148行</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="variable constant_">COCO_CLASSES_LIST</span> = [<span class="string">&#x27;unlabeled&#x27;</span>, <span class="string">&#x27;dirty&#x27;</span>, <span class="string">&#x27;oil&#x27;</span>, <span class="string">&#x27;pit&#x27;</span>, <span class="string">&#x27;scratch&#x27;</span>, <span class="string">&#x27;wire_drawing&#x27;</span>]</span><br></pre></td></tr></table></figure>

<div class="note danger"><p>定义你自己的CLASSES_LIST，切记'unlabeled'不能少</p></div>

<ul>
<li><h4 id="MODEL-NAME"><a href="#MODEL-NAME" class="headerlink" title="MODEL_NAME"></a>MODEL_NAME</h4></li>
</ul>
<figure class="highlight ruby"><figcaption><span>detect_objects.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="comment"># Model used for inference</span></span><br><span class="line"><span class="variable constant_">MODEL_NAME</span> = <span class="string">&#x27;my_model&#x27;</span></span><br></pre></td></tr></table></figure>

<p>  接着注释掉model下的raise error和download_model</p>
<figure class="highlight ruby"><figcaption><span>uff_ssd/utils/model.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> model_name != <span class="string">&quot;ssd_inception_v2_coco_2017_11_17&quot;</span>:</span><br><span class="line">    <span class="comment"># raise NotImplementedError(</span></span><br><span class="line">    <span class="comment">#     &quot;Model &#123;&#125; is not supported yet&quot;.format(model_name))</span></span><br><span class="line">    <span class="comment">#####test#####</span></span><br><span class="line">    print(model_name)</span><br><span class="line"><span class="comment">######test#####</span></span><br><span class="line"><span class="comment">#download_model(model_name, silent)</span></span><br></pre></td></tr></table></figure>

<ul>
<li><h4 id="numClasses"><a href="#numClasses" class="headerlink" title="numClasses"></a>numClasses</h4></li>
</ul>
<figure class="highlight ruby"><figcaption><span>utils/model.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="variable constant_">NMS</span> = gs.create_plugin_node(</span><br><span class="line">    name=<span class="string">&quot;NMS&quot;</span>,</span><br><span class="line">    op=<span class="string">&quot;NMS_TRT&quot;</span>,</span><br><span class="line">    shareLocation=<span class="number">1</span>,</span><br><span class="line">    varianceEncodedInTarget=<span class="number">0</span>,</span><br><span class="line">    backgroundLabelId=<span class="number">0</span>,</span><br><span class="line">    confidenceThreshold=<span class="number">1e-8</span>,</span><br><span class="line">    nmsThreshold=<span class="number">0.6</span>,</span><br><span class="line">    topK=<span class="number">100</span>,</span><br><span class="line">    keepTopK=<span class="number">100</span>,</span><br><span class="line">    numClasses=<span class="number">6</span>,</span><br><span class="line">    inputOrder=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">    confSigmoid=<span class="number">1</span>,</span><br><span class="line">    isNormalized=<span class="number">1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<div class="note danger"><p>切记这里的numClasses为classes+1</p></div>

<h3 id><a href="#" class="headerlink" title></a></h3>]]></content>
      <categories>
        <category>TensorRT实战记</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>Next 8.0 进阶美化篇二</title>
    <url>/post/4f44d92e.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>原始next-pieces的布局不太符合我的审美，所以想按照自己的喜好自定义以下页面样式，比如自定义背景图片，去掉文章底部的白色背景，部件边框椭圆化一下，以及位置调整一下。所以这里就把自己的实现步骤记录一下。</p>

</blockquote>       

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/74c4f787.html"><font color="blue">Next 8.0 进阶美化篇一</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/4f44d92e.html"><font color="red">Next 8.0 进阶美化篇二</font></a> </p>
<p>我的next版本为8.0，这里先贴出我最终实现的首页样式。</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/FireShot%20Capture%20039%20-%20Bella's%20Blog%20-%20localhost.png" alt="Bella&#39;s Blog"></p>
<h3 id="去除首页文章间隔与短横线"><a href="#去除首页文章间隔与短横线" class="headerlink" title="去除首页文章间隔与短横线"></a>去除首页文章间隔与短横线</h3><p>原版首页文章之间是以间距与一条短横线作为分文标记的</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-11-06%2009-46-49.png"></p>
<p>这里我不需要这个就需要把它删掉，这里要改的地方是Bolg/themes/next/source/css/_common/components/post下的post-footer.styl文件，具体如下：</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-11-06%2009-44-04.png"></p>
<p>注释后可以预览效果</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-11-06%2009-49-06.png"></p>
<p>接下来就是自定义美化内容了</p>
<h3 id="自定义首页背景图片"><a href="#自定义首页背景图片" class="headerlink" title="自定义首页背景图片"></a>自定义首页背景图片</h3><p><span id="inline-toc"><b>1. </b></span>在styles.styl里自定义post, 添加背景图象</p>
<figure class="highlight ruby"><figcaption><span>Bolg/source/_data/styles.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">/<span class="regexp">/全局布局美化代码</span></span><br><span class="line"><span class="regexp">body &#123;</span></span><br><span class="line"><span class="regexp">	background-image:url(/images</span><span class="regexp">/Background.jpg);</span></span><br><span class="line"><span class="regexp">	background-repeat: no-repeat;</span></span><br><span class="line"><span class="regexp">	background-attachment: fixed;</span></span><br><span class="line"><span class="regexp">	background-position: center;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure>

<p><span id="inline-red"> 这里的images为Bolg/themes/next/source/images </span></p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-11-00.png" alt="before"></p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-12-01.png" alt="after"></p>
<p><span id="inline-toc"><b>2. </b></span>预览时又发现next自身设置的背景有个main-inner的属性，颜色是继承post content color，所以我们的思路是自定义main-inner的background-color</p>
<figure class="highlight ruby"><figcaption><span>Bolg/source/_data/styles.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">.main-inner &#123;</span><br><span class="line">    background-<span class="symbol">color:</span> rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>rgba(255, 255, 255, 0)里的0代表透明度大小，值在0-1之间，0为全透明。再次预览发现此时文章的背景也为透明了。</p>
<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-13-21.png" alt="before"></p>
<p>那为了突出文章，我们想让它的颜色透明度为1，那就再次自定义一下，加上之前我们设置过每篇文章的边框，所以我们直接在post-block里加上background-color设置。</p>
<figure class="highlight ruby"><figcaption><span>Bolg/source/_data/styles.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">.post-block&#123;</span><br><span class="line">		background-<span class="symbol">color:</span> rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">1</span>);</span><br><span class="line">		margin-<span class="symbol">top:</span> 24px;</span><br><span class="line">    	margin-<span class="symbol">bottom:</span> 24px;</span><br><span class="line">    	<span class="symbol">padding:</span> 20px;</span><br><span class="line">		border-<span class="symbol">radius:</span> 30px 30px 30px 30px;</span><br><span class="line">		box-<span class="symbol">shadow:</span> 8px 7px 2px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), 7px 4px 1px -2px rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> 1px 5px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-13-58.png" alt="after"></p>
<h3 id="调整组件位置"><a href="#调整组件位置" class="headerlink" title="调整组件位置"></a>调整组件位置</h3><p>这时发现post-block的位置距离顶端有些距离，看起来不美观，</p>
<p>所以这里就把main-inner的padding顶部置0, 并注释post-block的margin-top</p>
<figure class="highlight ruby"><figcaption><span>Bolg/source/_data/styles.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">.main-inner &#123;</span><br><span class="line">    background-<span class="symbol">color:</span> rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="symbol">padding:</span> 0px 40px 40px 40px;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-16-20.png"></p>
<p>post-block的内容太靠近边框了，那就用padding集中一下</p>
<figure class="highlight ruby"><figcaption><span>Bolg/source/_data/styles.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">.post-block&#123;</span><br><span class="line">		background-<span class="symbol">color:</span> rgba(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">1</span>);</span><br><span class="line">		<span class="regexp">//margin</span>-<span class="symbol">top:</span> 24px;</span><br><span class="line">    	margin-<span class="symbol">bottom:</span> 24px;</span><br><span class="line">    	<span class="symbol">padding:</span> 20px;</span><br><span class="line">		border-<span class="symbol">radius:</span> 30px 50px 30px 50px;</span><br><span class="line">		box-<span class="symbol">shadow:</span> 8px 7px 2px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), 7px 4px 1px -2px rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> 1px 5px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-17-06.png"></p>
<h3 id="组件边框椭圆化"><a href="#组件边框椭圆化" class="headerlink" title="组件边框椭圆化"></a>组件边框椭圆化</h3><figure class="highlight ruby"><figcaption><span>Bolg/source/_data/styles.styl</span></figcaption><table><tr><td class="code"><pre><span class="line">.header-inner &#123;</span><br><span class="line">	border-<span class="symbol">radius:</span> 30px 30px 30px 30px;</span><br><span class="line">	box-<span class="symbol">shadow:</span> 8px 7px 2px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), 7px 4px 1px -2px rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> 1px 5px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br><span class="line">.sidebar-inner&#123;</span><br><span class="line">	border-<span class="symbol">radius:</span> 30px 30px 30px 30px;</span><br><span class="line">	box-<span class="symbol">shadow:</span> 8px 7px 2px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), 7px 4px 1px -2px rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> 1px 5px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);	</span><br><span class="line">&#125;</span><br><span class="line">.pagination &#123;</span><br><span class="line">	border-<span class="symbol">radius:</span> 30px 80px 30px 80px;</span><br><span class="line">	box-<span class="symbol">shadow:</span> 8px 7px 2px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), 7px 4px 1px -2px rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> 1px 5px <span class="number">0</span> rgba(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/Next-8-0-%E8%BF%9B%E9%98%B6%E7%BE%8E%E5%8C%96%E7%AF%87%E4%BA%8C/Screenshot%20from%202020-09-18%2018-18-11.png"></p>
]]></content>
      <categories>
        <category>小白学搭Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下为AppImage应用添加图标并添加到应用</title>
    <url>/post/3c4ff36.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>有时下载的一些AppImage应用是没有配置图标的，所以不是很美观，本篇教程指导根据自己喜好自定义应用图标，具体内容参见文章详情</p>

</blockquote>

<span id="more"></span>

<h3 id="准备好图标文件"><a href="#准备好图标文件" class="headerlink" title="准备好图标文件"></a>准备好图标文件</h3><p>这里建议下载的时候搜索xx图标或者xx icon进行下载，这样之后生成的图标能美观点</p>
<h3 id="创建xx-desktop"><a href="#创建xx-desktop" class="headerlink" title="创建xx.desktop"></a>创建xx.desktop</h3><p>在任意位置新建一个名为xx.desktop的文件，并写入如下内容：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line">[<span class="string">Desktop</span> <span class="string">Entry</span>]</span><br><span class="line"><span class="string">Name=DiffChecker</span></span><br><span class="line"><span class="string">Exec=/home/xxx/Downloads/Diffchecker-3.7.2.AppImage</span></span><br><span class="line"><span class="string">Icon=/home/xxx/Downloads/Diffchecker.png</span></span><br><span class="line"><span class="string">Type=Application</span></span><br><span class="line"><span class="string">StartupNotify=true</span></span><br></pre></td></tr></table></figure>

<p>Name：快捷方式的名称<br>Exec：AppImage所在的文件路径<br>icon：要为其添加的图标的文件路径</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-23-27.png"></p>
<p>保存xx.desktop后右键属性,在权限目录下允许作为程序执行文件上打钩。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-51-52.png"></p>
<h3 id="添加到应用"><a href="#添加到应用" class="headerlink" title="添加到应用"></a>添加到应用</h3><p>打开终端，输入sudo nautilus</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo nautilus</span><br></pre></td></tr></table></figure>

<p>然后在弹出的文件窗口定位到/usr/share/applications，再将xx.desktop复制过来</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-17-49.png"></p>
<p>关闭终端</p>
<h3 id="添加到快捷应用栏"><a href="#添加到快捷应用栏" class="headerlink" title="添加到快捷应用栏"></a>添加到快捷应用栏</h3><p>现在在应用列表里就可以看到已经更换好图标的应用了，选中然后右键选择添加到常用，最后在快捷应用栏就可以看到我们的应用啦，验证以下使用也正常无误。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-25-30.png"><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-25-52.png"><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-26-08.png"></p>
]]></content>
      <categories>
        <category>教你玩转Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorRT成功测试自己的数据集SSD模型四</title>
    <url>/post/f524ef1f.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>经过之前一系列的工作，进坑出坑的尝试，总算是把测试结果搞出来了，所以在此总结。并结合之前一些在google colab上的测试对比，将实际数据公布出来以供大家参考。</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/c02a3ba5.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型一</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/fbaa150c.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型二</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/b9f68301.html"><font color="blue">TensorRT成功测试自己的数据集SSD模型三</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/f524ef1f.html"><font color="red">TensorRT成功测试自己的数据集SSD模型四</font></a> </p>
<h3 id="检测结果"><a href="#检测结果" class="headerlink" title="检测结果"></a>检测结果</h3><table>
    <tr>
        <td colspan="12"><font color="red"><center>单张推理结果</center></font></td>
    </tr>
    <tr>
        <td colspan="12"><center>3类目标，训练样本219张，训练代数50K</center></td>
    </tr>
    <tr>
        <td colspan="4"><center>No tensorrt infer GTX 1070 Ti</center></td>
        <td colspan="8"><center>With tensorrt infer GTX 1070 Ti</center></td>
    </tr>
    <tr>
        <td colspan="3"><center>precision</center></td>
        <td colspan="1"><center>time</center></td>
        <td colspan="6"><center>precision</center></td>
        <td colspan="2"><center>time</center></td>
    </tr>
    <tr>
        <td colspan="3"><center></center></td>
        <td colspan="1"><center></center></td>
        <td colspan="3"><center>half</center></td>
        <td colspan="3"><center>float</center></td>
        <td colspan="1"><center>half</center></td>
        <td colspan="1"><center>float</center></td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/1_res_2390.bmp"></td>
        <td>21.9ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/1_h_5.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/1_f_5.jpg"></td>
        <td>5ms</td>
        <td>5ms</td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/2_res_2387-1602234745418.bmp"></td>
        <td>21.87ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/2_h_7.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/2_f_5.jpg"></td>
        <td>7ms</td>
        <td>5ms</td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/3_res_2375.bmp"></td>
        <td>21.75ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/3_h_6.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/3_f_5.jpg"></td>
        <td>6ms</td>
        <td>5ms</td>
    </tr>
   <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/4_res_2372.bmp"></td>
        <td>21.72ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/4_h_5.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/4_f_6.jpg"></td>
        <td>5ms</td>
        <td>6ms</td>
    </tr>
        <tr>
        <td colspan="12"><center>5类目标，训练样本1006张，训练代数200K</center></td>
    </tr>
    <tr>
        <td colspan="4"><center>No tensorrt infer GTX 1070 Ti</center></td>
        <td colspan="8"><center>With tensorrt infer GTX 1070 Ti</center></td>
    </tr>
    <tr>
        <td colspan="3"><center>precision</center></td>
        <td colspan="1"><center>time</center></td>
        <td colspan="6"><center>precision</center></td>
        <td colspan="2"><center>time</center></td>
    </tr>
    <tr>
        <td colspan="3"><center></center></td>
        <td colspan="1"><center></center></td>
        <td colspan="3"><center>half</center></td>
        <td colspan="3"><center>float</center></td>
        <td colspan="1"><center>half</center></td>
        <td colspan="1"><center>float</center></td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_1_res_2871.bmp"></td>
        <td>21.86ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_1_h_6.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_1_f_5.jpg"></td>
        <td>6ms</td>
        <td>5ms</td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_2_res_2470.bmp"></td>
        <td>21.7ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_2_h_5.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_2_f_6.jpg"></td>
        <td>5ms</td>
        <td>6ms</td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_3_res_2648.bmp"></td>
        <td>21.48ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_3_h_5.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_3_f_5.jpg"></td>
        <td>5ms</td>
        <td>5ms</td>
    </tr>
    <tr>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_4_res_2485.bmp"></td>
        <td>21.85ms</td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_4_h_5.jpg"></td>
        <td colspan="3"><img data-src="../images/TensorRT%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86SSD%E6%A8%A1%E5%9E%8B%E5%9B%9B/5_4_f_5.jpg"></td>
        <td>5ms</td>
        <td>5ms</td>
    </tr>
        <tr>
        <td colspan="12"><font color="red">结论：1. 无论从推测用时还是检测精度来看，tensorrt下选择精度为16或32的检测结果都基本无差；2. 用了tensorrt后的推理时长相比不用的时候能够提升4倍左右；3.  用了tensorrt后的预测精度相比不用的时候有所提升</font></td>
    </tr>
    <tr>
        <td colspan="12"><font color="red"><center>批量推理结果</center></font></td>
    </tr>
    <tr>
        <td colspan="12"><center>Image size(8k×40k), 预测裁剪小图size(300×300)，w方向：8000/300=26，h方向：40000/300= 133，裁剪生成的小图有：26×133 = 3458张</center></td>
    </tr>
    <tr>
        <td colspan="6"><center>No tensorrt infer GTX 1070 Ti</center></td>
        <td colspan="6"><center>With tensorrt infer GTX 1070 Ti</center></td>
    </tr>
    <tr>
        <td colspan="6"><center>infer_batch_size = 70</center></td>
        <td colspan="6"><center>infer_batch_size = 13</center></td>
    </tr>
    <tr>
        <td colspan="6"><center>1.0401s</center></td>
        <td colspan="6"><center>26.68ms</center></td>
    </tr>
    <tr>
        <td colspan="6"><center>total_time</center></td>
        <td colspan="6"><center>total_time</center></td>
    </tr>
    <tr>
        <td colspan="6"><center>52.0058s</center></td>
        <td colspan="6"><center>7.097s</center></td>
    </tr>
    <tr>        
        <td colspan="6"><center></center></td>
        <td colspan="6"><center>With tensorrt infer GTX 1070 Ti</center></td>
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>infer_batch_size = 26</center></td>
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>47.47ms</center></td>    
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>total_time</center></td>    
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>6.314s</center></td>    
    </tr>
    <tr>        
        <td colspan="6"><center></center></td>
        <td colspan="6"><center>With tensorrt infer GTX 1070 Ti</center></td>
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>infer_batch_size = 38</center></td>
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>65.076ms</center></td>    
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>total_time</center></td>    
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>5.922s</center></td>    
    </tr>
    <tr>        
        <td colspan="6"><center></center></td>
        <td colspan="6"><center>With tensorrt infer GTX 1070 Ti</center></td>
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>infer_batch_size = 70</center></td>
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>117.3ms</center></td>    
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>total_time</center></td>    
    </tr>    
    <tr>        
        <td colspan="6"><center></center></td>        
        <td colspan="6"><center>5.865s</center></td>    
    </tr>
        <tr>
        <td colspan="12"><font color="red">结论： 1. 用了tensorrt后的推理时长相比不用的时候能够提升8-10倍左右；2. 一直到batch_size = 70GPU未饱和，并且最大利用率到70%左右，仍有剩余</font></td>
    </tr>
</table>






]]></content>
      <categories>
        <category>TensorRT实战记</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu20.04下成功配置Qv2ray</title>
    <url>/post/a231f91f.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>对于一名码农来说，经常需要解决bug, 加上有时还需要对最新paper方向的掌握，也都需要上网查资料获取，尤其是深度学习方向最新的一些数据集以及模型的下载，都需要合适的网络环境，所以在这里我把自己在Ubuntu下解决这一问题的过程记录下来，希望能够帮助到和我有同样需求的小伙伴</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/a6ffce94.html"><font color="blue">Windows下成功配置Qv2ray</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/a231f91f.html"><font color="red">Ubuntu20.04下成功配置Qv2ray</font></a> </p>
<h3 id="安装客户端"><a href="#安装客户端" class="headerlink" title="安装客户端"></a>安装客户端</h3><p>​    软件中心搜索qv2ray安装</p>
<p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-03-10.png"></p>
<h3 id="配置客户端"><a href="#配置客户端" class="headerlink" title="配置客户端"></a>配置客户端</h3><h4 id="从应用列表将app右键添加到主页最常用应用栏"><a href="#从应用列表将app右键添加到主页最常用应用栏" class="headerlink" title="从应用列表将app右键添加到主页最常用应用栏"></a>从应用列表将app右键添加到主页最常用应用栏</h4><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-17-24.png"></p>
<h4 id="打开Qv2ray-会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹"><a href="#打开Qv2ray-会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹" class="headerlink" title="打开Qv2ray, 会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹"></a>打开Qv2ray, 会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹</h4><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-03-42.png"></p>
<h4 id="先配置语言，点击preferences进入设置，语言栏选中中文并确定"><a href="#先配置语言，点击preferences进入设置，语言栏选中中文并确定" class="headerlink" title="先配置语言，点击preferences进入设置，语言栏选中中文并确定"></a>先配置语言，点击preferences进入设置，语言栏选中中文并确定</h4><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-03-59.png"></p>
<h4 id="核心core文件配置"><a href="#核心core文件配置" class="headerlink" title="核心core文件配置"></a>核心core文件配置</h4><h5 id="进入https-github-com-v2ray-v2ray-core-releases-根据自己的系统下载相应的核心文件"><a href="#进入https-github-com-v2ray-v2ray-core-releases-根据自己的系统下载相应的核心文件" class="headerlink" title="进入https://github.com/v2ray/v2ray-core/releases 根据自己的系统下载相应的核心文件"></a>进入<a href="https://github.com/v2ray/v2ray-core/releases">https://github.com/v2ray/v2ray-core/releases</a> 根据自己的系统下载相应的核心文件</h5><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/FireShot%20Capture%20019%20-%20Releases%20%C2%B7%20v2ray_v2ray-core%20-%20github.com.png"></p>
<h5 id="在-home-xxx-snap-qv2ray-2733-config-qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl-h才能显示隐藏的-config文件夹，这里注意即可。"><a href="#在-home-xxx-snap-qv2ray-2733-config-qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl-h才能显示隐藏的-config文件夹，这里注意即可。" class="headerlink" title="在/home/xxx/snap/qv2ray/2733/.config/qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl+h才能显示隐藏的.config文件夹，这里注意即可。"></a>在/home/xxx/snap/qv2ray/2733/.config/qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl+h才能显示隐藏的.config文件夹，这里注意即可。</h5><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-06-18.png"><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-06-52.png"><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-07-13.png"></p>
<h5 id="验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功"><a href="#验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功" class="headerlink" title="验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功"></a>验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功</h5><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-07-30.png"><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-07-34.png"></p>
<h3 id="回到app首页配置入网config文件。选择新建下的手动输入开始录入信息"><a href="#回到app首页配置入网config文件。选择新建下的手动输入开始录入信息" class="headerlink" title="回到app首页配置入网config文件。选择新建下的手动输入开始录入信息"></a>回到app首页配置入网config文件。选择新建下的手动输入开始录入信息</h3><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-08-27.png"></p>
<p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-08-55.png"></p>
<blockquote>
<p><strong>以下是我经常获取free acounts的两个网址：<br>link 1:  <a href="http://tr1.freeair888.club/v2ray%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/">http://tr1.freeair888.club/v2ray%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/</a><br>link 2: <a href="https://view.freev2ray.org/">https://view.freev2ray.org/</a><br>ink 2的accounts info每12H 会更新一次，只要删除旧连接添加另一个新连接就哦了</strong></p>
</blockquote>
<h3 id="最后主页右键选中线路连接就搞定啦"><a href="#最后主页右键选中线路连接就搞定啦" class="headerlink" title="最后主页右键选中线路连接就搞定啦"></a>最后主页右键选中线路连接就搞定啦</h3><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-09-20.png"><br>&emsp;</p>
<blockquote>
<p><em>写在最后：请在合理合法的范围内使用。希望大家都好好珍惜这些资源，不然使用不当造成账号被封是大家都不愿意看到的事。</em></p>
</blockquote>
]]></content>
      <categories>
        <category>科学上网指南</category>
      </categories>
      <tags>
        <tag>Qv2ray</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下用TensorFlow Object Detection API测试训练的模型</title>
    <url>/post/e88b7107.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>得到训练的模型后，进行测试前需要进行inference graph 的pb文件导出，本文记载了详细的操作步骤，以及最终的模型加载直到最终的检测结果</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/1a71c089.html"><font color="blue">Ubuntu20.04下成功配置TensorFlow Object Detection API 教程</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/bb2ec196.html"><font color="blue">Ubuntu下用TensorFlow Object Detection API训练自己的数据</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/e88b7107.html"><font color="red">Ubuntu下用TensorFlow Object Detection API测试自己的数据</font></a> </p>
<p>经过之前的训练后，会在workspace/training_demo/models/my_ssd_inception_v2保存最终生成的模型文件。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-34-14.png"></p>
<p>准备好你要测试的图像文件，接下来我们开始测试。</p>
<h3 id="ckpt模型转换pb模型"><a href="#ckpt模型转换pb模型" class="headerlink" title="ckpt模型转换pb模型"></a>ckpt模型转换pb模型</h3><h4 id="打开终端，激活虚拟环境"><a href="#打开终端，激活虚拟环境" class="headerlink" title="打开终端，激活虚拟环境"></a>打开终端，激活虚拟环境</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> activate python370</span><br></pre></td></tr></table></figure>

<h4 id="复制TensorFlow-models-research-object-detection-export-inference-graph-py文件到training-demo文件夹"><a href="#复制TensorFlow-models-research-object-detection-export-inference-graph-py文件到training-demo文件夹" class="headerlink" title="复制TensorFlow/models/research/object_detection/export_inference_graph.py文件到training_demo文件夹"></a>复制TensorFlow/models/research/object_detection/export_inference_graph.py文件到training_demo文件夹</h4><p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-43-07.png"></p>
<h4 id="找出模型文件夹下step最小的ckpt"><a href="#找出模型文件夹下step最小的ckpt" class="headerlink" title="找出模型文件夹下step最小的ckpt"></a>找出模型文件夹下step最小的ckpt</h4><p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-46-00.png"></p>
<h4 id="在终端cd到training-demo文件夹，运行下面的命令"><a href="#在终端cd到training-demo文件夹，运行下面的命令" class="headerlink" title="在终端cd到training_demo文件夹，运行下面的命令"></a>在终端cd到training_demo文件夹，运行下面的命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python export_inference_graph.py --input_type image_tensor --pipeline_config_path models/my_ssd_inception_v2/pipeline.config --trained_checkpoint_prefix models/my_ssd_inception_v2/model.ckpt-194120 --output_directory trained-inference-graphs/output_inference_graph_v1.pb</span><br></pre></td></tr></table></figure>

<p>运行后在生成的trained-inference-graphs/output_inference_graph_v1.pb文件夹下可以看到结果。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-54-23.png"></p>
<h3 id="测试pb模型得到结果"><a href="#测试pb模型得到结果" class="headerlink" title="测试pb模型得到结果"></a>测试pb模型得到结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> six.moves.urllib <span class="keyword">as</span> urllib</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MODEL_NAME = <span class="string">&#x27;workspace/training_demo/trained-inference-graphs/output_inference_graph_v1.pb&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Path to frozen detection graph. This is the actual model that is used for the object detection.</span></span><br><span class="line">PATH_TO_CKPT = MODEL_NAME + <span class="string">&#x27;/frozen_inference_graph.pb&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List of the strings that is used to add correct label for each box.</span></span><br><span class="line">PATH_TO_LABELS = <span class="string">&#x27;workspace/training_demo/annotations/label_map.pbtxt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of classes to detect</span></span><br><span class="line">NUM_CLASSES = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load a (frozen) Tensorflow model into memory.</span></span><br><span class="line">detection_graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">    od_graph_def = tf.compat.v1.GraphDef()</span><br><span class="line">    <span class="keyword">with</span> tf.io.gfile.GFile(PATH_TO_CKPT, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        serialized_graph = fid.read()</span><br><span class="line">        od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">        tf.import_graph_def(od_graph_def, name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loading label map</span></span><br><span class="line"><span class="comment"># Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine</span></span><br><span class="line">label_map = label_map_util.load_labelmap(PATH_TO_LABELS)</span><br><span class="line">categories = label_map_util.convert_label_map_to_categories(</span><br><span class="line">    label_map, max_num_classes=NUM_CLASSES, use_display_name=<span class="literal">True</span>)</span><br><span class="line">category_index = label_map_util.create_category_index(categories)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;workspace/training_demo/test_data&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Detection</span></span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">    <span class="keyword">with</span> tf.compat.v1.Session(graph=detection_graph) <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(data_dir):</span><br><span class="line">            image_np = np.array(Image.<span class="built_in">open</span>(os.path.join(data_dir, filename)))</span><br><span class="line">            <span class="comment"># Expand dimensions since the model expects images to have shape: [1, None, None, 3]</span></span><br><span class="line">            image_np_expanded = np.expand_dims(image_np, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># Extract image tensor</span></span><br><span class="line">            image_tensor = detection_graph.get_tensor_by_name(<span class="string">&#x27;image_tensor:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract detection boxes</span></span><br><span class="line">            boxes = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_boxes:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract detection scores</span></span><br><span class="line">            scores = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_scores:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract detection classes</span></span><br><span class="line">            classes = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_classes:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract number of detectionsd</span></span><br><span class="line">            num_detections = detection_graph.get_tensor_by_name(</span><br><span class="line">                <span class="string">&#x27;num_detections:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Actual detection.</span></span><br><span class="line">            (boxes, scores, classes, num_detections) = sess.run(</span><br><span class="line">                [boxes, scores, classes, num_detections],</span><br><span class="line">                feed_dict=&#123;image_tensor: image_np_expanded&#125;)</span><br><span class="line">            <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">            vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">                image_np,</span><br><span class="line">                np.squeeze(boxes),</span><br><span class="line">                np.squeeze(classes).astype(np.int32),</span><br><span class="line">                np.squeeze(scores),</span><br><span class="line">                category_index,</span><br><span class="line">                use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">                line_thickness=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Display output</span></span><br><span class="line">            <span class="comment"># cv2.imshow(&#x27;object detection&#x27;, cv2.resize(image_np, (800, 600)))</span></span><br><span class="line">            cv2.imwrite(filename, image_np)</span><br></pre></td></tr></table></figure>

<p>只需要把里面涉及到路径的内容改成你自己的，就可以看到最终的测试结果啦！测试py文件可以<a href="/download/model_infer.py">在此下载</a></p>
<p>最后贴出我的一些测试结果。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/1.bmp"><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/3.bmp"></p>
]]></content>
      <categories>
        <category>Ubuntu下TensorFlow Object Detection API实战</category>
      </categories>
      <tags>
        <tag>TensorFlow Object Detection API</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下用TensorFlow Object Detection API训练自己的数据</title>
    <url>/post/bb2ec196.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>对于使用TensorFlow Object Detection API训练自己的数据集，网上教程还是很全的，只要认真细心，跟着官方指导就不会有任何问题</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/1a71c089.html"><font color="blue">Ubuntu20.04下成功配置TensorFlow Object Detection API 教程</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/bb2ec196.html"><font color="red">Ubuntu下用TensorFlow Object Detection API训练自己的数据</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/e88b7107.html"><font color="blue">Ubuntu下用TensorFlow Object Detection API测试自己的数据</font></a> </p>
<p>如果你是跟着我之前的教程配置过来的，那相信你目前已经有一个名为Tensorflow的文件夹了，且包含的内容具体如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">models/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line">   <span class="string">└─</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>接下来我们就直入主题开始训练步骤。</p>
<h3 id="在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training-demo文件夹"><a href="#在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training-demo文件夹" class="headerlink" title="在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training_demo文件夹"></a>在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training_demo文件夹</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">...</span></span><br><span class="line"><span class="string">└─</span> <span class="string">workspace/</span></span><br><span class="line">   <span class="string">└─</span> <span class="string">training_demo/</span></span><br></pre></td></tr></table></figure>

<p>对于training_demo文件夹，主要存放数据集，训练输出的模型以及预训练模型。最终的具体形式如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">training_demo/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">annotations/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">exported-models/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">images/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">test/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">train/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">pre-trained-models/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">README.md</span></span><br></pre></td></tr></table></figure>

<h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><p>这里需要说明的是，如果你现在还没有标注或者准备好要训练的数据集，那么建议你只需要新建除test以及train之外的相应位置的文件夹，把你需要标注的所有图像放在images下，然后用诸如labelImg的工具完成标注工作，将最终的xml注释文件全部置于annotations文件夹下。至于labelImg的具体使用方法可以自行搜索，非常简单。</p>
<p>接下来比较重要的一步是进行训练与测试的划分，即将数据集按照一定比例划分为训练集与测试集，通常的比例是9：1。如果你的数据集只有一类目标，那么可以直接用下面的代码自动生成test与train文件夹。 <a href="/download/partition_dataset.py">点击下载代码</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; usage: partition_dataset.py [-h] [-i IMAGEDIR] [-o OUTPUTDIR] [-r RATIO] [-x]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Partition dataset of images into training and testing sets</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help            show this help message and exit</span></span><br><span class="line"><span class="string">  -i IMAGEDIR, --imageDir IMAGEDIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the image dataset is stored. If not specified, the CWD will be used.</span></span><br><span class="line"><span class="string">  -o OUTPUTDIR, --outputDir OUTPUTDIR</span></span><br><span class="line"><span class="string">                        Path to the output folder where the train and test dirs should be created. Defaults to the same directory as IMAGEDIR.</span></span><br><span class="line"><span class="string">  -r RATIO, --ratio RATIO</span></span><br><span class="line"><span class="string">                        The ratio of the number of test images over the total number of images. The default is 0.1.</span></span><br><span class="line"><span class="string">  -x, --xml             Set this flag if you want the xml annotation files to be processed and copied over.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copyfile</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">iterate_dir</span>(<span class="params">source, dest, ratio, copy_xml</span>):</span><br><span class="line">    source = source.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    dest = dest.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    train_dir = os.path.join(dest, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    test_dir = os.path.join(dest, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_dir):</span><br><span class="line">        os.makedirs(train_dir)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(test_dir):</span><br><span class="line">        os.makedirs(test_dir)</span><br><span class="line"></span><br><span class="line">    images = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(source)</span><br><span class="line">              <span class="keyword">if</span> re.search(<span class="string">r&#x27;([a-zA-Z0-9\s_\\.\-\(\):])+(.jpg|.jpeg|.png)$&#x27;</span>, f)]</span><br><span class="line"></span><br><span class="line">    num_images = <span class="built_in">len</span>(images)</span><br><span class="line">    num_test_images = math.ceil(ratio*num_images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_test_images):</span><br><span class="line">        idx = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(images)-<span class="number">1</span>)</span><br><span class="line">        filename = images[idx]</span><br><span class="line">        copyfile(os.path.join(source, filename),</span><br><span class="line">                 os.path.join(test_dir, filename))</span><br><span class="line">        <span class="keyword">if</span> copy_xml:</span><br><span class="line">            xml_filename = os.path.splitext(filename)[<span class="number">0</span>]+<span class="string">&#x27;.xml&#x27;</span></span><br><span class="line">            copyfile(os.path.join(source, xml_filename),</span><br><span class="line">                     os.path.join(test_dir,xml_filename))</span><br><span class="line">        images.remove(images[idx])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> images:</span><br><span class="line">        copyfile(os.path.join(source, filename),</span><br><span class="line">                 os.path.join(train_dir, filename))</span><br><span class="line">        <span class="keyword">if</span> copy_xml:</span><br><span class="line">            xml_filename = os.path.splitext(filename)[<span class="number">0</span>]+<span class="string">&#x27;.xml&#x27;</span></span><br><span class="line">            copyfile(os.path.join(source, xml_filename),</span><br><span class="line">                     os.path.join(train_dir, xml_filename))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initiate argument parser</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&quot;Partition dataset of images into training and testing sets&quot;</span>,</span><br><span class="line">                                     formatter_class=argparse.RawTextHelpFormatter)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-i&#x27;</span>, <span class="string">&#x27;--imageDir&#x27;</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;Path to the folder where the image dataset is stored. If not specified, the CWD will be used.&#x27;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">        default=os.getcwd()</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;--outputDir&#x27;</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;Path to the output folder where the train and test dirs should be created. &#x27;</span></span><br><span class="line">             <span class="string">&#x27;Defaults to the same directory as IMAGEDIR.&#x27;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">        default=<span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-r&#x27;</span>, <span class="string">&#x27;--ratio&#x27;</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;The ratio of the number of test images over the total number of images. The default is 0.1.&#x27;</span>,</span><br><span class="line">        default=<span class="number">0.1</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">float</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-x&#x27;</span>, <span class="string">&#x27;--xml&#x27;</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;Set this flag if you want the xml annotation files to be processed and copied over.&#x27;</span>,</span><br><span class="line">        action=<span class="string">&#x27;store_true&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.outputDir <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        args.outputDir = args.imageDir</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Now we are ready to start the iteration</span></span><br><span class="line">    iterate_dir(args.imageDir, args.outputDir, args.ratio, args.xml)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>这里建议在TensorFlow主文件夹下新建scripts/preprocessing文件夹，用来存放这些自动化的py文件。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">...</span></span><br><span class="line"><span class="string">├─</span> <span class="string">scripts/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">preprocessing/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">workspace/</span></span><br><span class="line">   <span class="string">└─</span> <span class="string">training_demo/</span></span><br></pre></td></tr></table></figure>

<p>运行的时候只要在TensorFlow/scripts/preprocessing文件夹下运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python partition_dataset.py -x -i [PATH_TO_IMAGES_FOLDER] -r 0.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># For example</span></span><br><span class="line"><span class="comment"># python partition_dataset.py -x -i C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images -r 0.1</span></span><br></pre></td></tr></table></figure>

<p>就会在training_demo/images下新建<span id="inline-green"> train </span>和新建<span id="inline-green"> test </span>这两个文件夹，并且在train和test下可以看到既有图像文件又有xml注释文件，并且train与test文件数目比为<span id="inline-yellow"> 9:1 </span>.</p>
<blockquote>
<p><strong>这里提醒一点：当你的数据集是包含两种及以上类别的目标时，建议不要直接这么操作，原因是样本可能会不被均匀非配，这样造成的后果就是你在之后训练的时候可能出现训练集主要是A目标，而测试集主要是B目标，所以可想而知，模型的效果会有多差，所以在这种情况下建议以样本均衡为原则进行分配，保证训练集与测试集的统一与均衡。</strong></p>
</blockquote>
<h3 id="创建-Label-Map"><a href="#创建-Label-Map" class="headerlink" title="创建 Label Map"></a>创建 Label Map</h3><p>在training_demo/annotations下新建label_map.pbtxt文件，内容为：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;dirty&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">2</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;oil&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;pit&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">4</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;scratch&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;wire_drawing&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="生成TensorFlow-Records文件"><a href="#生成TensorFlow-Records文件" class="headerlink" title="生成TensorFlow Records文件"></a>生成TensorFlow Records文件</h3><p>之前生成的training_demo/images/train与training_demo/images/test文件夹下的xml可通过以下代码转换成record文件<a href="download/generate_tfrecord.py">点击下载转换代码</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Sample TensorFlow XML-to-TFRecord converter</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help            show this help message and exit</span></span><br><span class="line"><span class="string">  -x XML_DIR, --xml_dir XML_DIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the input .xml files are stored.</span></span><br><span class="line"><span class="string">  -l LABELS_PATH, --labels_path LABELS_PATH</span></span><br><span class="line"><span class="string">                        Path to the labels (.pbtxt) file.</span></span><br><span class="line"><span class="string">  -o OUTPUT_PATH, --output_path OUTPUT_PATH</span></span><br><span class="line"><span class="string">                        Path of output TFRecord (.record) file.</span></span><br><span class="line"><span class="string">  -i IMAGE_DIR, --image_dir IMAGE_DIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the input image files are stored. Defaults to the same directory as XML_DIR.</span></span><br><span class="line"><span class="string">  -c CSV_PATH, --csv_path CSV_PATH</span></span><br><span class="line"><span class="string">                        Path of output .csv file. If none provided, then no file will be written.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span>    <span class="comment"># Suppress TensorFlow logging (1)</span></span><br><span class="line"><span class="keyword">import</span> tensorflow.compat.v1 <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> dataset_util, label_map_util</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initiate argument parser</span></span><br><span class="line">parser = argparse.ArgumentParser(</span><br><span class="line">    description=<span class="string">&quot;Sample TensorFlow XML-to-TFRecord converter&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-x&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--xml_dir&quot;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;Path to the folder where the input .xml files are stored.&quot;</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="built_in">str</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-l&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--labels_path&quot;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;Path to the labels (.pbtxt) file.&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-o&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--output_path&quot;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;Path of output TFRecord (.record) file.&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-i&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--image_dir&quot;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;Path to the folder where the input image files are stored. &quot;</span></span><br><span class="line">                         <span class="string">&quot;Defaults to the same directory as XML_DIR.&quot;</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-c&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--csv_path&quot;</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&quot;Path of output .csv file. If none provided, then no file will be &quot;</span></span><br><span class="line">                         <span class="string">&quot;written.&quot;</span>,</span><br><span class="line">                    <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.image_dir <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    args.image_dir = args.xml_dir</span><br><span class="line"></span><br><span class="line">label_map = label_map_util.load_labelmap(args.labels_path)</span><br><span class="line">label_map_dict = label_map_util.get_label_map_dict(label_map)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xml_to_csv</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Iterates through all .xml files (generated by labelImg) in a given directory and combines</span></span><br><span class="line"><span class="string">    them in a single Pandas dataframe.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    path : str</span></span><br><span class="line"><span class="string">        The path containing the .xml files</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    Pandas DataFrame</span></span><br><span class="line"><span class="string">        The produced dataframe</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">&#x27;/*.xml&#x27;</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">            value = (root.find(<span class="string">&#x27;filename&#x27;</span>).text,</span><br><span class="line">                     <span class="built_in">int</span>(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">0</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">1</span>].text),</span><br><span class="line">                     member[<span class="number">0</span>].text,</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;width&#x27;</span>, <span class="string">&#x27;height&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;xmin&#x27;</span>, <span class="string">&#x27;ymin&#x27;</span>, <span class="string">&#x27;xmax&#x27;</span>, <span class="string">&#x27;ymax&#x27;</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">class_text_to_int</span>(<span class="params">row_label</span>):</span><br><span class="line">    <span class="keyword">return</span> label_map_dict[row_label]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split</span>(<span class="params">df, group</span>):</span><br><span class="line">    data = namedtuple(<span class="string">&#x27;data&#x27;</span>, [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;object&#x27;</span>])</span><br><span class="line">    gb = df.groupby(group)</span><br><span class="line">    <span class="keyword">return</span> [data(filename, gb.get_group(x)) <span class="keyword">for</span> filename, x <span class="keyword">in</span> <span class="built_in">zip</span>(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_tf_example</span>(<span class="params">group, path</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(os.path.join(path, <span class="string">&#x27;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(group.filename)), <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        encoded_jpg = fid.read()</span><br><span class="line">    encoded_jpg_io = io.BytesIO(encoded_jpg)</span><br><span class="line">    image = Image.<span class="built_in">open</span>(encoded_jpg_io)</span><br><span class="line">    width, height = image.size</span><br><span class="line"></span><br><span class="line">    filename = group.filename.encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">    image_format = <span class="string">b&#x27;jpg&#x27;</span></span><br><span class="line">    xmins = []</span><br><span class="line">    xmaxs = []</span><br><span class="line">    ymins = []</span><br><span class="line">    ymaxs = []</span><br><span class="line">    classes_text = []</span><br><span class="line">    classes = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> group.<span class="built_in">object</span>.iterrows():</span><br><span class="line">        xmins.append(row[<span class="string">&#x27;xmin&#x27;</span>] / width)</span><br><span class="line">        xmaxs.append(row[<span class="string">&#x27;xmax&#x27;</span>] / width)</span><br><span class="line">        ymins.append(row[<span class="string">&#x27;ymin&#x27;</span>] / height)</span><br><span class="line">        ymaxs.append(row[<span class="string">&#x27;ymax&#x27;</span>] / height)</span><br><span class="line">        classes_text.append(row[<span class="string">&#x27;class&#x27;</span>].encode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        classes.append(class_text_to_int(row[<span class="string">&#x27;class&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        <span class="string">&#x27;image/height&#x27;</span>: dataset_util.int64_feature(height),</span><br><span class="line">        <span class="string">&#x27;image/width&#x27;</span>: dataset_util.int64_feature(width),</span><br><span class="line">        <span class="string">&#x27;image/filename&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/source_id&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/encoded&#x27;</span>: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        <span class="string">&#x27;image/format&#x27;</span>: dataset_util.bytes_feature(image_format),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmin&#x27;</span>: dataset_util.float_list_feature(xmins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmax&#x27;</span>: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymin&#x27;</span>: dataset_util.float_list_feature(ymins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymax&#x27;</span>: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/class/text&#x27;</span>: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        <span class="string">&#x27;image/object/class/label&#x27;</span>: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    <span class="keyword">return</span> tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">_</span>):</span><br><span class="line"></span><br><span class="line">    writer = tf.python_io.TFRecordWriter(args.output_path)</span><br><span class="line">    path = os.path.join(args.image_dir)</span><br><span class="line">    examples = xml_to_csv(args.xml_dir)</span><br><span class="line">    grouped = split(examples, <span class="string">&#x27;filename&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> grouped:</span><br><span class="line">        tf_example = create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.SerializeToString())</span><br><span class="line">    writer.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Successfully created the TFRecord file: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.output_path))</span><br><span class="line">    <span class="keyword">if</span> args.csv_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        examples.to_csv(args.csv_path, index=<span class="literal">None</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Successfully created the CSV file: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.csv_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>

<p>具体使用方法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create train data:</span></span><br><span class="line">python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create test data:</span></span><br><span class="line">python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/test -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/test.record</span><br><span class="line"></span><br><span class="line"><span class="comment"># For example</span></span><br><span class="line"><span class="comment"># python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/train -l C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/train.record</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/test -l C:/Users/sglvladi/Documents/Tensorflow2/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/test.record</span></span><br></pre></td></tr></table></figure>

<p>之后会在training_demo/annotations文件夹下生成test.record 和 train.record 即为转换成功。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-05-28.png"></p>
<h3 id="下载预训练模型"><a href="#下载预训练模型" class="headerlink" title="下载预训练模型"></a>下载预训练模型</h3><p>这里我以ssd_inception_v2为例。</p>
<blockquote>
<p><strong>下载预训练模型这里需要注意一点：tf版本。<br>如果你是tf1.x<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md">就进入进行下载</a>。<br>如果你是tf2.x<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">就进入进行下载</a>。</strong></p>
</blockquote>
<p>将下载好的模型解压到<span id="inline-green"> pre-trained-models </span>下。形式如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">training_demo/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">...</span></span><br><span class="line"><span class="string">├─</span> <span class="string">pre-trained-models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">ssd_inception_v2_coco_2018_01_28/</span></span><br><span class="line"><span class="string">│</span>     <span class="string">├─</span> <span class="string">saved_model/</span></span><br><span class="line"><span class="string">│</span> 	  <span class="string">├─</span> <span class="string">pipeline.config</span></span><br><span class="line"><span class="string">│</span>     <span class="string">└─</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h3 id="设置训练Pipeline"><a href="#设置训练Pipeline" class="headerlink" title="设置训练Pipeline"></a>设置训练Pipeline</h3><p>首先在training_demo/models下创建文件夹my_ssd_inception_v2;</p>
<p>然后复制training_demo/pre-trained-models/ssd_inception_v2_coco_2018_01_28/pipeline.config</p>
<p>到training_demo/models/my_ssd_inception_v2；</p>
<p>接着打开training_demo/models/my_ssd_inception_v2下的<span id="inline-green"> pipeline.config </span>；</p>
<figure class="highlight yaml"><figcaption><span>/home/xxx/TensorFlow/workspace/training_demo/models/my_ssd_inception_v2/pipeline.config</span></figcaption><table><tr><td class="code"><pre><span class="line">  <span class="string">ssd</span> &#123;</span><br><span class="line">    <span class="attr">num_classes:</span> <span class="number">5</span>                                                                                 <span class="comment">##########更改1</span></span><br><span class="line">    <span class="string">image_resizer</span> &#123;</span><br><span class="line">      <span class="string">fixed_shape_resizer</span> &#123;</span><br><span class="line">        <span class="attr">height:</span> <span class="number">300</span></span><br><span class="line">        <span class="attr">width:</span> <span class="number">300</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">feature_extractor</span> &#123;</span><br><span class="line">      <span class="attr">type:</span> <span class="string">&quot;ssd_inception_v2&quot;</span></span><br><span class="line">      <span class="attr">depth_multiplier:</span> <span class="number">1.0</span></span><br><span class="line">      <span class="attr">min_depth:</span> <span class="number">16</span></span><br><span class="line">      <span class="string">conv_hyperparams</span> &#123;</span><br><span class="line">        <span class="string">regularizer</span> &#123;</span><br><span class="line">          <span class="string">l2_regularizer</span> &#123;</span><br><span class="line">            <span class="attr">weight:</span> <span class="number">3.99999989895e-05</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="string">initializer</span> &#123;</span><br><span class="line">          <span class="string">truncated_normal_initializer</span> &#123;</span><br><span class="line">            <span class="attr">mean:</span> <span class="number">0.0</span></span><br><span class="line">            <span class="attr">stddev:</span> <span class="number">0.0299999993294</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="attr">activation:</span> <span class="string">RELU_6</span></span><br><span class="line">        <span class="string">batch_norm</span> &#123;</span><br><span class="line">          <span class="attr">decay:</span> <span class="number">0.999700009823</span></span><br><span class="line">          <span class="attr">center:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">scale:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">epsilon:</span> <span class="number">0.0010000000475</span></span><br><span class="line">          <span class="attr">train:</span> <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="attr">override_base_feature_extractor_hyperparams:</span> <span class="literal">true</span>                                            <span class="comment">##########更改2</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">box_coder</span> &#123;</span><br><span class="line">      <span class="string">faster_rcnn_box_coder</span> &#123;</span><br><span class="line">        <span class="attr">y_scale:</span> <span class="number">10.0</span></span><br><span class="line">        <span class="attr">x_scale:</span> <span class="number">10.0</span></span><br><span class="line">        <span class="attr">height_scale:</span> <span class="number">5.0</span></span><br><span class="line">        <span class="attr">width_scale:</span> <span class="number">5.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">matcher</span> &#123;</span><br><span class="line">      <span class="string">argmax_matcher</span> &#123;</span><br><span class="line">        <span class="attr">matched_threshold:</span> <span class="number">0.5</span></span><br><span class="line">        <span class="attr">unmatched_threshold:</span> <span class="number">0.5</span></span><br><span class="line">        <span class="attr">ignore_thresholds:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">negatives_lower_than_unmatched:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">force_match_for_each_row:</span> <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">similarity_calculator</span> &#123;</span><br><span class="line">      <span class="string">iou_similarity</span> &#123;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">box_predictor</span> &#123;</span><br><span class="line">      <span class="string">convolutional_box_predictor</span> &#123;</span><br><span class="line">        <span class="string">conv_hyperparams</span> &#123;</span><br><span class="line">          <span class="string">regularizer</span> &#123;</span><br><span class="line">            <span class="string">l2_regularizer</span> &#123;</span><br><span class="line">              <span class="attr">weight:</span> <span class="number">3.99999989895e-05</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="string">initializer</span> &#123;</span><br><span class="line">            <span class="string">truncated_normal_initializer</span> &#123;</span><br><span class="line">              <span class="attr">mean:</span> <span class="number">0.0</span></span><br><span class="line">              <span class="attr">stddev:</span> <span class="number">0.0299999993294</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="attr">activation:</span> <span class="string">RELU_6</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="attr">min_depth:</span> <span class="number">0</span></span><br><span class="line">        <span class="attr">max_depth:</span> <span class="number">0</span></span><br><span class="line">        <span class="attr">num_layers_before_predictor:</span> <span class="number">0</span></span><br><span class="line">        <span class="attr">use_dropout:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">dropout_keep_probability:</span> <span class="number">0.800000011921</span></span><br><span class="line">        <span class="attr">kernel_size:</span> <span class="number">3</span></span><br><span class="line">        <span class="attr">box_code_size:</span> <span class="number">4</span></span><br><span class="line">        <span class="attr">apply_sigmoid_to_scores:</span> <span class="literal">false</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">anchor_generator</span> &#123;</span><br><span class="line">      <span class="string">ssd_anchor_generator</span> &#123;</span><br><span class="line">        <span class="attr">num_layers:</span> <span class="number">6</span></span><br><span class="line">        <span class="attr">min_scale:</span> <span class="number">0.20000000298</span></span><br><span class="line">        <span class="attr">max_scale:</span> <span class="number">0.949999988079</span></span><br><span class="line">        <span class="attr">aspect_ratios:</span> <span class="number">1.0</span></span><br><span class="line">        <span class="attr">aspect_ratios:</span> <span class="number">2.0</span></span><br><span class="line">        <span class="attr">aspect_ratios:</span> <span class="number">0.5</span></span><br><span class="line">        <span class="attr">aspect_ratios:</span> <span class="number">3.0</span></span><br><span class="line">        <span class="attr">aspect_ratios:</span> <span class="number">0.333299994469</span></span><br><span class="line">        <span class="attr">reduce_boxes_in_lowest_layer:</span> <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">post_processing</span> &#123;</span><br><span class="line">      <span class="string">batch_non_max_suppression</span> &#123;</span><br><span class="line">        <span class="attr">score_threshold:</span> <span class="number">0.300000011921</span></span><br><span class="line">        <span class="attr">iou_threshold:</span> <span class="number">0.600000023842</span></span><br><span class="line">        <span class="attr">max_detections_per_class:</span> <span class="number">100</span></span><br><span class="line">        <span class="attr">max_total_detections:</span> <span class="number">100</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="attr">score_converter:</span> <span class="string">SIGMOID</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="attr">normalize_loss_by_num_matches:</span> <span class="literal">true</span></span><br><span class="line">    <span class="string">loss</span> &#123;</span><br><span class="line">      <span class="string">localization_loss</span> &#123;</span><br><span class="line">        <span class="string">weighted_smooth_l1</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="string">classification_loss</span> &#123;</span><br><span class="line">        <span class="string">weighted_sigmoid</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="string">hard_example_miner</span> &#123;</span><br><span class="line">        <span class="attr">num_hard_examples:</span> <span class="number">3000</span></span><br><span class="line">        <span class="attr">iou_threshold:</span> <span class="number">0.990000009537</span></span><br><span class="line">        <span class="attr">loss_type:</span> <span class="string">CLASSIFICATION</span></span><br><span class="line">        <span class="attr">max_negatives_per_positive:</span> <span class="number">3</span></span><br><span class="line">        <span class="attr">min_negatives_per_image:</span> <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="attr">classification_weight:</span> <span class="number">1.0</span></span><br><span class="line">      <span class="attr">localization_weight:</span> <span class="number">1.0</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">train_config</span> &#123;</span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">24</span>                                                                                   <span class="comment">##########更改3</span></span><br><span class="line">  <span class="string">data_augmentation_options</span> &#123;</span><br><span class="line">    <span class="string">random_horizontal_flip</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">data_augmentation_options</span> &#123;</span><br><span class="line">    <span class="string">ssd_random_crop</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="string">optimizer</span> &#123;</span><br><span class="line">    <span class="string">rms_prop_optimizer</span> &#123;</span><br><span class="line">      <span class="string">learning_rate</span> &#123;</span><br><span class="line">        <span class="string">exponential_decay_learning_rate</span> &#123;</span><br><span class="line">          <span class="attr">initial_learning_rate:</span> <span class="number">0.00400000018999</span></span><br><span class="line">          <span class="attr">decay_steps:</span> <span class="number">800720</span></span><br><span class="line">          <span class="attr">decay_factor:</span> <span class="number">0.949999988079</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="attr">momentum_optimizer_value:</span> <span class="number">0.899999976158</span></span><br><span class="line">      <span class="attr">decay:</span> <span class="number">0.899999976158</span></span><br><span class="line">      <span class="attr">epsilon:</span> <span class="number">1.0</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="attr">fine_tune_checkpoint:</span> <span class="string">&quot;pre-trained-models/ssd_inception_v2_coco_2018_01_28/model.ckpt&quot;</span>            <span class="comment">##########更改4</span></span><br><span class="line">  <span class="attr">from_detection_checkpoint:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">num_steps:</span> <span class="number">200000</span>                                                                                 <span class="comment">##########更改5</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">train_input_reader</span> &#123;</span><br><span class="line">  <span class="attr">label_map_path:</span> <span class="string">&quot;annotations/label_map.pbtxt&quot;</span>                                                     <span class="comment">##########更改6</span></span><br><span class="line">  <span class="string">tf_record_input_reader</span> &#123;</span><br><span class="line">    <span class="attr">input_path:</span> <span class="string">&quot;annotations/train.record&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="string">eval_config</span> &#123;</span><br><span class="line">  <span class="attr">num_examples:</span> <span class="number">8000</span></span><br><span class="line">  <span class="attr">max_evals:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">use_moving_averages:</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">eval_input_reader</span> &#123;</span><br><span class="line">  <span class="attr">label_map_path:</span> <span class="string">&quot;annotations/label_map.pbtxt&quot;</span>                                                    <span class="comment">##########更改7</span></span><br><span class="line">  <span class="attr">shuffle:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">num_readers:</span> <span class="number">1</span></span><br><span class="line">  <span class="string">tf_record_input_reader</span> &#123;</span><br><span class="line">    <span class="attr">input_path:</span> <span class="string">&quot;annotations/test.record&quot;</span>                                                          <span class="comment">##########更改8</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h3><blockquote>
<p><strong>tf1.x版本的复制TensorFlow/models/research/object_detection/model_main.py到training_demo文件夹<br>tf2.x版本的复制TensorFlow/models/research/object_detection/model_main_tf2.py到training_demo文件夹</strong></p>
</blockquote>
<p>定位到training_demo文件夹，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python model_main.py --model_dir=models/my_ssd_inception_v2 --pipeline_config_path=models/my_ssd_inception_v2/pipeline.config</span><br></pre></td></tr></table></figure>

<p>如果遇到如下error,则是忘了加上override_base_feature_extractor_hyperparams: true    #####这个位置加上这句#####</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-05-36.png"></p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-05-59.png"><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-09-45.png"></p>
<p>训练成功则如下：</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-09-01%2014-19-16.png"></p>
]]></content>
      <categories>
        <category>Ubuntu下TensorFlow Object Detection API实战</category>
      </categories>
      <tags>
        <tag>TensorFlow Object Detection API</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu20.04下成功配置TensorFlow Object Detection API 教程</title>
    <url>/post/1a71c089.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>TensorFlow Object Detection API 作为目前开源的接口，集成了当下比较主流的一些网络模型，并且作了系统性的划分，所以适合快速上手各个算法模型，在使用之前，必须按照官方指导配置好环境，具体参考本篇内容完成配置</p>

</blockquote>

<span id="more"></span>

<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/1a71c089.html"><font color="red">Ubuntu20.04下成功配置TensorFlow Object Detection API 教程</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/bb2ec196.html"><font color="blue">Ubuntu下用TensorFlow Object Detection API训练自己的数据</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/e88b7107.html"><font color="blue">Ubuntu下用TensorFlow Object Detection API测试自己的数据</font></a> </p>
<h3 id="新建一个名为TensorFlow的文件夹"><a href="#新建一个名为TensorFlow的文件夹" class="headerlink" title="新建一个名为TensorFlow的文件夹"></a>新建一个名为TensorFlow的文件夹</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> TensorFlow</span><br></pre></td></tr></table></figure>


<h3 id="打开终端，cd进入TensorFlow"><a href="#打开终端，cd进入TensorFlow" class="headerlink" title="打开终端，cd进入TensorFlow"></a>打开终端，cd进入TensorFlow</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> TensorFlow</span><br></pre></td></tr></table></figure>

<h3 id="克隆TensorFlow-Models"><a href="#克隆TensorFlow-Models" class="headerlink" title="克隆TensorFlow Models"></a>克隆TensorFlow Models</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/tensorflow/models.git</span><br></pre></td></tr></table></figure>

<p>现在你的TensorFlow文件夹应该如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">models/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line">   <span class="string">└──</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h3 id="配置Protobuf"><a href="#配置Protobuf" class="headerlink" title="配置Protobuf"></a>配置Protobuf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install protobuf</span><br><span class="line"><span class="built_in">cd</span> models/research/</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>

<h3 id="配置COCO-API"><a href="#配置COCO-API" class="headerlink" title="配置COCO API"></a>配置COCO API</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/cocodataset/cocoapi.git</span><br><span class="line"><span class="built_in">cd</span> cocoapi/PythonAPI</span><br><span class="line">make</span><br><span class="line"><span class="built_in">cp</span> -r pycocotools &lt;PATH_TO_TF&gt;/TensorFlow/models/research/</span><br></pre></td></tr></table></figure>

<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2016-04-34-1598871276938.png"></p>
<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2016-05-05-1598871293831.png"></p>
<h3 id="安装Object-Detection-API"><a href="#安装Object-Detection-API" class="headerlink" title="安装Object Detection API"></a>安装Object Detection API</h3><p>这里需要注意一点，先要确认你的tensorflow版本，我的是tf1.x，所以这里我要拷贝的是tf1的setup,如果你的是tf2.x,那就拷贝tf2的setup.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#确保你当前在TensorFlow/models/research/文件夹下</span></span><br><span class="line"><span class="built_in">cp</span> object_detection/packages/tf2/setup.py .</span><br><span class="line">python -m pip install .</span><br></pre></td></tr></table></figure>

<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2016-05-18-1598871310225.png"></p>
<h3 id="测试Object-Detection-API是否安装成功"><a href="#测试Object-Detection-API是否安装成功" class="headerlink" title="测试Object Detection API是否安装成功"></a>测试Object Detection API是否安装成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python object_detection/builders/model_builder_tf1_test.py</span><br></pre></td></tr></table></figure>

<p>注意这里也是要和你自己的tensorflow版本对上。</p>
<p>测试通过则说明安装无误。</p>
<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2018-03-06-1598871325137.png"></p>
]]></content>
      <categories>
        <category>Ubuntu下TensorFlow Object Detection API实战</category>
      </categories>
      <tags>
        <tag>TensorFlow Object Detection API</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署一</title>
    <url>/post/b99b85b3.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本系列主要介绍如何在本地单卡运行chatglm大模型，并实现一些有趣的应用，实践过程中出现的问题解决方法等都进行记录和总结。</p>

</blockquote>
<span id="more"></span>

<h2 id="1-环境创建"><a href="#1-环境创建" class="headerlink" title="1. 环境创建"></a>1. 环境创建</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/THUDM/ChatGLM-6B.git</span><br><span class="line"><span class="built_in">cd</span> ChatGLM-6B</span><br><span class="line">conda create --name chatglm python=3.10 <span class="comment">#3.12会出现奇奇怪怪的问题，这里建议还是用3.10</span></span><br><span class="line">conda activate chatglm</span><br><span class="line">pip install -r requirements.txt  -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<p>这里注意可能会遇到ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">      running build_ext</span><br><span class="line">      running build_rust</span><br><span class="line">      error: can<span class="string">&#x27;t find Rust compiler</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      To update pip, run:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          pip install --upgrade pip</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      and then retry package installation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.</span></span><br><span class="line"><span class="string">      [end of output]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  note: This error originates from a subprocess, and is likely not a problem with pip.</span></span><br><span class="line"><span class="string">  ERROR: Failed building wheel for tokenizers</span></span><br><span class="line"><span class="string">Failed to build tokenizers</span></span><br><span class="line"><span class="string">ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects</span></span><br></pre></td></tr></table></figure>

<p>原因是需要安装rust.</p>
<p>安装链接参考<a href="https://blog.csdn.net/md521/article/details/108110676">https://blog.csdn.net/md521/article/details/108110676</a></p>
<p>在添加环境变量时注意默认安装路径是</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">C:\Users\XXXX\.cargo\bin</span><br></pre></td></tr></table></figure>

<p>添加环境变量后新开promt检查rust是否安装成功</p>
<h2 id="2-chatglm-6b-int4"><a href="#2-chatglm-6b-int4" class="headerlink" title="2. chatglm-6b-int4"></a>2. chatglm-6b-int4</h2><p>在<a href="https://huggingface.co/THUDM/chatglm-6b-int4/tree/main">huggingface</a>下载好模型文件存放在文件夹</p>
<p>跑着试一下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;chatglm-6b-int4&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&quot;chatglm-6b-int4&quot;</span>, trust_remote_code=<span class="literal">True</span>).quantize(<span class="number">4</span>).half().cuda()</span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">&quot;你好&quot;</span>, history=[])</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">&quot;晚上睡不着应该怎么办&quot;</span>, history=history)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/image-20240315162242918.png" alt="image-20240315162242918"></p>
<h2 id="3-结果展示"><a href="#3-结果展示" class="headerlink" title="3. 结果展示"></a>3. 结果展示</h2><p>可以换着花样把输入给模型，对比输出的变化</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-15%20163935.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-15_163818.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-15_164619.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-15%20164619.png" alt="屏幕截图 2024-03-15 164619"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-15%20164613.png" alt="屏幕截图 2024-03-15 164613"></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/IronSpiderMan/MachineLearningPractice/blob/main/chatglm_qa%2Fchatglm_document_qa_READM.md">https://github.com/IronSpiderMan/MachineLearningPractice/blob/main/chatglm_qa%2Fchatglm_document_qa_READM.md</a></li>
<li><a href="https://blog.csdn.net/qq_40968179/article/details/128996692">https://blog.csdn.net/qq_40968179/article/details/128996692</a></li>
</ol>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署三</title>
    <url>/post/c0473d17.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就api形式调用大模型以及本地文档向量化的步骤详细介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="api调用chatglm"><a href="#api调用chatglm" class="headerlink" title="api调用chatglm"></a>api调用chatglm</h2><p>为了配合显存，需要调整api.py模型加载部分为int4量化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># model = AutoModel.from_pretrained(&quot;THUDM/chatglm-6b&quot;, trust_remote_code=True).half().cuda()</span></span><br><span class="line"> <span class="comment"># 丐版</span></span><br><span class="line"> model = AutoModel.from_pretrained(<span class="string">&quot;chatglm-6b&quot;</span>, trust_remote_code=<span class="literal">True</span>).quantize(<span class="number">4</span>).half().cuda()</span><br></pre></td></tr></table></figure>

<h3 id="启服务"><a href="#启服务" class="headerlink" title="启服务"></a>启服务</h3><p>这样就代表启动成功</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20152252.png"></p>
<h3 id="调用aip"><a href="#调用aip" class="headerlink" title="调用aip"></a>调用aip</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">heade_ = &#123;<span class="string">&quot;Content-Type&quot;</span>:<span class="string">&quot;application/json;charset=utf-8&quot;</span>&#125;</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">promt, history</span>):</span><br><span class="line">    resq = requests.post(</span><br><span class="line">        url=<span class="string">&#x27;http://127.0.0.1:8000&#x27;</span>,</span><br><span class="line">        json = &#123;<span class="string">&quot;prompt&quot;</span>:promt, <span class="string">&quot;history&quot;</span>:history&#125;,</span><br><span class="line">        headers= heade_</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> resq.json()[<span class="string">&quot;response&quot;</span>], resq.json()[<span class="string">&quot;history&quot;</span>]</span><br><span class="line"></span><br><span class="line">history = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    response, history =  chat(<span class="built_in">input</span>(<span class="string">&quot;Q: &quot;</span>), history)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;A: &quot;</span>, response)</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20152648.png"></p>
<p>也可以用curl的方式调用(windows下写法)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -X POST <span class="string">&quot;http://127.0.0.1:8000&quot;</span> -H <span class="string">&quot;Content-Type: application/json&quot;</span> -d <span class="string">&quot;&#123;\&quot;prompt\&quot;: \&quot;你好\&quot;, \&quot;history\&quot;: []&#125;&quot;</span></span><br></pre></td></tr></table></figure>

<p>postman调用方法</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20155007.png"></p>
<h2 id="本地文档向量化"><a href="#本地文档向量化" class="headerlink" title="本地文档向量化"></a>本地文档向量化</h2><p>这里选择下载了甄嬛传和盗墓笔记的txt</p>
<h3 id="文档格式统一"><a href="#文档格式统一" class="headerlink" title="文档格式统一"></a>文档格式统一</h3><p>向量化txt用的是langchain.document_loaders.directory import DirectoryLoader函数，使用中发现非utf-8文档load失败，所以转换思路，按照文件写了一些非utf-8文档转换为utf-8的函数，在源文档基础上改写，新内容覆盖原始文档内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">encode_out = &#x27;utf-8&#x27;</span><br><span class="line">dirpath = &#x27;own\\books&#x27;</span><br><span class="line"></span><br><span class="line">for book in os.listdir(dirpath):</span><br><span class="line">    with open(&quot;&#123;&#125;/&#123;&#125;&quot;.format(dirpath, book), &#x27;rb&#x27;) as f:</span><br><span class="line">        data = f.read()</span><br><span class="line">        encoding_type = chardet.detect(data)[&quot;encoding&quot;] # 获取输入文档的编码类型</span><br><span class="line">        if encoding_type != encode_out:</span><br><span class="line">            with open(&quot;&#123;&#125;/&#123;&#125;&quot;.format(dirpath, book), mode=&#x27;wb+&#x27;) as fo:</span><br><span class="line">                fo.write(data.decode(encoding_type,&#x27;ignore&#x27;).encode(encode_out))</span><br><span class="line">                fo.close()</span><br></pre></td></tr></table></figure>

<p>另外说一下我用下面这两种设置方式都没有成功，有没有懂得大佬指点一二。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">from langchain.document_loaders.directory import DirectoryLoader</span><br><span class="line">DirectoryLoader(</span><br><span class="line">    silent_errors=True</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">from langchain.document_loaders.text import TextLoader</span><br><span class="line">TextLoader(</span><br><span class="line">    autodetect_encoding=True</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="几种有趣的文档加载方式"><a href="#几种有趣的文档加载方式" class="headerlink" title="几种有趣的文档加载方式"></a>几种有趣的文档加载方式</h3><p><a href="https://python.langchain.com/docs/integrations/document_loaders">官网</a>提供了各式各样的加载文档的方式，其中也有很多有意思的接口，比如</p>
<h4 id="BiliBili"><a href="#BiliBili" class="headerlink" title="BiliBili"></a><a href="https://python.langchain.com/docs/integrations/document_loaders/bilibili">BiliBili</a></h4><p>可以提取视频字幕，有的原始视频没有字幕，这个方法也可以用</p>
<p>首先需要安装bilibili-api-python</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install bilibili-api-python</span><br></pre></td></tr></table></figure>

<p>其次使用方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders.bilibili <span class="keyword">import</span> BiliBiliLoader</span><br><span class="line"></span><br><span class="line">loader = BiliBiliLoader([<span class="string">&#x27;https://www.bilibili.com/video/BV1t8411y7fp/?p=4&amp;spm_id_from=pageDriver&amp;vd_source=9bfa62da16aae5e7da38cd1197e6acc7&#x27;</span>])</span><br><span class="line">loader = loader.load()</span><br><span class="line">split_docs = RecursiveText.split_documents(loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(split_docs))</span><br></pre></td></tr></table></figure>

<p>这里需要注意两个问题：</p>
<p>a.修正C:\Users\xxx\envs\chatglm\Lib\site-packages\langchain_community\document_loaders\bilibili.py</p>
<p>这里具体文件位置根据你自己的实际情况来有，总共有三处需要需改的地方</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##### 修改一 在开头定义credential</span></span><br><span class="line">from bilibili_api import Credential</span><br><span class="line">sessdata = <span class="string">&quot;your sessdata&quot;</span></span><br><span class="line">bili_jct = <span class="string">&quot;your bili_jct&quot;</span></span><br><span class="line">buvid3 = <span class="string">&quot;your buvid3&quot;</span></span><br><span class="line">credential = Credential(sessdata=sessdata, bili_jct=bili_jct, buvid3=buvid3)</span><br><span class="line"><span class="comment">##### 修改二、三 _get_bilibili_subs_and_info内两处video.Video增加内容</span></span><br><span class="line">        <span class="keyword">if</span> bvid is not None:</span><br><span class="line">            v = video.Video(bvid=bvid.group(),  credential=credential)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            aid = re.search(r<span class="string">&quot;av[0-9]+&quot;</span>, url)</span><br><span class="line">            <span class="keyword">if</span> aid is not None:</span><br><span class="line">                try:</span><br><span class="line">                    v = video.Video(aid=int(aid.group()[2:]), credential=credential)</span><br><span class="line">                except AttributeError:</span><br><span class="line">                    raise ValueError(f<span class="string">&quot;&#123;url&#125; is not bilibili url.&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                raise ValueError(f<span class="string">&quot;&#123;url&#125; is not bilibili url.&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这样可以避免之后调用api报错 Credential 类未提供 sessdata 或者为空。</p>
<p>sessdata、bili_jct以及buvid3的在goole chrome获取方式加下图</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20101936.png"></p>
<p>这里展示一下调用api的效果</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20105210.png"></p>
<p>可以看出，字幕基本是提取出来了。<font face="黑体" color="red" size="5">这个接口使用的时候一定注意要清除系统代理。</font></p>
<h4 id="Images"><a href="#Images" class="headerlink" title="Images"></a><a href="https://python.langchain.com/docs/integrations/document_loaders/image">Images</a></h4><p>首先需要安装依赖</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install unstructured_inference</span><br></pre></td></tr></table></figure>

<p>以及单独安装<a href="https://digi.bib.uni-mannheim.de/tesseract/">tesseract-ocr</a></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20114522.png"></p>
<p>并添加环境变量</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20112538.png"></p>
<p>使用方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">filepath = <span class="string">&#x27;own/2.png&#x27;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders.image <span class="keyword">import</span> UnstructuredImageLoader</span><br><span class="line">loader = UnstructuredImageLoader(filepath)</span><br><span class="line">data = loader.load()</span><br></pre></td></tr></table></figure>

<p>也是需要更改一个地方才能实现调用</p>
<p>C:\Users\xxx\envs\chatglm\Lib\site-packages\unstructured_pytesseract\pytesseract.py</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20114821.png"></p>
<p>这里因为调用的是unstructured_pytesseract,所以修改的unstructured_pytesseract下的pytesseract，还有一个pytesseract.py是C:\Users\xxx\envs\chatglm\Lib\site-packages\pytesseract\pytesseract.py，也可以如法炮制，以便之后使用正常。</p>
<p>看一下加载图像后识别图像的文字效果如何</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20113924.png"></p>
<p>英文识别效果看起来可以，再看看中文如何识别</p>
<p>关于pytesseract使用的时候发现一些有意思的地方</p>
<p><font face="黑体" color="red" size="5">一般画图的时候，默认左上角为坐标系起点，然而pytesseract的接口返回结果是以左下角为坐标系原点，所以不注意的时候会发现画的框的位置是错的。</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw,ImageFont</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> pytesseract</span><br><span class="line"></span><br><span class="line">filepath = <span class="string">&#x27;own/2.png&#x27;</span></span><br><span class="line">im = cv2.imread(filepath, cv2.IMREAD_COLOR)</span><br><span class="line"></span><br><span class="line">font = ImageFont.truetype(font=<span class="string">&quot;simsun.ttc&quot;</span>, size=<span class="number">18</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">img = Image.fromarray(im)</span><br><span class="line">draw = ImageDraw.Draw(img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">text3 = pytesseract.image_to_boxes(im, output_type=Output.STRING, lang=<span class="string">&#x27;chi_sim&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(text3)</span><br><span class="line">h, w = im.shape[:-<span class="number">1</span>]</span><br><span class="line">outlist =  text3.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> outlist:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(i)==<span class="number">0</span>:</span><br><span class="line">		<span class="keyword">continue</span></span><br><span class="line">	(s, x0, y0, x1, y1, conf) = i.split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">	x0, y0, x1, y1, conf = <span class="built_in">int</span>(x0), h-<span class="built_in">int</span>(y0), <span class="built_in">int</span>(x1), h-<span class="built_in">int</span>(y1), <span class="built_in">float</span>(conf)</span><br><span class="line">	draw.text((x0, y1 - <span class="number">20</span>), s, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), font=font) </span><br><span class="line">	draw.rectangle([(x0, y1), (x1, y0)], outline=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">	outimage = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)</span><br><span class="line">	cv2.imshow(<span class="string">&quot;output&quot;</span>, outimage)</span><br><span class="line">	cv2.imwrite(<span class="string">&#x27;res.jpg&#x27;</span>, outimage)</span><br><span class="line">	cv2.waitKey(<span class="number">0</span>) </span><br><span class="line">	cv2.destroyAllWindows() </span><br></pre></td></tr></table></figure>

<p>改成随机颜色</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">color = <span class="built_in">tuple</span>(np.random.randint(<span class="number">0</span>, <span class="number">255</span>, <span class="number">3</span>, dtype=np.int32))</span><br></pre></td></tr></table></figure>

<p>看看文字提取效果</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/res.jpg"></p>
<p><font face="黑体" color="red" size="5">文字大致上没有问题，提取的位置多多少少会有些偏差。</font></p>
<p>还有一种是按照词的结果返回，即一个框对应多个字词的样式。</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/res1.jpg"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 识别出的每块框画在图像上    </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chunk_single</span>():</span><br><span class="line">    tess_text = pytesseract.image_to_data(im, output_type=Output.DICT, lang=<span class="string">&#x27;chi_sim&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tess_text[<span class="string">&#x27;text&#x27;</span>])):</span><br><span class="line">        word_len = <span class="built_in">len</span>(tess_text[<span class="string">&#x27;text&#x27;</span>][i])</span><br><span class="line">        <span class="keyword">if</span> word_len &gt; <span class="number">0</span>:</span><br><span class="line">            (x, y, w, h) = (tess_text[<span class="string">&#x27;left&#x27;</span>][i], tess_text[<span class="string">&#x27;top&#x27;</span>][i], tess_text[<span class="string">&#x27;width&#x27;</span>][i], tess_text[<span class="string">&#x27;height&#x27;</span>][i])</span><br><span class="line">            color = <span class="built_in">tuple</span>(np.random.randint(<span class="number">0</span>, <span class="number">255</span>, <span class="number">3</span>, dtype=np.int32))    </span><br><span class="line">            draw.text((x, y - <span class="number">20</span>), tess_text[<span class="string">&#x27;text&#x27;</span>][i], color, font=font)</span><br><span class="line">            draw.rectangle([(x, y), (x + w, y + h)], outline=color)</span><br><span class="line">            outimage = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)</span><br><span class="line">            cv2.imwrite(<span class="string">&#x27;res1.jpg&#x27;</span>, outimage)</span><br></pre></td></tr></table></figure>

<p><font face="黑体" color="red" size="5">pytesseract.image_to_data的返回结果是不用做坐标转换的。</font></p>
<h4 id="Subtitle"><a href="#Subtitle" class="headerlink" title="Subtitle"></a><a href="https://python.langchain.com/docs/integrations/document_loaders/subtitle">Subtitle</a></h4><p>字幕文件内容提取，以电子榨菜甄嬛传为例</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20163149.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20164123.png"></p>
<p><a href="https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf">PDF</a></p>
<p>首先需要安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install pymupdf</span><br></pre></td></tr></table></figure>

<p>使用方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loader = PyMuPDFLoader(filepath)</span><br></pre></td></tr></table></figure>

<p>提取效果</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20183710.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-19%20184349.png"></p>
<h3 id="文档切块"><a href="#文档切块" class="headerlink" title="文档切块"></a>文档切块</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders.directory <span class="keyword">import</span> DirectoryLoader</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_docs</span>(<span class="params">dirpath</span>):</span><br><span class="line">    loader = DirectoryLoader(dirpath)</span><br><span class="line">    docs = loader.load()</span><br><span class="line">    text_split = CharacterTextSplitter(chunk_size =<span class="number">256</span>, chunk_overlap =<span class="number">10</span> )</span><br><span class="line">    split_docs = text_split.split_documents(docs)</span><br><span class="line">    <span class="keyword">return</span> split_docs</span><br></pre></td></tr></table></figure>

<h4 id="切块方式"><a href="#切块方式" class="headerlink" title="切块方式"></a>切块方式</h4><p>CharacterTextSplitter vs RecursiveCharacterTextSplitter vs Token splitting</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-18%20100138.png"></p>
<p>看的出来RecursiveCharacterTextSplitter 切分方法效果最好，这个方法也是langchain最推荐的。</p>
<h4 id="切块数量"><a href="#切块数量" class="headerlink" title="切块数量"></a>切块数量</h4><p>甄嬛传当没有重复即chunk_overlap=0的时候应该是被切分为5873段</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-18%20084826.png"></p>
<p>现在chunk_overlap =10的时候，切分的数目是6572</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%89/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-18%20085029.png"></p>
<p>数目是对的上的</p>
<h3 id="文档向量化"><a href="#文档向量化" class="headerlink" title="文档向量化"></a>文档向量化</h3><p>主要包含两步：</p>
<p>第一步加载向量化模型；</p>
<p>第二步向量化并存储；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载embedding</span></span><br><span class="line">embedding_model_dict = &#123;</span><br><span class="line">    <span class="string">&quot;ernie-tiny&quot;</span>: <span class="string">&quot;nghuyong/ernie-3.0-nano-zh&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ernie-base&quot;</span>: <span class="string">&quot;nghuyong/ernie-3.0-base-zh&quot;</span>,</span><br><span class="line">    <span class="string">&quot;text2vec&quot;</span>: <span class="string">&quot;GanymedeNil/text2vec-large-chinese&quot;</span>,</span><br><span class="line">    <span class="string">&quot;text2vec2&quot;</span>: <span class="string">&quot;uer/sbert-base-chinese-nli&quot;</span>,</span><br><span class="line">    <span class="string">&quot;text2vec3&quot;</span>: <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_embeding_mode</span>(<span class="params">model_name</span>):</span><br><span class="line">    encode_kwargs = &#123;<span class="string">&quot;normalize_embeddings&quot;</span>:<span class="literal">False</span>&#125;</span><br><span class="line">    model_kwargs = &#123;<span class="string">&quot;device&quot;</span>:<span class="string">&quot;cuda:0&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> HuggingFaceEmbeddings(</span><br><span class="line">        model_name=embedding_model_dict[model_name],</span><br><span class="line">        model_kwargs = model_kwargs,</span><br><span class="line">        encode_kwargs = encode_kwargs</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">store_chroma</span>(<span class="params">doc, persist_directory, embeddings</span>):</span><br><span class="line">    db = Chroma.from_documents(documents=doc, embedding=embeddings, persist_directory=persist_directory)</span><br><span class="line">    db.persist()</span><br><span class="line">    <span class="keyword">return</span> db</span><br></pre></td></tr></table></figure>

<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://github.com/langchain-ai/langchain/issues/14213">Credential 类未提供 sessdata 或者为空</a></p>
<p><a href="https://geekdaxue.co/read/bilibili-api-docs/docs-get-credential.md">获取 Credential 类所需信息</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/448253254">Python OCR工具pytesseract详解</a></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署七</title>
    <url>/post/2092d409.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就chain_type的选择以及promt优化使用以及效果做实验介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="关于chain-type的选择"><a href="#关于chain-type的选择" class="headerlink" title="关于chain_type的选择"></a>关于chain_type的选择</h2><p>这里引用 <a href="https://colab.research.google.com/github/Clarifai/examples/blob/main/Integrations/Langchain/Chains/Retrieval_QA_chain_with_Clarifai_Vectorstore.ipynb#scrollTo=XkLwLsFVLCFf">对比结果</a> 看一下不同chain_type 的效果。 我在本地只有refine和stuff成功了，另外两种使用时遇到了奇奇怪怪的问题，起初以为是中文的问题，但后来验证下来也不是这个原因，具体使用成功的案例还希望有大佬能提供思路一起学习呐。</p>
<h3 id="stuff"><a href="#stuff" class="headerlink" title="stuff"></a>stuff</h3><p>Stuff 是一种简单的方法，它会检索所有相关的文档块，并将其作为一个整体放入提示中，然后发送给LLM 生成响应。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=llm, chain_type=<span class="string">&quot;stuff&quot;</span>, retriever=clarifai_vector_db.as_retriever())</span><br><span class="line">query = <span class="string">&quot;How automobile classes has been segregated with respect to engines?&quot;</span></span><br></pre></td></tr></table></figure>

<p>它能有效地将从向量存储中获取的所有相关块填充到 LLM 模型的上下文中作为提示。这样就能根据用户的查询生成响应。</p>
<p><font face="黑体" color="red" size="5">当上下文较小，需要精确回答问题时，使用 stuff 会更清晰明了。</font></p>
<h3 id="Map-Reduce"><a href="#Map-Reduce" class="headerlink" title="Map Reduce"></a><strong>Map Reduce</strong></h3><p>Map Reduce 链首先对每个文档单独应用 LLM 链（Map 步骤），将链输出视为新文档。然后，它将所有新文档传递给单独的合并文档链，以获得单一输出（Reduce 步骤）。它可以选择先压缩或折叠映射文档，以确保它们适合合并文档链（通常会将它们传递给 LLM）。如有必要，压缩步骤会递归执行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=llm, chain_type=<span class="string">&quot;map_reduce&quot;</span>, retriever=clarifai_vector_db.as_retriever())</span><br><span class="line">query = <span class="string">&quot;How automobile classes has been segregated with respect to engines?&quot;</span></span><br></pre></td></tr></table></figure>

<p>对于相同的查询，我们在使用 Map_reduce 链类型时得到了不同的响应，因为它在每个阶段都进行了汇总，然后才将其传递到最后阶段，因此<font face="黑体" color="red" size="5">对于需要根据汇总回答的文档块数量较多的大型场景，这种链可能是一个很好的用例。</font></p>
<h3 id="Map-Re-rank"><a href="#Map-Re-rank" class="headerlink" title="Map Re-rank"></a><strong>Map Re-rank</strong></h3><p>映射重排会对对每个文档运行初始提示，不仅尝试完成回答，还为其答案的确定程度打分。得分最高的回答将被返回。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=llm, chain_type=<span class="string">&quot;map_rerank&quot;</span>, retriever=clarifai_vector_db.as_retriever())</span><br><span class="line">query = <span class="string">&quot;How automobile classes has been segregated with respect to engines?&quot;</span></span><br></pre></td></tr></table></figure>

<p>从上面的回复中我们可以看到，生成的答案是基于 vectorstore 中排名靠前的内容块摘要，然后将其传递给 LLM 来生成回复。<font face="黑体" color="red" size="5">它可以有效地用于长上下文场景，而且 Top K 较大，文档中可能包含多个主题相同的块。</font></p>
<h2 id="本地部署进阶优化"><a href="#本地部署进阶优化" class="headerlink" title="本地部署进阶优化"></a>本地部署进阶优化</h2><h3 id="输出语言"><a href="#输出语言" class="headerlink" title="输出语言"></a>输出语言</h3><h4 id="promt优化"><a href="#promt优化" class="headerlink" title="promt优化"></a>promt优化</h4><p>这里给出三种优化方式：</p>
<ol>
<li>直接调用model.chat时在搜索相关文本后将所有文档作为提示一遍输入给大模型；</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">from langchain.vectorstores.chroma import Chroma</span><br><span class="line">from langchain.embeddings.huggingface import HuggingFaceEmbeddings</span><br><span class="line">import requests</span><br><span class="line">from jieba.analyse import extract_tags</span><br><span class="line"></span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan_32&#x27;</span>     <span class="comment"># 指定向量库文件夹位置</span></span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>   <span class="comment"># 指定加载embeddding模型</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: False&#125;</span><br><span class="line">embeddings = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">db = Chroma(embedding_function=embeddings, persist_directory=persist_directory)  <span class="comment"># 加载之前创建的向量库文件里的向量数据</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">heade_ = &#123;<span class="string">&quot;Content-Type&quot;</span>:<span class="string">&quot;application/json;charset=utf-8&quot;</span>&#125;</span><br><span class="line">def chat(promt, <span class="built_in">history</span>):</span><br><span class="line">    resq = requests.post(</span><br><span class="line">        url=<span class="string">&#x27;http://127.0.0.1:8000&#x27;</span>,</span><br><span class="line">        json = &#123;<span class="string">&quot;prompt&quot;</span>:promt, <span class="string">&quot;history&quot;</span>:<span class="built_in">history</span>&#125;,</span><br><span class="line">        headers= heade_</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">return</span> resq.json()[<span class="string">&quot;response&quot;</span>], resq.json()[<span class="string">&quot;history&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">history</span> = []</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">提取问题主语和谓语</span></span><br><span class="line"><span class="string">适合用于英文，# subject, verb = extract_subject_verb(question)</span></span><br><span class="line"><span class="string">中文没有空格符，中文调用第三方包jieba</span></span><br><span class="line"><span class="string">&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">from nltk.tokenize import word_tokenize</span><br><span class="line">from nltk.tag import pos_tag</span><br><span class="line">def extract_subject_verb(sentence):</span><br><span class="line">    tokens = word_tokenize(sentence)</span><br><span class="line">    tags = pos_tag(tokens)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(tags)):</span><br><span class="line">        word, tag = tags[i]</span><br><span class="line">        <span class="keyword">if</span> tag.startswith(<span class="string">&#x27;NN&#x27;</span>): <span class="comment"># 名词</span></span><br><span class="line">            subject = <span class="string">&#x27; &#x27;</span>.<span class="built_in">join</span>([word <span class="keyword">for</span> word, tag <span class="keyword">in</span> tags[:i+1]])</span><br><span class="line">            verb = <span class="string">&#x27; &#x27;</span>.<span class="built_in">join</span>([word <span class="keyword">for</span> word, tag <span class="keyword">in</span> tags[i+1:]])</span><br><span class="line">            <span class="built_in">return</span> subject, verb</span><br><span class="line">    <span class="built_in">return</span> None, None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> True:   </span><br><span class="line">    question = input(<span class="string">&quot;请提问: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> question == <span class="string">&quot;quit&quot;</span>:        <span class="comment">### 键入 quit 终止对话</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已关闭对话&quot;</span>)</span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        keywords = extract_tags(question, topK=5)</span><br><span class="line"></span><br><span class="line">        similarity_docs = db.similarity_search(question)</span><br><span class="line">        promt = <span class="string">&quot;根据下面给出的资料用中文回答问题，如果资料不足请回复不知道，下面是资料：&quot;</span></span><br><span class="line">        <span class="keyword">for</span> idx, doc <span class="keyword">in</span> enumerate(similarity_docs):</span><br><span class="line">            promt += f<span class="string">&quot;&#123;idx+1&#125;.&#123;doc.page_content&#125;\n&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(promt)</span><br><span class="line">        promt = f<span class="string">&quot;下面是问题：&#123;question&#125;&quot;</span></span><br><span class="line">        response, <span class="built_in">history</span> = chat(promt, <span class="built_in">history</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;答: &quot;</span>, response)</span><br></pre></td></tr></table></figure>

<p>回答效果如下：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20161427.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20161631.png" alt="屏幕截图 2024-03-24 161631"></p>
<ol start="2">
<li><p>调用langchain进行问答，对问题加提示词实现优化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.llms.chatglm <span class="keyword">import</span> ChatGLM </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan_32&#x27;</span>     <span class="comment"># 指定向量库文件夹位置</span></span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>   <span class="comment"># 指定加载embeddding模型</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">embeddings = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">db = Chroma(embedding_function=embeddings, persist_directory=persist_directory)  <span class="comment"># 加载之前创建的向量库文件里的向量数据</span></span><br><span class="line"></span><br><span class="line">llm = ChatGLM(                                   <span class="comment"># 通过api调用大模型</span></span><br><span class="line">        endpoint_url=<span class="string">&#x27;http://127.0.0.1:8000&#x27;</span>,</span><br><span class="line">        max_token=<span class="number">2000</span>,</span><br><span class="line">        top_p=<span class="number">0.7</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">retriever = db.as_retriever()</span><br><span class="line"></span><br><span class="line">prompt_template = <span class="string">&quot;&quot;&quot;Use the following pieces of context to answer the question at the end.  If you don&#x27;t know the answer, answer I don&#x27;t know.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;question&#125;</span></span><br><span class="line"><span class="string">Answer in Chinese:&quot;&quot;&quot;</span></span><br><span class="line">PROMPT = PromptTemplate(</span><br><span class="line">    template=prompt_template, input_variables=[<span class="string">&quot;context&quot;</span>, <span class="string">&quot;question&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain_type_kwargs = &#123;<span class="string">&quot;prompt&quot;</span>: PROMPT,<span class="string">&quot;verbose&quot;</span>:<span class="literal">True</span>&#125;</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(         <span class="comment"># 启用问答模式开始聊天</span></span><br><span class="line">    llm=llm,</span><br><span class="line">    retriever = retriever,</span><br><span class="line">    <span class="comment">#chain_type_kwargs=chain_type_kwargs)</span></span><br><span class="line">    chain_type= <span class="string">&quot;stuff&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:   </span><br><span class="line">    question = <span class="built_in">input</span>(<span class="string">&quot;请提问: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> question == <span class="string">&quot;quit&quot;</span>:        <span class="comment">### 键入 quit 终止对话</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已关闭对话&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        question +=<span class="string">&quot;。无法回答就说不知道，用中文回答&quot;</span> </span><br><span class="line">        response = qa.run(question)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;原始回答: &quot;</span>, response)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>回答效果如下：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20162002.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20162301.png" alt="屏幕截图 2024-03-24 162301"></p>
</li>
<li><p>调用promt模板</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.llms.chatglm <span class="keyword">import</span> ChatGLM </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan_32&#x27;</span>     <span class="comment"># 指定向量库文件夹位置</span></span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>   <span class="comment"># 指定加载embeddding模型</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">embeddings = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">db = Chroma(embedding_function=embeddings, persist_directory=persist_directory)  <span class="comment"># 加载之前创建的向量库文件里的向量数据</span></span><br><span class="line"></span><br><span class="line">llm = ChatGLM(                                   <span class="comment"># 通过api调用大模型</span></span><br><span class="line">        endpoint_url=<span class="string">&#x27;http://127.0.0.1:8000&#x27;</span>,</span><br><span class="line">        max_token=<span class="number">2000</span>,</span><br><span class="line">        top_p=<span class="number">0.7</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">retriever = db.as_retriever()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_template = <span class="string">&quot;&quot;&quot;Use the following pieces of context to answer the question at the end.  If you don&#x27;t know the answer, answer I don&#x27;t know.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;question&#125;</span></span><br><span class="line"><span class="string">Answer in Chinese:&quot;&quot;&quot;</span></span><br><span class="line">PROMPT = PromptTemplate(</span><br><span class="line">    template=prompt_template, input_variables=[<span class="string">&quot;context&quot;</span>, <span class="string">&quot;question&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain_type_kwargs = &#123;<span class="string">&quot;prompt&quot;</span>: PROMPT,<span class="string">&quot;verbose&quot;</span>:<span class="literal">True</span>&#125;</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(         <span class="comment"># 启用问答模式开始聊天</span></span><br><span class="line">    llm=llm,</span><br><span class="line">    retriever = retriever,</span><br><span class="line">    chain_type_kwargs=chain_type_kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:   </span><br><span class="line">    question = <span class="built_in">input</span>(<span class="string">&quot;请提问: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> question == <span class="string">&quot;quit&quot;</span>:        <span class="comment">### 键入 quit 终止对话</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已关闭对话&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        response = qa.run(question)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;原始回答: &quot;</span>, response)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>回答效果如下：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20162902.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20162619.png" alt="屏幕截图 2024-03-24 162619"></p>
</li>
</ol>
<p>总结：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%83/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-24%20164020.png"></p>
<ol>
<li><p>不变更输入的情况下，不同promt对搜索相似文本返回的匹配文档时一致的，除非变动输入，匹配结果会不同；</p>
</li>
<li><p>用promt模板的回答效果看起来要更好一些；</p>
</li>
</ol>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署二</title>
    <url>/post/821bab1a.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就初次使用大模型出现一些问答出现幻觉的情况做分析介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="幻觉问题"><a href="#幻觉问题" class="headerlink" title="幻觉问题"></a>幻觉问题</h2><p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/image-20240316101400256.png" alt="image-20240316101400256"></p>
<p>可以看出的问题有：</p>
<ol>
<li><p>多轮问答出现自我矛盾；</p>
<p>原因可能是模型在整个对话过程中失去了对上下文的跟踪或者无法保持长期记忆的一致性；</p>
</li>
<li><p>生成与事实冲突的内容；</p>
</li>
</ol>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/image-20240316103029915.png" alt="image-20240316103029915"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20131022.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20131136.png"><br>这种情况下可见模型是具备一些知识的，但是生成内容是不正确的</p>
<p>如何判别模型其实自身具备某些知识呢？</p>
<ol>
<li><p>自我纠正</p>
<p>就是用模型生成的结果再去反问模型，验证回答的准确性</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20132335.png"></p>
<ol start="2">
<li>用生成结果与真实结果结合输入给模型让模型回答</li>
</ol>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20134050.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20134116.png"><br>由上可以看出，给出选项的时候大模型更倾向于输出正确的答案</p>
</li>
<li><p>误解意图</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/image-20240316105125298.png" alt="image-20240316105125298"></p>
</li>
</ol>
<h2 id="幻觉出现的原因"><a href="#幻觉出现的原因" class="headerlink" title="幻觉出现的原因"></a>幻觉出现的原因</h2><ol>
<li><p>知识不足：</p>
<p>a. 训练语料的知识不足；</p>
<p>b. 针对性的知识不足；</p>
<p>c. 干净正确的知识不足；</p>
</li>
<li><p>生成策略</p>
<p>在解码的时候用的是topk采样，并不是一定就选中概率值最高的token做输出，万一选中了错的token, 根据生成策略，大模型还是会继续顺着前面错误的生成继续往下生成token，也会导致幻觉像滚雪球越来越严重。</p>
</li>
<li><p>“谄媚”</p>
<p>大模型从不质疑人类的输入，一味附和人类的喜好做输出</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20143313.png"></p>
</li>
</ol>
<h2 id="幻觉缓解"><a href="#幻觉缓解" class="headerlink" title="幻觉缓解"></a>幻觉缓解</h2><ol>
<li><p>补充知识</p>
<p>a. 加大数据投喂量；</p>
<p>b. 人工清除数据库中的噪声；</p>
<p>c. 外挂知识库</p>
</li>
<li><p>诚实性微调</p>
</li>
<li><p>自查</p>
<p>即模型自己判断自己生成内容的正确性：先生成回答，再判断回答是否为真；</p>
</li>
<li><p>多生成几次</p>
<p>通过生成内容的一致性来判断是否是幻觉</p>
</li>
</ol>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20143600.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%8C/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-16%20143634.png"></p>
<p>可以看出，在幻觉出现时，每次输出相差挺大的。</p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署五</title>
    <url>/post/9177334c.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就如何使用爬虫工具实现文本抓取进行验证介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><p>开始我下载的是小说，但是发现小说和我所知道的电视剧改动比较大，而且小说的语法用词不太白话文，后面又想着字幕是不是好一点，但是忽略了字幕会跳过最重要的环节：人物关系，也就是丢给大模型，它并不明白这话都是谁说的，无法联系起来。所以最终决定从分集剧情作为数据，更简单干练。</p>
<p>因为我要从网站上把每集的分集剧情内容爬下来，所以不得不提爬虫工具。</p>
<h3 id="网页不可复制代码块内容提取"><a href="#网页不可复制代码块内容提取" class="headerlink" title="网页不可复制代码块内容提取"></a>网页不可复制代码块内容提取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.zhihu.com/question/467685925&quot;</span>  <span class="comment"># 替换为你要爬取的网页URL</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line">html_content = response.content</span><br><span class="line">soup = BeautifulSoup(html_content, <span class="string">&quot;html.parser&quot;</span>)</span><br><span class="line">class_element = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;highlight&#x27;</span>)  <span class="comment">## 这里的class_就对应根据关键字在网页源码找到具体块</span></span><br><span class="line">class_text = class_element.text</span><br><span class="line"><span class="built_in">print</span>(class_text)</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%94/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20101753.png"></p>
<p>可以看下效果</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%94/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20102136.png"></p>
<h3 id="带有下一页格式网页内容提取"><a href="#带有下一页格式网页内容提取" class="headerlink" title="带有下一页格式网页内容提取"></a>带有下一页格式网页内容提取</h3><p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%94/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20111344.png"></p>
<p>观察网页格式可以得到网页命名格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/0-2</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/0-3</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/1-4</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/1-5</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/1-6</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/20-63</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/21-64</span></span><br><span class="line"><span class="string">https://www.tvmao.com/drama/YicsIy8=/episode/25-76</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>所以中心思想是遍历所有网页再根据关键信息提取对应的块内容</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%94/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20113753.png"></p>
<p><font face="黑体" color="red" size="5">这里一定注意：1.查找时尽量找文本最后的字符为查找对象，才能找对，文档前面的字符可能会在网页源码中多次出现，不注意的话很容易找错地方。2. 文本提取出来看看有没有不相关的内容尽早清洗剔除掉，保证数据干净</font></p>
<p>所以整体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_html</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取网页源代码</span></span><br><span class="line"><span class="string">    :param url: URL</span></span><br><span class="line"><span class="string">    :return: str</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: UserAgent().random&#125;</span><br><span class="line">    response = requests.get(url, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> response.text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_html</span>(<span class="params">html</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    解析网页源码并提取数据</span></span><br><span class="line"><span class="string">    :param html: Page_Source</span></span><br><span class="line"><span class="string">    :return: generator</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    class_element = soup.find(<span class="string">&#x27;article&#x27;</span>, class_=<span class="string">&#x27;clear epi_c&#x27;</span>)</span><br><span class="line">    description = class_element.text </span><br><span class="line">    <span class="comment">## 数据清洗</span></span><br><span class="line">    description = description.replace(<span class="string">&#x27;(后宫·甄嬛传剧情系电视猫原创，未经许可，请勿转载！转载许可)&#x27;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;上传剧照图片&quot;</span>, <span class="string">&#x27;&#x27;</span>).strip()+ <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(description)</span><br><span class="line">    <span class="keyword">return</span> description</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write2csv</span>(<span class="params">filename, rows</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    保存数据到csv文件</span></span><br><span class="line"><span class="string">    :param filename: </span></span><br><span class="line"><span class="string">    :param rows: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;a+&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        csv_writer = csv.writer(f)</span><br><span class="line">        csv_writer.writerows(rows)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write2txt</span>(<span class="params">filename, contents</span>):</span><br><span class="line">      fh = <span class="built_in">open</span>(filename, <span class="string">&#x27;a+&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">      fh.write(contents)</span><br><span class="line">      fh.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    入口函数</span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    filename = <span class="string">&#x27;./甄嬛传剧情.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/0-2</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/0-3</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/1-4</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/1-5</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/1-6</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/20-63</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/21-64</span></span><br><span class="line"><span class="string">    https://www.tvmao.com/drama/YicsIy8=/episode/25-76</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">77</span>):</span><br><span class="line">        shang = index//<span class="number">3</span></span><br><span class="line">        rest = index%<span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span>  rest==<span class="number">0</span>:</span><br><span class="line">            pageNo = shang -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pageNo = shang</span><br><span class="line">        <span class="keyword">if</span> index ==<span class="number">1</span>:</span><br><span class="line">            url = <span class="string">&#x27;https://www.tvmao.com/drama/YicsIy8=/episode&#x27;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            url = <span class="string">&#x27;https://www.tvmao.com/drama/YicsIy8=/episode/&#123;&#125;-&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(pageNo, index)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        page_source = get_html(url)</span><br><span class="line">        <span class="built_in">print</span>(url)</span><br><span class="line">        content = parse_html(page_source)</span><br><span class="line">        write2txt(filename, content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>最终的效果：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%94/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20113852.png"></p>
<p>保存提取的内容</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%BA%94/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20113932.png"></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署六</title>
    <url>/post/976efb4f.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就实践中遇到的幻觉现象以及web端部署大模型做实验介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="大模型表现"><a href="#大模型表现" class="headerlink" title="大模型表现"></a>大模型表现</h2><h3 id="幻觉的回答"><a href="#幻觉的回答" class="headerlink" title="幻觉的回答"></a>幻觉的回答</h3><p>表现是文本搜索结果中并没有相关的文段内容，所以大模型自由发挥胡说八道，不知道真实答案的人很容易被误导。原因可能是：</p>
<ol>
<li><p>资料路中相关语料内容本来就少；</p>
<p><font face="黑体" color="red" size="5">原本语料库根本没有提及到华妃喜欢食物的相关内容</font></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20143550.png"></p>
</li>
<li><p>对象出现的频率很小的时候很容易被误认为是其他高频出现的对象；</p>
<p><font face="黑体" color="red" size="5">把康禄海当成年羹尧了，原始文本中年羹尧出现31次，康禄海出现2次</font></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141506.png"></p>
</li>
<li><p>大模型是生成内容，前面文本出现的时候，大模型后面生成内容很容易生成常见的、极易出现的语句对，比如说天气是晴朗的，才艺是唱歌之类的。</p>
<p><font face="黑体" color="red" size="5">大模型自由发挥</font></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141209.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141834.png"></p>
</li>
<li><p>大模型有时候会对输入问题出现误解，所以这时候的回答也就是错的</p>
<p><font face="黑体" color="red" size="5">这里我提问的其实谁拥有过椒房之宠，大模型理解成谁有过错</font></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141340.png"></p>
</li>
</ol>
<h3 id="不错的回答"><a href="#不错的回答" class="headerlink" title="不错的回答"></a>不错的回答</h3><p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141627.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141054.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20140925.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20140647.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20141948.png"></p>
<p>至此，本地部署最简单的方式已经完成，这里给出部署代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="comment"># 创建向量库以及如何调用向量库查询</span></span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders.text <span class="keyword">import</span> TextLoader</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan_32&#x27;</span></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">hf = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">db = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(persist_directory):</span><br><span class="line">    <span class="comment">## 本地加载向量数据库</span></span><br><span class="line">    db = Chroma(embedding_function=hf, persist_directory=persist_directory)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loader = TextLoader(<span class="string">&#x27;甄嬛传剧情.txt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    text_split = RecursiveCharacterTextSplitter(</span><br><span class="line">            chunk_size = <span class="number">32</span>,</span><br><span class="line">            chunk_overlap  = <span class="number">10</span>,</span><br><span class="line">            length_function = <span class="built_in">len</span>,</span><br><span class="line">            add_start_index = <span class="literal">True</span>)</span><br><span class="line">    split_docs = text_split.split_documents(loader.load())</span><br><span class="line">    db = Chroma.from_documents(documents=split_docs, embedding=hf, persist_directory=persist_directory)</span><br><span class="line">    db.persist()</span><br><span class="line"></span><br><span class="line">ques = <span class="string">&#x27;华妃终身不孕的原因是什么&#x27;</span></span><br><span class="line"><span class="comment"># ques_embedding = hf.embed_query(ques)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res_similarity_search = db.similarity_search(ques)</span><br><span class="line"><span class="comment"># res_similarity_search_by_vector = db.similarity_search_by_vector(ques_embedding, k=5)</span></span><br><span class="line"><span class="comment"># res_similarity_search_by_vector_with_relevance_scores = db.similarity_search_by_vector_with_relevance_scores(ques_embedding, k=5)</span></span><br><span class="line"><span class="comment"># res_similarity_search_with_relevance_scores = db.similarity_search_with_relevance_scores(ques)</span></span><br><span class="line"><span class="comment"># res_similarity_search_with_score = db.similarity_search_with_score(ques, k=5)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;over&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>调用大模型开启对话</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.llms.chatglm <span class="keyword">import</span> ChatGLM </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"></span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan_32&#x27;</span>     <span class="comment"># 指定向量库文件夹位置</span></span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>   <span class="comment"># 指定加载embeddding模型</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">embeddings = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">db = Chroma(embedding_function=embeddings, persist_directory=persist_directory)  <span class="comment"># 加载之前创建的向量库文件里的向量数据</span></span><br><span class="line"></span><br><span class="line">llm = ChatGLM(                                   <span class="comment"># 通过api调用大模型</span></span><br><span class="line">        endpoint_url=<span class="string">&#x27;http://127.0.0.1:8000&#x27;</span>,</span><br><span class="line">        max_token=<span class="number">2000</span>,</span><br><span class="line">        top_p=<span class="number">0.7</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">retriever = db.as_retriever()</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(         <span class="comment"># 启用问答模式开始聊天</span></span><br><span class="line">    llm=llm,</span><br><span class="line">    retriever = retriever,</span><br><span class="line">    chain_type= <span class="string">&quot;stuff&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:   </span><br><span class="line">    question = <span class="built_in">input</span>(<span class="string">&quot;请提问: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> question == <span class="string">&quot;quit&quot;</span>:        <span class="comment">### 键入 quit 终止对话</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已关闭对话&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        response = qa.run(question)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;答: &quot;</span>, response)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20153446.png"></p>
<h2 id="本地部署的改进"><a href="#本地部署的改进" class="headerlink" title="本地部署的改进"></a>本地部署的改进</h2><h4 id="中英文夹杂"><a href="#中英文夹杂" class="headerlink" title="中英文夹杂"></a>中英文夹杂</h4><p>解决办法：promt</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:   </span><br><span class="line">    question = <span class="built_in">input</span>(<span class="string">&quot;请提问: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> question == <span class="string">&quot;quit&quot;</span>:        <span class="comment">### 键入 quit 终止对话</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已关闭对话&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        question +=<span class="string">&quot;。无法回答就说不知道，用中文回答。&quot;</span>  </span><br><span class="line">        response = qa.run(question)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;原始回答: &quot;</span>, response)</span><br></pre></td></tr></table></figure>

<h3 id="webUI端部署"><a href="#webUI端部署" class="headerlink" title="webUI端部署"></a>webUI端部署</h3><p>首先安装依赖</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install gradio</span><br></pre></td></tr></table></figure>

<p>网页端部署脚本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.llms.chatglm <span class="keyword">import</span> ChatGLM </span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"></span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan_32&#x27;</span>     <span class="comment"># 指定向量库文件夹位置</span></span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>   <span class="comment"># 指定加载embeddding模型</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">embeddings = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">db = Chroma(embedding_function=embeddings, persist_directory=persist_directory)  <span class="comment"># 加载之前创建的向量库文件里的向量数据</span></span><br><span class="line"></span><br><span class="line">llm = ChatGLM(                                   <span class="comment"># 通过api调用大模型</span></span><br><span class="line">        endpoint_url=<span class="string">&#x27;http://127.0.0.1:8000&#x27;</span>,</span><br><span class="line">        max_token=<span class="number">2000</span>,</span><br><span class="line">        top_p=<span class="number">0.7</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">retriever = db.as_retriever()</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(         <span class="comment"># 启用问答模式开始聊天</span></span><br><span class="line">    llm=llm,</span><br><span class="line">    retriever = retriever,</span><br><span class="line">    chain_type= <span class="string">&quot;stuff&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">question, history</span>):</span><br><span class="line">    response = qa.run(question)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line">    demo = gr.ChatInterface(chat)</span><br><span class="line">    demo.launch(inbrowser=<span class="literal">True</span>, share= <span class="literal">True</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(traceback.format_exc())</span><br></pre></td></tr></table></figure>

<h4 id="UnicodeDecodeError-‘gbk’-codec-can’t-decode-byte-0xb2-in-position-1972-illegal-multibyte-sequence"><a href="#UnicodeDecodeError-‘gbk’-codec-can’t-decode-byte-0xb2-in-position-1972-illegal-multibyte-sequence" class="headerlink" title="UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xb2 in position 1972: illegal multibyte sequence"></a>UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xb2 in position 1972: illegal multibyte sequence</h4><p>开始问题出现在import gradio as gr，为了定位具体位置，加上traceback，最后找到是在read部分出现读入错误。</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20162942.png"></p>
<p>所以在原位置加上指定utf-8编码</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20163122.png"></p>
<p>再次运行问题解决</p>
<h4 id="TypeError-chat-takes-1-positional-argument-but-2-were-given"><a href="#TypeError-chat-takes-1-positional-argument-but-2-were-given" class="headerlink" title="TypeError: chat() takes 1 positional argument but 2 were given"></a>TypeError: chat() takes 1 positional argument but 2 were given</h4><p>网页打开后输入问题报错</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20163735.png"></p>
<p>这里一定注意</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">question, history</span>):       <span class="comment">#### chat的history一定要有</span></span><br><span class="line">    response = qa.run(question)</span><br><span class="line">    <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>

<p>加上history问题解决。</p>
<p>最后正常运行的结果如下：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-23%20164412.png"></p>
<p>加了共享链接在手机上运行也是正常的</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%85%AD/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240323164305.jpg"></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+llama2_7b本地部署一</title>
    <url>/post/8b93c30d.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就llama2本地部署以及微调训练一个客服对话机器人的使用以及效果以实验步骤做实验介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="环境安装配置"><a href="#环境安装配置" class="headerlink" title="环境安装配置"></a>环境安装配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 在原有环境基础上创建一个新环境</span></span><br><span class="line">conda create -n llama2 --<span class="built_in">clone</span> chatglm </span><br><span class="line">pip install peft trl</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows-anaconda-4050-6G-llama2-7b%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-27%20111227.png"></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://blog.csdn.net/qq_37764129/article/details/102496746">复制Anaconda虚拟环境</a></p>
<p><a href="https://plainenglish.io/blog/fine-tuning-llama2-0-with-qloras-single-gpu-magic">Fine-Tuning Llama 2.0 with Single GPU Magic</a></p>
<p><a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco/tree/main">timdettmers/openassistant-guanaco</a></p>
<p><a href="https://huggingface.co/NousResearch/Llama-2-7b-chat-hf/tree/main">NousResearch/Llama-2-7b-chat-hf</a></p>
<p><a href="https://riteshkhanna.com/2023/03/14/running-llama-7b-on-windows-cpu-or-gpu/">Running Llama-7B on Windows CPU or GPU</a></p>
<p><a href="https://deci.ai/blog/fine-tune-llama-2-with-lora-for-question-answering/">How to Fine-tune Llama 2 with LoRA for Question Answering: A Guide for Practitioners</a></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 llama2 lora rag</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows+anaconda+4050 6G+chatglm本地部署四</title>
    <url>/post/8c955109.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文就文本的向量表示以及向量数据库结合大模型的使用作以介绍</p>

</blockquote>
<span id="more"></span>

<h2 id="中文文本向量表征"><a href="#中文文本向量表征" class="headerlink" title="中文文本向量表征"></a>中文文本向量表征</h2><h3 id="文本向量表征"><a href="#文本向量表征" class="headerlink" title="文本向量表征"></a>文本向量表征</h3><p>这里我对比了三种不同模型embedding的结果：分别是<a href="https://huggingface.co/shibing624/text2vec-base-chinese">shibing624/text2vec-base-chinese</a>和 <a href="https://github.com/shibing624/text2vec/releases/download/1.1.4/light_Tencent_AILab_ChineseEmbedding.bin">w2v-light-tencent-chinese</a> 以及 <a href="https://huggingface.co/shibing624/text2vec-base-chinese-paraphrase">shibing624/text2vec-base-chinese-paraphrase</a></p>
<p>调用方法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> text2vec <span class="keyword">import</span> SentenceModel, Word2Vec</span><br><span class="line">model = SentenceModel(<span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>)</span><br><span class="line">model = Word2Vec(<span class="string">&#x27;w2v-light-tencent-chinese&#x27;</span>)</span><br><span class="line">model = SentenceModel(<span class="string">&quot;shibing624/text2vec-base-chinese-paraphrase&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>看看不同embeddding模型对于同一输入最终表征结果的差异性：</p>
<p>我这里对比了三段文本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">from text2vec import SentenceModel, Word2Vec</span><br><span class="line"><span class="comment"># model = SentenceModel(&quot;shibing624/text2vec-base-chinese&quot;)</span></span><br><span class="line"><span class="comment"># model = Word2Vec(&#x27;w2v-light-tencent-chinese&#x27;)</span></span><br><span class="line">model = SentenceModel(<span class="string">&quot;shibing624/text2vec-base-chinese-paraphrase&quot;</span>)</span><br><span class="line">textvec1 = model.encode(<span class="string">&quot;铲子里还带着刚从地下带出的旧土，离奇的是，这一杯土正不停的向外渗着鲜红的液体，就像刚刚在血液里蘸过一样&quot;</span>)</span><br><span class="line">textvec2 = model.encode(<span class="string">&quot;“下不下去喃？要得要不得，一句话，莫七里八里的！”独眼的小伙子说：“你说你个老人家腿脚不方便，就莫下去了，我和我弟两个下去，管他什么东西，直接给他来一梭子。”&quot;</span>)</span><br><span class="line">textvec3 = model.encode(<span class="string">&quot;果然，这样一来他就和洞里的东西对持住了，双方都各自吃力，但是都拉不动分毫，僵持了有10几秒，就听到洞里一声盒子炮响，然后听到他爹大叫：“三伢子，快跑！！！！！！”，就觉的绳子一松，土耗子嗖一声从洞里弹了出来，好象上面还挂了什么东西！那时候老三也顾不得那么多了，他知道下面肯定出了事情了，一把接住土耗子，扭头就跑！他一口七跑出有2里多地，才敢停下来，掏出他怀里的土耗子一看，吓的大叫了一声，原来土耗子上什么都没勾，只勾着一只血淋淋的断手。他认得那手上，不由哭了出来，他手是分明是他二哥的。看样子他二哥就算不死也残废了，想到这里，他不由一咬，就想回去救他二哥和老爹，刚一回头，就看见背后蹲着个血红血红的东西，正直钩钩看着他&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(cosine_hard(textvec1, textvec2))</span><br><span class="line"><span class="built_in">print</span>(cosine_hard(textvec1, textvec3))</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20151218.png"></p>
<p>由此可见，在embedding阶段选取不同的模型也会影响最后相似性的结果。一般中文比较用的最多的是<a href="https://huggingface.co/shibing624/text2vec-base-chinese">shibing624/text2vec-base-chinese</a>。</p>
<p>一般通过在线下载方式最后模型文件夹的保存路径一般在C:\Users\xxx.cache\huggingface\hub</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20144410.png"></p>
<p>如果没有安装text2vec也可以通过其他两种方式加载模型完成文本embedding。</p>
<p>方式一：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import torch</span><br><span class="line">from transformers import AutoTokenizer, AutoModel</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;KMP_DUPLICATE_LIB_OK&quot;</span>] = <span class="string">&quot;TRUE&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean Pooling - Take attention mask into account for correct averaging</span></span><br><span class="line">def mean_pooling(model_output, attention_mask):</span><br><span class="line">    token_embeddings = model_output[0]  <span class="comment"># First element of model_output contains all token embeddings</span></span><br><span class="line">    input_mask_expanded = attention_mask.unsqueeze(-1).<span class="built_in">expand</span>(token_embeddings.size()).<span class="built_in">float</span>()</span><br><span class="line">    <span class="built_in">return</span> torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load model from HuggingFace Hub</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&#x27;shibing624/text2vec-base-chinese&#x27;</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&#x27;shibing624/text2vec-base-chinese&#x27;</span>)</span><br><span class="line">sentences = [<span class="string">&#x27;如何更换花呗绑定银行卡&#x27;</span>, <span class="string">&#x27;花呗更改绑定银行卡&#x27;</span>]</span><br><span class="line"><span class="comment"># Tokenize sentences</span></span><br><span class="line">encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=<span class="string">&#x27;pt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute token embeddings</span></span><br><span class="line">with torch.no_grad():</span><br><span class="line">    model_output = model(**encoded_input)</span><br><span class="line"><span class="comment"># Perform pooling. In this case, max pooling.</span></span><br><span class="line">sentence_embeddings = mean_pooling(model_output, encoded_input[<span class="string">&#x27;attention_mask&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sentence embeddings:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(sentence_embeddings)</span><br></pre></td></tr></table></figure>

<p>方式一加载模型并将文本映射到高维空间后再次计算相似度，还是用同一文本对</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20154855.png"></p>
<p>和上面计算的结果稍稍有点差别。</p>
<p>方式二：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">from sentence_transformers import SentenceTransformer</span><br><span class="line"></span><br><span class="line">m = SentenceTransformer(<span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span>)</span><br><span class="line">sentences = [<span class="string">&#x27;如何更换花呗绑定银行卡&#x27;</span>, <span class="string">&#x27;花呗更改绑定银行卡&#x27;</span>]</span><br><span class="line"></span><br><span class="line">sentence_embeddings = m.encode(sentences)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sentence embeddings:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(sentence_embeddings)</span><br></pre></td></tr></table></figure>

<p>方式二的加载方式和text2vet没有差别，计算结果通过验证也没有差别。</p>
<h3 id="向量相似度计算"><a href="#向量相似度计算" class="headerlink" title="向量相似度计算"></a>向量相似度计算</h3><p>回想之前高数的时候学过，向量之间夹角的表示</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20112047.png"></p>
<p>方便理解就是父母和孩子长相的相似性，亲生的就很像，这里就可以类比理解成向量的夹角Θ越接近0，孩子和陌生人就一点也不像，也就是Θ值越接近90°，就像坐标系的坐标轴，各自不能相互表示，也就是互不相关。</p>
<p>但是一般我们不直接求解Θ，只求到 cos Θ 就可以实现同样的效果，即<font face="黑体" color="red" size="5"> cos Θ 值越接近等于1就说明两向量越相似，cos Θ 值越接近等于0就说明两向量越不相关。</font></p>
<p>这里介绍两种计算方式</p>
<p>一种是直接用计算公式写的函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cos_sim_hard</span>(<span class="params">v1, v2</span>):</span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(v1, np.ndarray):</span><br><span class="line">		v1 = np.array(v1)</span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(v2, np.ndarray):</span><br><span class="line">        v2 = np.array(v2)</span><br><span class="line">    up = <span class="built_in">float</span>(np.<span class="built_in">sum</span>(v1*v2))  <span class="comment">## 向量乘积</span></span><br><span class="line">    down = np.linalg.norm(v1)*np.linalg.norm(v2) <span class="comment">## 向量模乘积</span></span><br><span class="line">    <span class="keyword">if</span> down!=<span class="number">0</span>:</span><br><span class="line">        res = up/down  <span class="comment">## 计算除法一定要保证分子不为0</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<p>第二种是利用矩阵求解</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cos_sim_matrx</span>(<span class="params">a, b</span>):</span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(a, torch.Tensor):</span><br><span class="line">        a = torch.tensor(a) <span class="comment">#使用cuda计算可改为torch.tensor(a).cuda(0)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(b, torch.Tensor):</span><br><span class="line">        a = torch.tensor(b) <span class="comment">#使用cuda计算可改为torch.tensor(b).cuda(0)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(a.shape)==<span class="number">1</span>:</span><br><span class="line">        a = a.unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(b.shape)==<span class="number">1</span>:</span><br><span class="line">        b = b.unsqueeze(<span class="number">0</span>)</span><br><span class="line">    a_norm = torch.nn.functional.normalize(a, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    b_norm = torch.nn.functional.normalize(b, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.mm(a_norm, b_norm.transpose(<span class="number">0</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>其实第二种方法是对公式做了变式</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20115739.png"></p>
<p>最后看一下两种方法的计算结果：</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20120713.png"></p>
<p>可以看出结果是一致的。</p>
<h2 id="向量数据库"><a href="#向量数据库" class="headerlink" title="向量数据库"></a>向量数据库</h2><p>接着之前的步骤，完成文本切块后，接着需要对文本向量化并存储，方便之后大模型调用</p>
<h3 id="chroma向量库创建"><a href="#chroma向量库创建" class="headerlink" title="chroma向量库创建"></a>chroma向量库创建</h3><p>使用方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.vectorstores.chroma <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders.text <span class="keyword">import</span> TextLoader</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings.huggingface <span class="keyword">import</span> HuggingFaceEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line">loader = TextLoader(<span class="string">&#x27;甄嬛传剧情.txt&#x27;</span>)</span><br><span class="line">text_split = RecursiveCharacterTextSplitter(</span><br><span class="line">        chunk_size = <span class="number">256</span>,</span><br><span class="line">        chunk_overlap  = <span class="number">10</span>,</span><br><span class="line">        length_function = <span class="built_in">len</span>,</span><br><span class="line">        add_start_index = <span class="literal">True</span>)</span><br><span class="line">split_docs = text_split.split_documents(loader.load())</span><br><span class="line">persist_directory = <span class="string">&#x27;vector_zhenhuanzhuan&#x27;</span></span><br><span class="line">model_name = <span class="string">&quot;shibing624/text2vec-base-chinese&quot;</span></span><br><span class="line">model_kwargs = &#123;<span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>&#125;</span><br><span class="line">encode_kwargs = &#123;<span class="string">&#x27;normalize_embeddings&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">hf = HuggingFaceEmbeddings(</span><br><span class="line">    model_name=model_name,</span><br><span class="line">    model_kwargs=model_kwargs,</span><br><span class="line">    encode_kwargs=encode_kwargs</span><br><span class="line">)</span><br><span class="line">db = Chroma.from_documents(documents=split_docs, embedding=hf, persist_directory=persist_directory)</span><br><span class="line">db.persist()</span><br></pre></td></tr></table></figure>

<p><font face="黑体" color="red" size="5">UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xac in position 2: illegal multibyte sequence</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loader = TextLoader(<span class="string">&#x27;甄嬛传剧情.txt&#x27;</span>)</span><br><span class="line">to</span><br><span class="line">loader = TextLoader(<span class="string">&#x27;甄嬛传剧情.txt&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>最终会在主文件夹下新建vector_zhenhuanzhuan文件夹，并保存向量文件。</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20134438.png"></p>
<h3 id="搜寻近似向量"><a href="#搜寻近似向量" class="headerlink" title="搜寻近似向量"></a>搜寻近似向量</h3><p>上一步已经创建好向量库，接下来测试一下输入一段文本，看能否找到最相关的文本段</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 关于相似性搜索chroma提供了5种函数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">db.similarity_search(输入为字符串)</span></span><br><span class="line"><span class="string">db.similarity_search_with_relevance_scores(输入为字符串)</span></span><br><span class="line"><span class="string">db.similarity_search_with_score(输入为字符串)</span></span><br><span class="line"><span class="string">db.similarity_search_by_vector(输入为字符串的embedding结果)</span></span><br><span class="line"><span class="string">db.similarity_search_by_vector_with_relevance_scores(输入为字符串的embedding结果)</span></span><br><span class="line"><span class="string">每种搜索结果默认返回4条文本，需要修改的话，直接按照如下指定就行</span></span><br><span class="line"><span class="string">db.similarity_search(输入为字符串, K=5)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">ques = <span class="string">&#x27;甄嬛离宫去了哪儿？&#x27;</span></span><br><span class="line">ques_embedding = hf.embed_query(ques) <span class="comment">#这里直接调用前文定义的embedding模型</span></span><br><span class="line"></span><br><span class="line">res_similarity_search = db.similarity_search(ques)</span><br><span class="line">res_similarity_search_with_relevance_scores = db.similarity_search_with_relevance_scores(ques)</span><br><span class="line">res_similarity_search_with_score = db.similarity_search_with_score(ques)</span><br><span class="line">res_similarity_search_by_vector = db.similarity_search_by_vector(ques_embedding)</span><br><span class="line">res_similarity_search_by_vector_with_relevance_scores = db.similarity_search_by_vector_with_relevance_scores(ques_embedding)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20154231.png"></p>
<p><font face="黑体" color="red" size="5">可以看出不同搜寻相似向量的返回结果都是殊途同归的，其实看源码的话，会发现有些方法其实是套壳写的，比如similarity_search里面就是调用了similarity_search_with_score</font></p>
<p>再看看向量输入与字符串输入的搜寻近似结果</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20160123.png"></p>
<p><font face="黑体" color="red" size="5">similarity_search_with_score 与 similarity_search_by_vector_with_relevance_scores 的结果一模一样，完全相等</font></p>
<p>至此流程跑通了，现在重点看看搜索结果的匹配度，这块直接影响到后期大模型回答问题的准确性，所以需要调整一下</p>
<p>开始我设置切块文本长度在256，想了一下，这里原始数据来自于高度提炼和总结的文本，所以是不是应该把断句调小一些，这样更准呢？所以我把256换成64，重新创建新的数据库，再搜索输入看看返回的准确性。</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20162824.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20163644.png" alt="屏幕截图 2024-03-22 163644"></p>
<p><font face="黑体" color="red" size="5">效果真的好了很多，很多问题都能找到正确答案，但是也要注意：1. 问题问的太细其实是匹配不到结果的，也对应了原始数据中没有匹配的数据；2. 提问可以多样性，也能找到答案</font></p>
<h3 id="向量库-大模型"><a href="#向量库-大模型" class="headerlink" title="向量库+大模型"></a>向量库+大模型</h3><p>思路是：调用大模型，根据输入问题在向量库里搜寻最相似的文档段集合并返回，由llm归纳输出。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">retrieval_ = db.as_retriever()</span><br><span class="line">from langchain.prompts import PromptTemplate</span><br><span class="line">QA_CHAIN_PROMPT = PromptTemplate.from_template(<span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">如果你不知道答案，就回答不知道，不要试图编造答案。</span></span><br><span class="line"><span class="string">总是在答案结束时说”谢谢你的提问！“</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string">问题：&#123;question&#125;</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span>)</span><br><span class="line">qa = RetrievalQA.from_chain_type(</span><br><span class="line">    llm=llm,</span><br><span class="line">    retriever = retrieval_,</span><br><span class="line">    verbose=True,</span><br><span class="line">    chain_type_kwargs=&#123;<span class="string">&quot;prompt&quot;</span>: QA_CHAIN_PROMPT&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = qa.run(<span class="string">&quot;翠果打谁了&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>

<p>最终看看大模型的归纳结果如何</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20164940.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20165503.png"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20165411.png" alt="屏幕截图 2024-03-22 165411"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20165429.png" alt="屏幕截图 2024-03-22 165429"></p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-22%20165449.png" alt="屏幕截图 2024-03-22 165449"></p>
<p>根据<a href="https://python.langchain.com/docs/modules/data_connection/vectorstores/">官网</a>说明，提供了3种向量数据库，</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20163922.png"></p>
<p>不同的数据库需要先完成依赖安装才能使用。</p>
<p>遇到小插曲</p>
<p>在Windows上遇到了“Symbol cudaLaunchKernel not found，…，RuntimeError: Library cublasLt is not initialized”</p>
<p>网上的方法对我没有用，我在用nvcc -V检查cuda的时候提示nvcc命令无效，应该是cuda出现了问题。所以重新安装了cuda,还是用的之前的版本。重新安装后再运行代码文件就也没再报错了。</p>
<p><img data-src="./../images/Windows+anaconda+4050%206G+chatglm%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E5%9B%9B/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-03-21%20165434.png"></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://github.com/shibing624/text2vec">Text2vec: Text to Vector</a></p>
<p><a href="https://huggingface.co/shibing624/text2vec-base-chinese">text2vec-base-chinese</a></p>
<p><a href="https://www.bytezonex.com/archives/26.html">FAISS和Chroma：两种流行的向量数据库的比较</a></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下成功配置Qv2ray</title>
    <url>/post/a6ffce94.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>免费冲浪是真香，小伙伴且浪且珍惜</p>

</blockquote>

<span id="more"></span>

<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/a6ffce94.html"><font color="red">Windows下成功配置Qv2ray</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/a231f91f.html"><font color="blue">Ubuntu20.04下成功配置Qv2ray</font></a> </p>
<h3 id="安装图像界面"><a href="#安装图像界面" class="headerlink" title="安装图像界面"></a>安装图像界面</h3><p><a href="https://github.com/Qv2ray/Qv2ray/releases"><font color="blue">EXE下载地址</font></a></p>
<p>根据你自己的<font color="red">环境</font>选择对应的exe，下载成功后直接双击傻瓜式安装，选择在桌面建立快捷方式，完成即可</p>
<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/FireShot%20Capture%20003%20-%20Releases%20%C2%B7%20Qv2ray_Qv2ray%20-%20github.com.png"></p>
<h3 id="配置核心文件"><a href="#配置核心文件" class="headerlink" title="配置核心文件"></a>配置核心文件</h3><p><a href="https://github.com/v2fly/v2ray-core/releases"><font color="blue">核心文件下载地址</font></a></p>
<p>根据你自己的<font color="red">环境</font>选择对应的压缩包下载，成功后先从桌面打开qv2ray, 进入界面后在设置里根据提示的核心文件路径进行配置。</p>
<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/FireShot%20Capture%20006%20-%20Releases%20%C2%B7%20v2fly_v2ray-core%20-%20github.com.png"></p>
<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201009105336.png"></p>
<div class="note success"><p>这里注意，根据路径提示需要有一个名为vcore的文件夹，因此这里必须在相应路径下新建该文件夹</p>
</div>

<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201009111935.png"></p>
<p>vcore文件夹新建好之后需要将刚才下载的压缩包里的核心文件拷贝过来，所以直接进行复制粘贴就行</p>
<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201009105405.png"></p>
<p>接着通过核心验证</p>
<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201009105410.png"></p>
<h3 id="最后配置联网"><a href="#最后配置联网" class="headerlink" title="最后配置联网"></a>最后配置联网</h3><p><a href="https://view.freev2ray.org/"><font color="blue">免费账号地址</font></a></p>
<p>这个网址的账号是每12小时更新一次的，连不上的时候直接更新信息就行了。</p>
<p>具体账号配置方法参见文章<a href="https://bella722.github.io/post/a231f91f.html"><font color="green">Ubuntu20.04下成功配置Qv2ray</font></a></p>
<p>联网成功！</p>
<p><img data-src="../images/Windows%E4%B8%8B%E6%88%90%E5%8A%9F%E5%AE%89%E8%A3%85QV2Ray/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201009105415.png"></p>
]]></content>
      <categories>
        <category>科学上网指南</category>
      </categories>
      <tags>
        <tag>Qv2ray</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/post/4a17b156.html</url>
    <content><![CDATA[<p> <strong>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</strong></p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>小白学搭Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>yolov1解读笔记</title>
    <url>/post/77611970.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>自己回顾yolo系列算法，并做个笔记进行巩固。</p>

</blockquote>
<span id="more"></span>

<h1 id="YOLOV1"><a href="#YOLOV1" class="headerlink" title="YOLOV1"></a>YOLOV1</h1><h2 id="one-stage"><a href="#one-stage" class="headerlink" title="one stage"></a>one stage</h2><p>对比RCNN模型的目标检测，做法都是<font face="黑体" color="red" size="5">先从图片中用一些方法（selective search、RPN等）给出一些可能存在对象的候选区，再对每个候选区做特征提取之后做目标分类和bbox回归。</font></p>
<p>所以称之为two stage, 即</p>
<p><img data-src="./../images/yolov1%E8%A7%A3%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20240418110145775.png" alt="image-20240418110145775"></p>
<p>yolo其实并没有真正的去掉候选区域，而是在模型结构上相较rcnn并没有rpn网络，只有一个cnn网络，yolo是创造性的将候选区与目标分类合二为一。</p>
<p>yolo采用<font face="黑体" color="red" size="5">预定义预测区域的方法来完成目标检测</font>，具体做法是：</p>
<ol>
<li><p>输入图像先resize为448×448</p>
</li>
<li><p>图像划分为7×7的网格，每个网格大小是64×64</p>
</li>
<li><p>每个网格根据预定义，预测2个检测目标的矩形框<font face="黑体" color="red" size="5">(YOLOV1是随机产生2个bbounding box, 既没有提前设置长宽比，也没有设置尺度，就随机任意生成，只要bbounding box的中心在这个网格内，长宽比和大小任意）</font>。那么此时整个图像相当于有98个预测区，<font face="黑体" color="red" size="5">这个预定义的前提是一张图像内包含98个目标的情况很少</font></p>
</li>
<li><p>对这98个区域进行目标分类和bbox回归，再进行NMS就可以得到最终的目标检测结果。</p>
</li>
</ol>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>与一般cnn结构的区别：</p>
<p>输出采用线性函数替换softmax函数，原因是：yolo除了要预测概率，还要预测对象的位置，softmax无法预测具体的位置。</p>
<h2 id="网络输出"><a href="#网络输出" class="headerlink" title="网络输出"></a>网络输出</h2><p><img data-src="./../images/yolov1%E8%A7%A3%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20240418113819435.png" alt="image-20240418113819435"><br>7×7×30 向量：7×7对应所有网格，30对象每个网格的2个bbox的位置和置信度以及在voc数据集上20种类别的分类概率</p>
<p>2个bbox位置：（x_center, y_center, bbox_width, bbox_height)</p>
<p>2个bbox的置信度：bbox内存在对象的概率×bbox与真实bbox的IOU</p>
<p><img data-src="./../images/yolov1%E8%A7%A3%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20240418114417632.png" alt="image-20240418114417632"></p>
<p>关于网格：</p>
<p><img data-src="./../images/yolov1%E8%A7%A3%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-04-18%20115357.png"></p>
<p>如上图所示：</p>
<p>黄色框代表目标的GT值，也就是车、狗、自行车的真实位置，<font face="黑体" color="red" size="5">根据真实值可以知道每个目标的中心点即上图绿色的点落在了49个网格中的哪些网格即上图绿色的网格，那么中心点所在的网格就负责进行预测这个目标，</font>其他网格因为bbox内存在对象的概率为0，那么对应的置信度也为0了，即使有的bbox可能与真实框交并比值很大，也因为置信度为0不会造成干扰。</p>
<p><img data-src="./../images/yolov1%E8%A7%A3%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-04-18%20121543.png"></p>
<p>以上图左上角汽车举例，黄色框为GT，中心点落在绿色小框内，所以中线点落在绿色小框的预测框有汽车的pr为1，比如蓝色大框，即便与汽车真实框的IOU值不低，但是蓝色大框的中心点并不在绿色小框而是在蓝色小框，那么对应的蓝色大框预测有汽车的置信度为0。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>49个格点，含有物体的格点往往只有3、4个，其余全是不含有物体的格点。此时如果不采取点措施，那么物体检测的mAP不会太高，因为模型更倾向于不含有物体的格点。<em>lambda</em><sub>coord</sub>与 <em>lambda</em><sub>noobj</sub>的作用，就是让含有物体的格点，在损失函数中的权重更大，<strong>让模型更加“重视”含有物体的格点所造成的损失</strong>。</p>
<p><img data-src="./../images/yolov1%E8%A7%A3%E8%AF%BB%E7%AC%94%E8%AE%B0/image-20240418145918216.png" alt="image-20240418145918216"></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 chatglm</tag>
      </tags>
  </entry>
  <entry>
    <title>《Deep Learning》第一章读书笔记一</title>
    <url>/post/245ac29.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>最近回过头来在看<a href="https://github.com/exacity/deeplearningbook-chinese"><font color="red">《Deep Learning》</font></a> 这本书，经过三年的工作时间，再看这本书的时候曾经理解不了的问题或者推导原理有了自己切身的认识与思考，所以现在想把自己曾经算是一个半路出家的机器视觉从业者从新手到上手的一些原理性和实践性的点加上我自己的思考把底层的基础点分享出来，帮助大家可以更直观的理解和学习</p>

</blockquote>
<span id="more"></span>

<h1 id="线性模型最著名的局限性"><a href="#线性模型最著名的局限性" class="headerlink" title="线性模型最著名的局限性"></a>线性模型最著名的局限性</h1><p>无法学习异或（XOR）函数，即f([0; 1]; w) = 1 和f([1; 0]; w) = 1，但f([1; 1]; w) = 0 和f([0; 0]; w) = 0。</p>
<h2 id="常用的逻辑函数都有哪些？"><a href="#常用的逻辑函数都有哪些？" class="headerlink" title="常用的逻辑函数都有哪些？"></a>常用的逻辑函数都有哪些？</h2><ol>
<li><p>与(AND): 输入全1输出1，输入有0输出0</p>
</li>
<li><p>或(OR):输入全0输出0，输入有1输出1</p>
</li>
<li><p>与非(NAND):输入全1输出0，输入有0输出1</p>
</li>
<li><p>或非(NOR):输入全0输出1，输入有1输出0</p>
</li>
<li><p>异或(XOR):输入相同输出0，输入相异输出1</p>
</li>
<li><p>同或(XNOR):输入相同输出1，输入相异输出0</p>
</li>
</ol>
<p>这里我们根据下图更好理解一点：</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97.png" alt="逻辑运算"></p>
<p>​      可以看出，与、与非、或以及或非都可以用线性模型来进行分类，也可以根据差异性进行区分，这就类似一种学习能力能够实现分类，所以延伸到深度学习，因为当时的线性模型无法学习同或以及异或函数，这个缺陷在当时难以被接受，便由此引发了神经网络热潮的第一次大衰退。</p>
<h2 id="那么神经网络又是如何解决异或函数的表达问题呢？"><a href="#那么神经网络又是如何解决异或函数的表达问题呢？" class="headerlink" title="那么神经网络又是如何解决异或函数的表达问题呢？"></a>那么神经网络又是如何解决异或函数的表达问题呢？</h2><p>​        首先我们先给出一个最简单的网络模型以及输入输出的表达。</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.png" alt="神经网络"></p>
<p>​        然后，我们根据异或函数的输入输出反推各神经节点的参数值，具体情况如下图推导过程。</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20210422150622.jpg" alt="微信图片_20210422150622"><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20210422150655.jpg" alt="微信图片_20210422150655"><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20210422150701.jpg" alt="微信图片_20210422150701"></p>
<p>​        至此，我们可以看出，合理的参数取值可以实现异或函数XOR的表达，这个进步完全弥补了线性模型的缺陷，深度学习也因此迎来新一波的学习浪潮。</p>
]]></content>
      <categories>
        <category>《Deep Learning》读书笔记</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>《Deep Learning》第九章读书笔记一</title>
    <url>/post/434b3c5a.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>关于卷积的运算过程相信大家已经读过各种各样的解释了，本文旨在以图示的方法从浅到深由单张图像到多张图像的卷积的图示形象的向大家解释卷积的基本原理，从单通道到多通道在卷积过程中输入到输出的具体映射都可以看到，相信在阅读本文之后，大家对卷积会有更直观的认识</p>

</blockquote>
<span id="more"></span>

<h1 id="关于卷积"><a href="#关于卷积" class="headerlink" title="关于卷积"></a>关于卷积</h1><h2 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h2><p>​    卷积核——kernel 、 filter</p>
<p>​    填充——padding</p>
<p>​    滑动步长——slides</p>
<p>​    通道数——channel</p>
<p>​    特征映射——feature map</p>
<p>​    张量——tensor</p>
<h2 id="卷积过程"><a href="#卷积过程" class="headerlink" title="卷积过程"></a>卷积过程</h2><p>​        相信大家对于二维数据的卷积形式已经很熟悉了，也知道了卷积的具体本质相当于矩阵乘法。这里我们直接以图像的表述方式来向大家展现卷积在神经网络中的过程。</p>
<p>​        这里首先是对几个张量的说明：</p>
<p>​        当我们输入1张长度为4宽度为4通道为4的图像时，我们可以表述输入为</p>
<p><span id="inline-red"> [要处理的图像数量，每张图像的高度，每张图像的宽度，每张图像的通道数] 即[batch, in_height, in_width, in_channels] </span></p>
<p>或许有人会疑惑？为什么图像的通道可以为4或者更大，我们以往知道的都是3通道啊？</p>
<p>​        是的，通常我们常见的是3通道的图像，至于4通道的图像是可以人为定义第四通道的数据的，比如令第四通道=0或者第四通道=第一二三的任意组合，都是可以的，以此类推，更多通道的也是可以参照理解。我记得曾经有一篇论文就是网络的输入是4通道的数据，其中第四通道=resize(第一通道)+resize(第二通道)+resize(第三通道)+0，可能文字不太好理解，具体可参见下图：</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%9B%9B%E9%80%9A%E9%81%93%E5%9B%BE%E5%83%8F.png" alt="四通道图像"></p>
<p>那么单张图像的张量形式可以表示为:</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/v2-082a6e222ed329eeac5b55ab715f807e_r.jpg" alt="单张图像的张量形式"></p>
<p>其次是卷积核（也称滤波器）的张量形式为</p>
<p><span id="inline-red"> [卷积核高度，卷积核宽度，输入图像的通道数，卷积输出的通道数],即[filter_height, filter_width, in_channels, out_channels]</span></p>
<div class="note danger"><p>out_channels即是卷积之后的feature_map的通道数，也是卷积核的个数</p></div>

<p>那么多个卷积核的张量形式可以表示为：</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/v2-5740cd72056f93fd65384833d453e818_r.jpg" alt="多个卷积核的张量形式"></p>
<h2 id="具体卷积过程可以参考下图"><a href="#具体卷积过程可以参考下图" class="headerlink" title="具体卷积过程可以参考下图"></a>具体卷积过程可以参考下图</h2><h3 id="首先介绍单张图像输入的卷积过程"><a href="#首先介绍单张图像输入的卷积过程" class="headerlink" title="首先介绍单张图像输入的卷积过程"></a>首先介绍单张图像输入的卷积过程</h3><p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%8D%B7%E7%A7%AF%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="卷积示意图"></p>
<h3 id="其次介绍多张图像输入的卷积过程"><a href="#其次介绍多张图像输入的卷积过程" class="headerlink" title="其次介绍多张图像输入的卷积过程"></a>其次介绍多张图像输入的卷积过程</h3><p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%A4%9A%E5%BC%A0%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt="多张图像卷积示意图"></p>
<h2 id="关于卷积的运算"><a href="#关于卷积的运算" class="headerlink" title="关于卷积的运算"></a>关于卷积的运算</h2><p>在tensorflow中经常用到的是conv2d函数，我用的版本是1.14，其conv2d的具体形式参见</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.nn.conv2d(<span class="built_in">input</span>, <span class="built_in">filter</span>, strides, padding, use_cudnn_on_gpu=<span class="literal">None</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>strides: 长度为4的一维向量，表示在input每个维度上的步长</p>
<p>padding：分为’VALID’与’SAME’</p>
<p>​                VALID——不对输入图像填充，直接卷积</p>
<p>​                SAME——表示卷积后的feature_map要与input的size相同（注意<font color="red">size是指[width,height]而不是四维tensor的shape</font>）所以<font color="red">要先对输入图像填充，再卷积</font></p>
<p>顺便给出卷积后的size计算大小公式，前提输入w_i=h_i, 卷积核 w_f=h_f,每边填充长度为p,步长为s,则卷积后的宽w_o或者高h_o</p>
<p>$$<br>w_{o}=\frac{w_{i}-w_{f}+2p}{s}+1<br>$$</p>
<h2 id="关于卷积核尺寸的选择"><a href="#关于卷积核尺寸的选择" class="headerlink" title="关于卷积核尺寸的选择"></a>关于卷积核尺寸的选择</h2><h3 id="为什么不建议使用偶数size的kernel？"><a href="#为什么不建议使用偶数size的kernel？" class="headerlink" title="为什么不建议使用偶数size的kernel？"></a>为什么不建议使用偶数size的kernel？</h3><p>​        答：推导过程如下：<br>$$<br>\frac{w-f+2p}{s}=w<br>$$<br>这里f=2k<br>$$<br>\frac{w-2k+2p}{s}=w-1<br>$$</p>
<p>$$<br>w-2k-2p=(w-1)s<br>$$</p>
<p>$$<br>2p=(w-1)(s-1) +(2k-1)<br>$$</p>
<p>若s为奇数2m+1,则上式化为：<br>$$<br>2p=(w-1)\times2m+(2k-1)<br>$$</p>
<p>$$<br>2p=偶数+奇数=奇数<br>$$</p>
<p><font color="red">显然不成立！</font></p>
<div class="note danger"><p>所以一般不使用偶数size的kernel,从而避免padding不居中的问题</p></div>

<h3 id="为什么经常使用3×3或5×5的卷积核，而不是7×7或者11×11？"><a href="#为什么经常使用3×3或5×5的卷积核，而不是7×7或者11×11？" class="headerlink" title="为什么经常使用3×3或5×5的卷积核，而不是7×7或者11×11？"></a>为什么经常使用3×3或5×5的卷积核，而不是7×7或者11×11？</h3><p>​        答：推导过程如下：<br>​        假设一张单通道的7×7图像进行7×7卷积输出一个值</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/v2-b72c69b808b48b1772938cb6950f2bc3_r.jpg" alt="卷积核尺寸逐渐减小"></p>
<p>​        三种卷积思路都是实现同一种卷积结果，但是可以看出第三种的参数个数最少，相较第一种参数量下降44.8%，这在实际内存中是非常客观的缩减量。</p>
<p>从卷积层的深入在特征映射上的反映：<img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B9%9D%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/v2-b2f87d8c2793f24574f74a1abcbadf8d_r.jpg" alt="卷积核在特征映射上的反映"></p>
<div class="note danger"><p>由此可以看出小尺寸的卷积核不仅降低了参数量，还能随着卷积层的增多，还能抽取更丰富的特征信息</p></div>
]]></content>
      <categories>
        <category>《Deep Learning》读书笔记</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>《Deep Learning》第一章读书笔记二</title>
    <url>/post/39c58280.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>相信大家都知道我们经常在深度学习评价指标中常用的精度、召回率、准确率以及ROC曲线，我之前对部分指标的理解还是不到位，所以这里再次把更直观的解释展示出来，方便大家理解</p>

</blockquote>
<span id="more"></span>

<h2 id="关于TP-、-FP、-TN以及FN"><a href="#关于TP-、-FP、-TN以及FN" class="headerlink" title="关于TP 、 FP、  TN以及FN"></a>关于TP 、 FP、  TN以及FN</h2><p>​        假设当前一张图像样本里总共包括230个行人，现在对图像中的行人进行检测，结果检测出来100个目标框，其中60个框检测到了行人，其余40个框没有检测到行人</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/%E7%B2%BE%E5%BA%A6%E7%A4%BA%E6%84%8F%E5%9B%BE2.png"></p>
<p>根据上图</p>
<p>$$<br>TP = 60,FP=40, FN=230-60=170<br>$$<br>所以</p>
<h2 id="精度Precision"><a href="#精度Precision" class="headerlink" title="精度Precision"></a>精度Precision</h2><p>$$<br>precision=\frac{TP}{TP+FP}=\frac{60}{60+40}=0.6<br>$$</p>
<h2 id="召回率Recall"><a href="#召回率Recall" class="headerlink" title="召回率Recall"></a>召回率Recall</h2><p>$$<br>recall=\frac{TP}{TP+FN}=\frac{60}{60+170}≈0.26<br>$$</p>
<p>举一个图像实例</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/IOU%E9%98%88%E5%80%BC%E7%A4%BA%E6%84%8F%E5%9B%BE3.png"><br>$$<br>precision=\frac{TP}{TP+FP}=\frac{1}{1+0}=1<br>$$</p>
<p>$$<br>recall=\frac{TP}{TP+FN}=\frac{1}{1+4}=0.2<br>$$</p>
<h2 id="为什么说仅仅精度无法有力说明网络模型的检测能力呢？"><a href="#为什么说仅仅精度无法有力说明网络模型的检测能力呢？" class="headerlink" title="为什么说仅仅精度无法有力说明网络模型的检测能力呢？"></a>为什么说仅仅精度无法有力说明网络模型的检测能力呢？</h2><p>​        假设上面的例子里样本总共包含2300个目标，对样本中的目标进行检测，结果检测出来100个目标框，其中60个框检测到了目标，其余40个框没有检测到目标。</p>
<p>那么，<br>$$<br>precision=\frac{TP}{TP+FP}=\frac{60}{60+40}=0.6<br>$$</p>
<p>$$<br>recall=\frac{TP}{TP+FN}=\frac{60}{60+1700}≈0.026<br>$$</p>
<p>​        可以看出，精度在两种情况下没有变化，而召回率则差异巨大，所以要综合指标进行考量。</p>
<h2 id="目标检测下IoU与FP、TP的关系"><a href="#目标检测下IoU与FP、TP的关系" class="headerlink" title="目标检测下IoU与FP、TP的关系"></a>目标检测下IoU与FP、TP的关系</h2><p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/IOU%E9%98%88%E5%80%BC%E7%A4%BA%E6%84%8F%E5%9B%BE.png"><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/IOU%E9%98%88%E5%80%BC%E7%A4%BA%E6%84%8F%E5%9B%BE2.png"></p>
<h2 id="延伸扩展"><a href="#延伸扩展" class="headerlink" title="延伸扩展"></a>延伸扩展</h2><h3 id="平均精度AP-average-precision）"><a href="#平均精度AP-average-precision）" class="headerlink" title="平均精度AP(average precision）"></a>平均精度AP(average precision）</h3><p><span id="inline-red"> AP: AP at IoU= 0.50: 0.05: 0.95 </span></p>
<div class="note default"><p> 含义：一般情况下通常使用的IoU取值0.5，0.05指step, 0.95指自己确定阈值范围的最大阈值。那么AP即指从0.5到0.95，每0.05步长取一个阈值对数据集中的每张图片进行单个类别目标检测，得到一组所有样本的precision值，当把这10组精度值都得到之后，再取其平均值，即可得到AP.</p></div>

<p>$$<br>AP^{50}，即指当IoU取值0.5时的数据集中的每张图片的单个类别目标检测的精度先求和再求其平均值。<br>$$</p>
<p>$$<br>AP^{75}，即指当IoU取值0.75时的数据集中的每张图片的单个类别目标检测的精度先求和再求其平均值。<br>$$</p>
<h3 id="mAP-mean-average-precision）"><a href="#mAP-mean-average-precision）" class="headerlink" title="mAP(mean average precision）"></a>mAP(mean average precision）</h3><div class="note default"><p> 含义：当IoU取某个定值时的数据集中的每张图片的所有类别目标检测的精度先求出每种类别的AP再求和最后求其平均值。</p></div>

<h3 id="通常赛事中的评价指标以及含义可参见下图"><a href="#通常赛事中的评价指标以及含义可参见下图" class="headerlink" title="通常赛事中的评价指标以及含义可参见下图"></a>通常赛事中的评价指标以及含义可参见下图</h3><p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/1__IkyrFHlqt_xCovk7l0rQQ.png"></p>
<h2 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h2><p>$$<br>accuracy=\frac{TP+TN}{TP+TN+FP+FN}=\frac{TP+TN}{Total}<br>$$</p>
<h2 id="F-Score"><a href="#F-Score" class="headerlink" title="F-Score"></a>F-Score</h2><p>分别比较两个模型的精度和召回率比较困难得出哪个模型更好，因此，为了使它们具有可比性，建议使用F-Score<br>$$<br>F_{score} = \frac{2\ast precision\ast recall}{precision + recall}<br>$$</p>
<h2 id="ROC-Receiver-operating-characteristic-曲线"><a href="#ROC-Receiver-operating-characteristic-曲线" class="headerlink" title="ROC(Receiver operating characteristic)曲线"></a>ROC(Receiver operating characteristic)曲线</h2><p>显示分类模型在所有分类阈值下的效果的图表。</p>
<p>X轴：真正例率 True Positive Rate，简称TPR<br>$$<br>TPR=\frac{TP}{TP+FN}<br>$$<br>Y轴：假正例率 False Positive Rate，简称FPR<br>$$<br>FPR=\frac{FP}{FP+TN}<br>$$<br>​    这里我给出一组例子方便大家更具体的理解ROC曲线：假定现在有总数为100的样本，其中正样本50张，负样本50张，现在要对样本进行分类，首先在阈值设定为0.3的时候，得到每张图像的分类结果，进行统计，再设定阈值为0.5对所有样本进行分类并统计，最后设定阈值为0.7对所有样本进行分类并统计，这样我们便会得到三组当在不同阈值下的分类统计数表。具体表格内容如下图：<img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/FPR%E4%B8%8ETPR.png" alt="FPR与TPR"></p>
<p>当然，你也许会问，这些数据背后的逻辑是什么呢？或者有什么隐含的关系吗？</p>
<p>我们不妨推理一下，当阈值设的越低的时候，是不是有更多的样本会被分类为正样本，即更多的正样本被分类为正样本，更多的负样本被分类为正样本，那么TP与FP的数值应该是随着阈值的降低而增大的，那么相应的，因为正样本与负样本的各类的总数是没有变化的，所以正样本被认为是负样本的数量即FN是减少的，负样本被认为是负样本的数量即TN也是减少的。</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/AOC1.png"></p>
<p>反映在曲线图上即如下图所示：</p>
<p><img data-src="../images/%E3%80%8ADeep-Learning%E3%80%8B%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%BA%8C/ROC2.png"></p>
<p>我以上图红点、绿点、蓝点、黄点以及紫点进行说明：黄点代表阈值为0.3的分类结果，蓝点代表阈值为0.5的分类结果，绿点代表阈值为0.7的分类结果。</p>
<p>​    （1）<font color="red">将同一模型每个阈值 的 (FPR, TPR) 座标都画在ROC空间里，就成为特定模型的ROC曲线。</font><br>​    （2）红点：当阈值设置的足够大时，分类为正样本的数量理论上接近于0，即包括TP=0以及FP=0，那么对应的TPR=0,FPR=0,对应到上图，相当于坐标轴的（0，0）点，则可得出<font color="red">红点对应的是阈值足够大的分类情况。</font><br>​        反之，当当阈值设置的足够小时，分类为正样本的数量理论上达到最大，相当于TP=所有的正样本数，FP=所有的负样本数，那么此时的TPR=1,FPR=1,对应到上图，相当于坐标轴的（1，1）点，则可得出<font color="red">紫点对应的是阈值足够小的分类情况。</font><br>​    （3）越靠近左上角准确度越高<br>当FPR=0时，得出FP=0,那么TPR=TP/(TP+0)=1, 又因为所有正样本都被分为正，那么正样本被分为负的数量就是0，即FN=0, 对应到图中，正确；那么此时的准确度ACC=(TP+TN)/(TP+FP+TN+FN)=(TP+TN)/(TP+0+TN+0)=1,所以证明了<font color="red">越靠近左上角的点准确度越高。同理可证，离右下角越近的点，预测越不准。</font><br>​    (4) <font color="red">随着阈值降低，ROC上的点向右上方移动，随着阈值变大，ROC上的点向左下方移动。</font></p>
]]></content>
      <categories>
        <category>《Deep Learning》读书笔记</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>关于TensorRT和TF-TRT的一些事儿</title>
    <url>/post/575cdcda.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>近期一直在研究TensorRT的加速原理，对于层融合起先一直不理解，现在总算是知道加速的原理了，所以就把自己理解到的结合网上找到的一些资料进行整理汇总，最后我贴出自己整写的一个关于TensorRT加速原理的PPT，有需要的同学可以自己下载下来看看</p>

</blockquote>

<span id="more"></span>

<h3 id="TensorRT简介"><a href="#TensorRT简介" class="headerlink" title="TensorRT简介"></a>TensorRT简介</h3><p>TensorRT是NVIDIA 推出的基于CUDA和cudnn的进行高性能推理（Inference）加速引擎。</p>
<p>●曾用名：GPU Inference Engine（GIE）</p>
<p> ●Tensor：表示数据流动以张量的形式</p>
<p>●RT：Runtime</p>
<h3 id="训练阶段优化方法"><a href="#训练阶段优化方法" class="headerlink" title="训练阶段优化方法"></a>训练阶段优化方法</h3><ol>
<li><p>外部数据：数据增强</p>
<p>其中具体方式有：平移、 翻转、噪声、对比度、缩放、尺度变换</p>
</li>
<li><p>内部网络：</p>
<ol>
<li><p>一阶优化：</p>
<ol>
<li>梯度下降：随机梯度下降、批量梯度下降、小批量梯度下降</li>
<li>权重初始化</li>
<li>批规范化</li>
<li>Dropout</li>
<li>动量法：AdaGrad      RMSProp      AdaDeita      Adam</li>
</ol>
</li>
<li><p>分治法：</p>
<ol>
<li>坐标下降法</li>
<li>SMO</li>
<li>分阶段优化</li>
</ol>
</li>
<li><p>二阶优化：</p>
<ol>
<li><p>牛顿法</p>
</li>
<li><p>拟牛顿法</p>
</li>
<li><p>可信域牛顿</p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><img data-src="../images/%E5%85%B3%E4%BA%8ETensorRT%E5%92%8CTF-TRT%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B%E5%84%BF/%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96.png" alt="训练优化"></p>
<h3 id="推理阶段优化方法"><a href="#推理阶段优化方法" class="headerlink" title="推理阶段优化方法"></a>推理阶段优化方法</h3><ol>
<li><p>模型压缩：</p>
<ol>
<li>前端压缩：<ol>
<li>知识蒸馏</li>
<li>模型紧凑结构化</li>
<li>滤波器剪枝</li>
</ol>
</li>
<li>后端压缩：<ol>
<li>低秩近似：矩阵分解、分组卷积、卷积分解</li>
<li>网络二值化</li>
<li>参数量化</li>
<li>随机剪枝：突触剪枝、神经元剪枝、权重矩阵剪枝</li>
</ol>
</li>
</ol>
</li>
<li><p>优化推理引擎</p>
<ol>
<li><p>TVM</p>
</li>
<li><p>TensorRT</p>
</li>
<li><p>OpenVINO</p>
</li>
</ol>
</li>
</ol>
<p><img data-src="../images/%E5%85%B3%E4%BA%8ETensorRT%E5%92%8CTF-TRT%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B%E5%84%BF/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96.png" alt="推理优化"></p>
<h3 id="TensorRT加速原理"><a href="#TensorRT加速原理" class="headerlink" title="TensorRT加速原理"></a>TensorRT加速原理</h3><h4 id="TensorRT优化方式"><a href="#TensorRT优化方式" class="headerlink" title="TensorRT优化方式"></a>TensorRT优化方式</h4><ol>
<li>权重与激活精度校准：通过将模型量化为 INT8 来更大限度地提高吞吐量，同时保持高准确度</li>
<li>层与张量融合：通过融合内核中的节点，优化 GPU 显存和带宽的使用</li>
<li>内核自动调整：基于目标 GPU 平台选择最佳数据层和算法</li>
<li>动态张量显存：更大限度减少显存占用，并高效地为张量重复利用内存</li>
<li>多流执行：用于并行处理多个输入流的可扩展设计</li>
</ol>
<h4 id="优化方式的可行性分析"><a href="#优化方式的可行性分析" class="headerlink" title="优化方式的可行性分析"></a>优化方式的可行性分析</h4><ol>
<li>样本数据中存在角度、目标位置、目标姿态以及数据噪声，通过训练，我们获得具有强鲁棒性的模型，该模型对噪声有一定的容忍度。所以当进行推理时，我们便可以将FP32数据转低精度执行，引起的误差视为引入噪声，噪声引进的变动同样会使各个层的激活值输出发生变动，然而却对结果影响不大，所以以低精度推理是可行的；</li>
<li>推理中的时间消耗主要集中在：<ol>
<li>每次启动CUDA核心需要大量时间</li>
<li>每一层输入/输出张量的读写耗时<br>所以按照一般推理工作流，数据流经每一层都需要输入输出以及调用，势必造成时间线越拉越长，因此层与张量融合就是通过聚合具有足够相似参数和相同源张量的operations，减少调用CUDA次数，将零碎数据整理到一起传输，减少向CPU传输次数，最终实现减少横向时间</li>
</ol>
</li>
<li>在每个tensor的使用期间，TensorRT会为其指定显存，避免显存重复申请，减少内存占用和提高重复使用效率</li>
<li>TensorRT里边调用了一些方法，以一个最合理的方式去调用、操作这些数据</li>
<li>CUDA多流执行把数据在传输过程中进行计算，隐藏了传输部分</li>
</ol>
<h3 id="TensorRT-amp-TF-TRT"><a href="#TensorRT-amp-TF-TRT" class="headerlink" title="TensorRT &amp; TF-TRT"></a>TensorRT &amp; TF-TRT</h3><ol>
<li><p>TensorRT是由NVIDIA开发，而TF-TRT是由NVIDIA和Google TensorFlow团队共同开发</p>
</li>
<li><p>TensorRT的当前版本支持3种“解析器”：Caffe，UFF和ONNX。根据<a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-release-notes/tensorrt-7.html#rel_7-0-0">TensorRT 7.0.0发行说明中</a>的“弃用Caffe解析器和UFF解析器”，不建议使用Caffe和UFF解析器，首选ONNX解析器</p>
</li>
<li><p>为了优化TensorFlow模型，您可以选择将pb转换为UFF或ONNX，然后转换为TensorRT引擎。如果模型中的某些层不被TensorRT支持（<a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-support-matrix/index.html#layers-matrix">请查看此表</a>），则可以：</p>
<ol>
<li>用插件替换这些层；</li>
<li>在构建TensorRT引擎时不要包括这些层，而是获取TensorRT引擎输出并进行处理以后再完成这些层的功能</li>
</ol>
</li>
<li><p>TF-TRT的优缺点：</p>
<p>​    优点：</p>
<ol>
<li>API易于使用；</li>
<li>无需担心插件。</li>
</ol>
<p>​    缺点：</p>
<ol>
<li>需要将整个TensorFlow库存储在平台中（这对部署环境不利）</li>
<li>需要在运行时将TensorFlow加载到内存中</li>
<li>通常比纯TensorRT引擎运行慢</li>
</ol>
</li>
<li><p>UFF TensorRT引擎的运行速度通常比TF-TRT优化图快得多，原因可能如下：</p>
<ol>
<li><p>在整个图上进行优化，而不仅仅是在图的单个节点或部分上。TF-TRT是针对部分优化，而TensorRT是对整个计算图做优化；</p>
</li>
<li><p>基于计算图不同的优化方式，所以在后续选择版精度FP16甚至INT8时，在TF-TRT情况下也仅在图形的某些优化部分上进行FP16/INT8计算</p>
</li>
<li><p>TensorRT在对CUDA内核的选取上有自己设计的优化机制，可以根据数据size\shape自动选取适合的CUDA内核，所以相较TF-TRT也是节省了时间</p>
</li>
</ol>
</li>
</ol>
<p><a href="/download/tensorrt.pptx"><font color="blue">点击下载TensorRT原理简析PPT</font></a></p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/35657027">高性能深度学习支持引擎实战——TensorRT</a></li>
<li><a href="https://github.com/jkjung-avt/tensorrt_demos/issues/43">TensorRT 与 TF-TRT的区别</a></li>
<li><a href="https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664">Hardware for Deep Learning. Part 3: GPU</a></li>
<li><a href="https://blog.tensorflow.org/2018/04/speed-up-tensorflow-inference-on-gpus-tensorRT.html">Speed up TensorFlow Inference on GPUs with TensorRT</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/138059904">一文看懂深度学习模型压缩和加速</a></li>
</ol>
]]></content>
      <tags>
        <tag>TensorRT实战记</tag>
      </tags>
  </entry>
  <entry>
    <title>书生·浦语大模型全链路开源体系课程笔记一</title>
    <url>/post/91f549e1.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>参加由上海人工智能实验室发起的《书生·浦语大模型全链路开源体系》的课程以及笔记记录</p>

</blockquote>
<span id="more"></span>

<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="InternLM2-Chat-1-8B"><a href="#InternLM2-Chat-1-8B" class="headerlink" title="InternLM2-Chat-1.8B"></a><a href="https://huggingface.co/internlm/internlm2-chat-1_8b">InternLM2-Chat-1.8B</a></h3><ul>
<li><p>使用 <code>InternLM2-Chat-1.8B</code> 模型生成 300 字的小故事</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;internlm2-chat-1_8b&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Set `torch_dtype=torch.float16` to load model in float16, otherwise it will be loaded as float32 and cause OOM Error.</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;internlm2-chat-1_8b&quot;</span>, torch_dtype=torch.float16, trust_remote_code=<span class="literal">True</span>).cuda()</span><br><span class="line">model = model.<span class="built_in">eval</span>()</span><br><span class="line">history=[]    </span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:   </span><br><span class="line">    question = <span class="built_in">input</span>(<span class="string">&quot;请提问: &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> question == <span class="string">&quot;quit&quot;</span>:        <span class="comment">### 键入 quit 终止对话</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已关闭对话&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        response, history = model.chat(tokenizer, question, history=history)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;答：&#x27;</span>, response)</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p><img data-src="./../images/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-04-01%20112938.png"></p>
<h3 id="huggingface-hub"><a href="#huggingface-hub" class="headerlink" title="huggingface_hub"></a><a href="https://huggingface.co/docs/huggingface_hub/main/en/guides/download">huggingface_hub</a></h3><ul>
<li>使用 <code>huggingface_hub</code>下载单文件 <a href="https://huggingface.co/internlm/internlm2-chat-7b">internlm2-chat-7b</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> hf_hub_download</span><br><span class="line">hf_hub_download(repo_id=<span class="string">&quot;internlm/internlm2-chat-7b &quot;</span>, filename=<span class="string">&quot;config.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/%E4%B9%A6%E7%94%9F%C2%B7%E6%B5%A6%E8%AF%AD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%93%BE%E8%B7%AF%E5%BC%80%E6%BA%90%E4%BD%93%E7%B3%BB%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-04-01%20093848.png"></p>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>InternLM</tag>
      </tags>
  </entry>
  <entry>
    <title>利用Google Colab成功测试TensorRT指南一</title>
    <url>/post/f9d0431a.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>前面总结了在本机上与谷歌colab上利用不同显卡对相同样本的检测结果，对比了二者推理耗时，最终发现借助tensorrt可以使推理时常缩减数倍，所以想着在更好的显卡上这个数值还能否再有所优化，因此本篇文章主要就如何在google colab上使用tensorrt做以说明。</p>

</blockquote>

<span id="more"></span>

<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/f9d0431a.html"><font color="red">利用Google Colab成功测试TensorRT指南一</font></a> </p>
<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/4f1188dc.html"><font color="blue">利用Google Colab成功测试TensorRT指南二</font></a> </p>
<h3 id="在-google-drive-新建笔记本并配置GPU"><a href="#在-google-drive-新建笔记本并配置GPU" class="headerlink" title="在 google drive 新建笔记本并配置GPU"></a>在 google drive 新建笔记本并配置GPU</h3><p>Colab的使用方法可以参见<a href="https://zhuanlan.zhihu.com/p/129663051"><font color="blue">使用Google colab免费GPU训练模型攻略</font></a></p>
<p>创建好笔记本之后打开；</p>
<h3 id="查看所分配得到的GPU资源"><a href="#查看所分配得到的GPU资源" class="headerlink" title="查看所分配得到的GPU资源"></a>查看所分配得到的GPU资源</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!nvidia-smi</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2016-57-25.png"></p>
<h3 id="挂载云端硬盘"><a href="#挂载云端硬盘" class="headerlink" title="挂载云端硬盘"></a>挂载云端硬盘</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">&#x27;/content/gdrive&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>输入验证码后挂载成功。</p>
<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-00-25.png"></p>
<h3 id="切换工作目录"><a href="#切换工作目录" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">project_path = <span class="string">&#x27;/content/gdrive/My Drive/Colab Notebooks/TensorRT Colab Test&#x27;</span></span><br><span class="line">os.chdir(project_path) </span><br></pre></td></tr></table></figure>

<p>我的工作目录是谷歌硬盘下的Colab Notebooks下的TensorRT Colab Test文件夹</p>
<h3 id="查看当前的CUDA版本"><a href="#查看当前的CUDA版本" class="headerlink" title="查看当前的CUDA版本"></a>查看当前的CUDA版本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!nvcc --version</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-03-47.png"></p>
<h3 id="查看Ubuntu版本"><a href="#查看Ubuntu版本" class="headerlink" title="查看Ubuntu版本"></a>查看Ubuntu版本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!<span class="built_in">cat</span> /etc/issue</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-05-02.png"></p>
<h3 id="查看Tensorflow版本"><a href="#查看Tensorflow版本" class="headerlink" title="查看Tensorflow版本"></a>查看Tensorflow版本</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="built_in">print</span>(tf.__version__)</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-06-30.png"></p>
<p>现在我要换掉cuda cudnn 以及tensorflow的版本，所以先要卸载掉就版本。</p>
<h3 id="卸载当前CUDA版本"><a href="#卸载当前CUDA版本" class="headerlink" title="卸载当前CUDA版本"></a>卸载当前CUDA版本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!sudo apt-get --purge remove cuda nvidia* libnvidia-*</span><br><span class="line">!sudo dpkg -l | grep cuda- | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | xargs -n1 dpkg --purge</span><br><span class="line">!sudo apt-get remove cuda-*</span><br><span class="line">!sudo apt autoremove</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/FireShot%20Capture%20067%20-%20tensorrt%20colab%20test.ipynb%20-%20Colaboratory%20-%20colab.research.google.com.png"></p>
<h3 id="安装CUDA-10-0"><a href="#安装CUDA-10-0" class="headerlink" title="安装CUDA 10.0"></a>安装CUDA 10.0</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb</span><br><span class="line">!sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb</span><br><span class="line">!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub</span><br><span class="line">!sudo apt-get update</span><br><span class="line">!wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb</span><br><span class="line">!sudo apt install -y ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb</span><br><span class="line">!sudo apt-get update</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/FireShot%20Capture%20070%20-%20tensorrt%20colab%20test.ipynb%20-%20Colaboratory%20-%20colab.research.google.com.png"></p>
<h3 id="安装nvidia驱动"><a href="#安装nvidia驱动" class="headerlink" title="安装nvidia驱动"></a>安装nvidia驱动</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!sudo apt-get -y install nvidia-driver-418</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-16-41.png"></p>
<h3 id="安装CUDNN"><a href="#安装CUDNN" class="headerlink" title="安装CUDNN"></a>安装CUDNN</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!sudo apt-get install -y \</span><br><span class="line">    cuda-10-0 \</span><br><span class="line">    libcudnn7=7.6.2.24-1+cuda10.0  \</span><br><span class="line">    libcudnn7-dev=7.6.2.24-1+cuda10.0 --allow-change-held-packages</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-18-17.png"></p>
<h3 id="检查CUDA是否已经改变了版本"><a href="#检查CUDA是否已经改变了版本" class="headerlink" title="检查CUDA是否已经改变了版本"></a>检查CUDA是否已经改变了版本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!nvcc --version</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-19-50.png"></p>
<h3 id="安装TensorRT"><a href="#安装TensorRT" class="headerlink" title="安装TensorRT"></a>安装TensorRT</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!sudo dpkg -i <span class="string">&quot;nv-tensorrt-repo-ubuntu1804-cuda10.0-trt7.0.0.11-ga-20191216_1-1_amd64.deb&quot;</span></span><br><span class="line">!sudo apt-key add /var/nv-tensorrt-repo-cuda10.0-trt7.0.0.11-ga-20191216/7fa2af80.pub</span><br><span class="line">!sudo apt-get update</span><br></pre></td></tr></table></figure>

<div class="note danger"><p>这里的nv-tensorrt-repo-ubuntu1804-cuda10.0-trt7.0.0.11-ga-20191216_1-1_amd64.deb是在官网根据自己系统的环境下载下来然后从本地上传到谷歌硬盘的工作目录下</p></div>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-24-37.png"></p>
<h3 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!sudo apt-get install libnvinfer7=7.0.0-1+cuda10.0 libnvonnxparsers7=7.0.0-1+cuda10.0 libnvparsers7=7.0.0-1+cuda10.0 libnvinfer-plugin7=7.0.0-1+cuda10.0 libnvinfer-dev=7.0.0-1+cuda10.0 libnvonnxparsers-dev=7.0.0-1+cuda10.0 libnvparsers-dev=7.0.0-1+cuda10.0 libnvinfer-plugin-dev=7.0.0-1+cuda10.0 python-libnvinfer=7.0.0-1+cuda10.0 python3-libnvinfer=7.0.0-1+cuda10.0</span><br><span class="line"></span><br><span class="line">!sudo apt-mark hold libnvinfer7 libnvonnxparsers7 libnvparsers7 libnvinfer-plugin7 libnvinfer-dev libnvonnxparsers-dev libnvparsers-dev libnvinfer-plugin-dev python-libnvinfer python3-libnvinfer</span><br><span class="line"></span><br><span class="line">!sudo apt-get install tensorrt</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-25-57.png"></p>
<h3 id="验证是否安装成功"><a href="#验证是否安装成功" class="headerlink" title="验证是否安装成功"></a>验证是否安装成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!dpkg -l | grep TensorRT</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-27-31.png"></p>
<h3 id="开始测试，先看看samples-python-uff-ssd例子能不能运行"><a href="#开始测试，先看看samples-python-uff-ssd例子能不能运行" class="headerlink" title="开始测试，先看看samples/python/uff_ssd例子能不能运行"></a>开始测试，先看看samples/python/uff_ssd例子能不能运行</h3><h4 id="解压压缩包"><a href="#解压压缩包" class="headerlink" title="解压压缩包"></a>解压压缩包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!tar zxvf TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.0.cudnn7.6.tar.gz</span><br></pre></td></tr></table></figure>

<p>这里的TensorRT-7.0.0.11.Ubuntu-18.04.x86_64-gnu.cuda-10.0.cudnn7.6.tar.gz也是在官网下载后直接上传到网盘的。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!python uff_ssd/detect_objects.py</span><br></pre></td></tr></table></figure>

<div class="note danger"><p>这里可能会遇到几个问题，特此说明解决办法如下</p></div>

<h4 id="解决ModuleNotFoundError-No-module-named-‘pycuda’"><a href="#解决ModuleNotFoundError-No-module-named-‘pycuda’" class="headerlink" title="解决ModuleNotFoundError: No module named ‘pycuda’"></a>解决ModuleNotFoundError: No module named ‘pycuda’</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!pip install pycuda</span><br></pre></td></tr></table></figure>

<h4 id="解决ModuleNotFoundError-No-module-named-‘graphsurgeon’"><a href="#解决ModuleNotFoundError-No-module-named-‘graphsurgeon’" class="headerlink" title="解决ModuleNotFoundError: No module named ‘graphsurgeon’"></a>解决ModuleNotFoundError: No module named ‘graphsurgeon’</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!pip install graphsurgeon-0.4.1-py2.py3-none-any.whl</span><br></pre></td></tr></table></figure>

<h4 id="解决ImportError-cannot-import-name-‘uff’"><a href="#解决ImportError-cannot-import-name-‘uff’" class="headerlink" title="解决ImportError: cannot import name ‘uff’"></a>解决ImportError: cannot import name ‘uff’</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!pip install uff-0.6.5-py2.py3-none-any.whl</span><br></pre></td></tr></table></figure>

<h4 id="解决ImportError-cannot-import-name-‘NodeDef’"><a href="#解决ImportError-cannot-import-name-‘NodeDef’" class="headerlink" title="解决ImportError: cannot import name ‘NodeDef’"></a>解决ImportError: cannot import name ‘NodeDef’</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!pip uninstall tensorflow</span><br><span class="line">!pip install tensorflow-gpu==1.14.0</span><br></pre></td></tr></table></figure>

<h4 id="开始测试"><a href="#开始测试" class="headerlink" title="开始测试"></a>开始测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">!python TensorRT-7.0.0.11/samples/python/uff_ssd/detect_objects.py TensorRT-7.0.0.11/samples/python/uff_ssd/images/image2.jpg</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/Screenshot%20from%202020-10-10%2017-36-05.png"><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%B8%80/image_inferred.jpg"></p>
<div class="note danger"><p>后面就是以批量图像测试对比推理耗时。</p></div>

<h3 id="完整的笔记文档下载地址"><a href="#完整的笔记文档下载地址" class="headerlink" title="完整的笔记文档下载地址"></a>完整的笔记文档下载地址</h3><p><a id="download" href="/download/tensorrt_colab_test.ipynb"><i class="fas fa-file-download"></i><span> <font color="blue">tensorrt_colab_test.ipynb</font></span></a></p>
]]></content>
      <categories>
        <category>TensorRT实战记</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>利用Google-Colab成功测试TensorRT指南二</title>
    <url>/post/4f1188dc.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>继续在colab上成功安装并配置好TensorRT, 接着我进行了针对几种不同显卡的测试，统计不同显卡(Tesla K80 Tesla P4 Tesla P100 Tesla T4)的批量测试耗时结果，大家可以根据最终的检测结果看出显卡对耗时的影响程度究竟有多大。</p>

</blockquote>

<span id="more"></span>

<p><i class="far fa-hand-point-right"></i><a href="https://bella722.github.io/post/f9d0431a.html"><font color="blue">利用Google Colab成功测试TensorRT指南一</font></a> </p>
<p><i class="fas fa-hand-point-right"></i><a href="https://bella722.github.io/post/4f1188dc.html"><font color="red">利用Google Colab成功测试TensorRT指南二</font></a> </p>
<h3 id="分配得到的环境"><a href="#分配得到的环境" class="headerlink" title="分配得到的环境"></a>分配得到的环境</h3><h4 id="Tesla-K80"><a href="#Tesla-K80" class="headerlink" title="Tesla K80"></a>Tesla K80</h4><p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%BA%8C/Tesla%20K80.png" alt="Tesla K80"></p>
<h4 id="Tesla-P4"><a href="#Tesla-P4" class="headerlink" title="Tesla P4"></a>Tesla P4</h4><p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%BA%8C/Tesla%20P4.png" alt="Tesla P4"></p>
<h4 id="Tesla-P100"><a href="#Tesla-P100" class="headerlink" title="Tesla P100"></a>Tesla P100</h4><p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%BA%8C/Tesla%20P100.png" alt="Tesla P100"></p>
<h4 id="Tesla-T4"><a href="#Tesla-T4" class="headerlink" title="Tesla T4"></a>Tesla T4</h4><p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%BA%8C/Tesla%20T4.png" alt="Tesla T4"></p>
<h3 id="批量测试结果"><a href="#批量测试结果" class="headerlink" title="批量测试结果"></a>批量测试结果</h3><table>
    <tr>
        <td colspan="9"><font color="red"><center>批量推理结果</center></font></td>
    </tr>
    <tr>
        <td colspan="9"><center>Image size(8k×40k), 预测裁剪小图size(300×300)，w方向：8000/300=26，h方向：40000/300= 133，裁剪生成的小图有：26×133 = 3458张</center></td>
    </tr>
    <tr>
        <td colspan="1"><center></center></td>
        <td colspan="2"><center>Tesla K80</center></td>
        <td colspan="2"><center>Tesla P4</center></td>
        <td colspan="2"><center>Tesla P100</center></td>
        <td colspan="2"><center>Tesla T4</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>batch size</center></td>
        <td colspan="1"><center>avg time(ms)</center></td>
        <td colspan="1"><center>tol time(ms)</center></td>
        <td colspan="1"><center>avg time(ms)</center></td>
        <td colspan="1"><center>tol time(ms)</center></td>
        <td colspan="1"><center>avg time(ms)</center></td>
        <td colspan="1"><center>tol time(ms)</center></td>
        <td colspan="1"><center>avg time(ms)</center></td>
        <td colspan="1"><center>tol time(ms)</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>13</center></td>
        <td colspan="1"><center>104.39</center></td>
        <td colspan="1"><center>28083</center></td>
        <td colspan="1"><center>41.78</center></td>
        <td colspan="1"><center>11241</center></td>
        <td colspan="1"><center>23.42</center></td>
        <td colspan="1"><center>6302</center></td>
        <td colspan="1"><center>55.01</center></td>
        <td colspan="1"><center>14799</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>26</center></td>
        <td colspan="1"><center>207.29</center></td>
        <td colspan="1"><center>27985</center></td>
        <td colspan="1"><center>67</center></td>
        <td colspan="1"><center>9046</center></td>
        <td colspan="1"><center></center></td>
        <td colspan="1"><center></center></td>
        <td colspan="1"><center>83.85</center></td>
        <td colspan="1"><center>11321</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>38</center></td>
        <td colspan="1"><center>297.91</center></td>
        <td colspan="1"><center>27408</center></td>
        <td colspan="1"><center>96.25</center></td>
        <td colspan="1"><center>8855</center></td>
        <td colspan="1"><center></center></td>
        <td colspan="1"><center></center></td>
        <td colspan="1"><center>88.05</center></td>
        <td colspan="1"><center>8101</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>70</center></td>
        <td colspan="1"><center>515.76</center></td>
        <td colspan="1"><center>25788</center></td>
        <td colspan="1"><center>175.18</center></td>
        <td colspan="1"><center>8759</center></td>
        <td colspan="1"><center>98.42</center></td>
        <td colspan="1"><center>4921</center></td>
        <td colspan="1"><center>161.22</center></td>
        <td colspan="1"><center>8061</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>91</center></td>
        <td colspan="1"><center>665.23</center></td>
        <td colspan="1"><center>25944</center></td>
        <td colspan="1"><center>224.12</center></td>
        <td colspan="1"><center>8741</center></td>
        <td colspan="1"><center>127.46</center></td>
        <td colspan="1"><center>4971</center></td>
        <td colspan="1"><center>222.69</center></td>
        <td colspan="1"><center>8685</center></td>
    </tr>
    <tr>
        <td colspan="1"><center>133</center></td>
        <td colspan="1"><center>972.25</center></td>
        <td colspan="1"><center>26251</center></td>
        <td colspan="1"><center>329.07</center></td>
        <td colspan="1"><center>8885</center></td>
        <td colspan="1"><center>184.25</center></td>
        <td colspan="1"><center>4975</center></td>
        <td colspan="1"><center>375.88</center></td>
        <td colspan="1"><center>10149</center></td>
    </tr>
</table>

<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%BA%8C/avg-1602753935076.png"></p>
<p><img data-src="../images/%E5%88%A9%E7%94%A8Google-Colab%E6%88%90%E5%8A%9F%E6%B5%8B%E8%AF%95TensorRT%E6%8C%87%E5%8D%97%E4%BA%8C/sum.png"></p>
<div class="note info">
    <p>
    结论：
        1.就目前的测试结果来看，不同显卡的加速耗时是有挺大区别的，并且与batch的大小有关，所以要获取最优的时间，需要尝试不同的batch size;
        2.对于云计算的环境，计算时长比本地还是有些差距，究其原因还需要思考，是否更优的显卡能获取更好的测试结果，只能再多测以结果为准了。
    </p>
</div>]]></content>
      <categories>
        <category>TensorRT实战记</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型微调经验总结记录</title>
    <url>/post/75643f1c.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>大模型使用过程中针对模型微调与预训练的经验总结记录</p>

</blockquote>
<span id="more"></span>

<h1 id="Pre-Training"><a href="#Pre-Training" class="headerlink" title="Pre-Training"></a>Pre-Training</h1><h2 id="什么是Pre-Training"><a href="#什么是Pre-Training" class="headerlink" title="什么是Pre-Training"></a>什么是Pre-Training</h2><ol>
<li><p>先收集大量不需要human labeling 的文本</p>
</li>
<li><p>在这些文本上做language modeling 的预训练任务</p>
<p>这样的话模型就能从大量的unlabeled data里面掌握一个fundamental language knowledge，这个模型也被称作基座模型</p>
</li>
</ol>
<h2 id="Pre-Training有哪些问题"><a href="#Pre-Training有哪些问题" class="headerlink" title="Pre-Training有哪些问题"></a>Pre-Training有哪些问题</h2><h3 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h3><p>目标：收集大量unlabeled text data</p>
<ul>
<li><p>通用数据：收集各种各样的网页、书籍以及对话数据等</p>
</li>
<li><p>专业领域：收集多语言文本、来自专业领域的专业文本，比如论文网站arxiv，代码网站github</p>
</li>
<li><p>文本质量越高越好，小模型在高质量文本上的训练效果也可以媲美大模型</p>
</li>
</ul>
<blockquote>
<p><em>Gunasekar et al., Textbooks Are All You Need. 2023.</em></p>
</blockquote>
<p>可以看一下现如今大模型的数据来源组成 </p>
<p><img data-src="./../images/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93%E8%AE%B0%E5%BD%95/image-20240402135134452.png" alt="image-20240402135134452"></p>
<blockquote>
<p><em>Image from: Zhao, Wayne Xin, et al. “A survey of large language models.” arXiv preprint arXiv:2303.18223 (2023)</em></p>
</blockquote>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>一般的数据预处理流程：</p>
<ol>
<li><p>从各种各样的来源收集原始语料库 raw corpus；</p>
</li>
<li><p>数据清洗</p>
<ul>
<li><p>删除：主要思路是基于统计特点做一些过滤，去除一些干扰字符, 主要方法包括：</p>
<p>a. 语言过滤</p>
<p>b. 关键字过滤</p>
<p>c. 统计过滤</p>
<p>d. 度量过滤</p>
<p>最终实现剔除非目标任务语言、丢弃低perplexity数据、删去标点/符号过多或过长过短的句子、删除具有某些特定词汇（如html标签、链接、脏话、敏感词）的句子</p>
</li>
<li><p>去重：</p>
<p>a. 包含大量重复词汇或短语的句子可以删掉；(sentence-level)</p>
<p>b. 重复率（词/n-grams共现）过高的段落可以删掉；(document-level)</p>
<p>c. 删除训练集中可能与测试集相关度过高的内容。(set-level)</p>
</li>
<li><p>隐私保护：通过关键词等方式剔除用户隐私信息（姓名、地址、电话等）</p>
</li>
</ul>
</li>
<li><p>分词：清洗语料之后便可以进行分词，要么直接使用GPT-2等现成的分词器，要么对训练语料构建基于SentencePiece、Byte Pair Encoding等算法的分词方式，最终实现词与ID的一一映射。</p>
<p>推荐使用大语言模型数据预处理工具data-juicer</p>
</li>
<li><p>数据安排：</p>
<p>a. 数据混合：不同来源的数据如何送入训练</p>
<p>b. 数据进阶：每种数据源下数据进入训练的顺序。例如由简到难，逐渐学会复杂的问题</p>
</li>
</ol>
<h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h3><h4 id="如何选择合适的模型"><a href="#如何选择合适的模型" class="headerlink" title="如何选择合适的模型"></a>如何选择合适的模型</h4><ol>
<li><p>纯自监督预训练：对只有解码器的模型进行预训练的效果最好</p>
</li>
<li><p>多任务微调预训练：使用masked 语言建模预训练的编码器解码器表现最佳。</p>
</li>
</ol>
<h4 id="长文本建模"><a href="#长文本建模" class="headerlink" title="长文本建模"></a>长文本建模</h4><ol>
<li> window attention: 无论input有多少，可以把attention值分配给最临近的 L个 attention，实现一个有带窗口限制的最近临的attention</li>
<li>在transformer做计算的过程中有很大量的attention score被分配最初的几个token，这种token叫做sink tokens, 也就是说他接收到了最大量的一个attention weights, 可以结合window attention, 既关注到我最近的几个邻居token，又持续关注着最开始的那几个token</li>
</ol>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><h4 id="训练策略"><a href="#训练策略" class="headerlink" title="训练策略"></a>训练策略</h4><h5 id="3D-parallelism"><a href="#3D-parallelism" class="headerlink" title="3D parallelism"></a>3D parallelism</h5><ul>
<li><p><strong>数据并行：</strong>这涉及同时在多个 GPU 或 TPU 上训练模型，每个 GPU 或 TPU 处理数据的不同部分。</p>
</li>
<li><p><strong>管道并行：</strong>当模型在一个gpu上都放不下时，可以将模型的参数分割到多个设备上，从而允许它们同时更新。</p>
</li>
<li><p><strong>张量并行：</strong>张量按照行或列的方式切分，分开计算。</p>
</li>
</ul>
<h5 id="混合精度训练"><a href="#混合精度训练" class="headerlink" title="混合精度训练"></a>混合精度训练</h5><p>我们将模型的<strong>weights, activations,</strong> <strong>gradients</strong>等等信息从32位的浮点数转换为16位</p>
<h1 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine-tuning"></a>Fine-tuning</h1><h2 id="什么是Fine-tuning"><a href="#什么是Fine-tuning" class="headerlink" title="什么是Fine-tuning"></a>什么是Fine-tuning</h2><p>得到基座基础之后，假如想提高某一个具体的任务，比如想做question answering或者dialogue system或者information extraction等 ，那么可以用相应的supervised learning data去做第二阶段的fine-tuning， 这样的话相当于基座模型在子任务的基础上又做了一个进一步的训练。</p>
<p>对比pre-training与fine-tuning：</p>
<ol>
<li>pre-training 阶段的data规模非常大，因为它是unlable data, 来源可以是网上收集的文本；</li>
<li>fine-tuning dataset规模小得多，它来源于人为或者高精度的模型去标注的</li>
</ol>
<h2 id="有监督微调（SFT）"><a href="#有监督微调（SFT）" class="headerlink" title="有监督微调（SFT）"></a>有监督微调（SFT）</h2><p>对比两组对话</p>
<table>
<thead>
<tr>
<th>问题</th>
<th>回答</th>
</tr>
</thead>
<tbody><tr>
<td>无法登录账户应该怎么做？</td>
<td>尝试使用 “忘记密码 “选项重置密码。</td>
</tr>
<tr>
<td>无法登录账户应该怎么做？</td>
<td>很遗憾您在登录时遇到困难。您可以尝试使用登录页面上的’忘记密码’选项重新设置密码。</td>
</tr>
</tbody></table>
<p>可以看出第二组问答更符合带有同理心的服务场景。</p>
<p>所以对 LLM 进行微调是有必要的，主要原因如下：</p>
<ul>
<li><p>获得与业务准则相匹配的答案。</p>
</li>
<li><p>提供新的特定/私人数据，这些数据在训练步骤中并未公开，以便 LLM 模型适应特定知识库。</p>
</li>
<li><p>教会 LLM 回答新的（未见的）问题；</p>
</li>
</ul>
<h3 id="利用-Trainer-class-实现-Finetuning"><a href="#利用-Trainer-class-实现-Finetuning" class="headerlink" title="利用 Trainer class 实现 Finetuning"></a>利用 Trainer class 实现 Finetuning</h3>  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TextDataset,DataCollatorForLanguageModeling</span><br><span class="line">tokenizer = AutoTokenizer.<span class="keyword">from</span> pretrained(<span class="string">&quot;&lt;YOUR MODEL&gt;&quot;</span>)</span><br><span class="line">train_path =<span class="string">&quot;&lt;TRAINING DATASET PATH&gt;&#x27;</span></span><br><span class="line"><span class="string">test_path = &quot;</span>&lt;TEST DATASET PATH&gt;<span class="string">&quot;</span></span><br><span class="line"><span class="string">def load dataset(train_path,test_path,tokenizer):</span></span><br><span class="line"><span class="string">    train_dataset = TextDataset(</span></span><br><span class="line"><span class="string">        tokenizer=tokenizer,</span></span><br><span class="line"><span class="string">        file_path=train_path,</span></span><br><span class="line"><span class="string">        block_size=128)</span></span><br><span class="line"><span class="string">	test_dataset =TextDataset(</span></span><br><span class="line"><span class="string">        tokenizer=tokenizer,</span></span><br><span class="line"><span class="string">        file_path=test_path,</span></span><br><span class="line"><span class="string">        block_size=128)</span></span><br><span class="line"><span class="string">	data_collator = DatacollatorForLanguageModeling(</span></span><br><span class="line"><span class="string">        tokenizer=tokenizer, </span></span><br><span class="line"><span class="string">        mlm=False,)</span></span><br><span class="line"><span class="string">	return train_dataset,test_dataset,data_collator</span></span><br><span class="line"><span class="string">train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">from transformers import Trainer, TrainingArguments,AutoModelwithLMHead</span></span><br><span class="line"><span class="string">model = AutoModelwithLMHead.from_pretrained(&quot;</span>&lt;YOUR_ MODEL&gt;<span class="string">&quot;)</span></span><br><span class="line"><span class="string">training args = TrainingArguments(output_dir=&quot;</span>./outputs<span class="string">&quot;,#The output directory</span></span><br><span class="line"><span class="string">                                  overwrite_output_dir=True, #overwrite the content of the output directory</span></span><br><span class="line"><span class="string">                                  num_train_epochs=3,# number of training epochs</span></span><br><span class="line"><span class="string">                                  per_device_train_batch_size=32,# batch size for training</span></span><br><span class="line"><span class="string">                                  per_device_eval_batch_size=64, # batch size for evaluation</span></span><br><span class="line"><span class="string">                                  eval_steps = 400,# Number of update steps between two evaluations.</span></span><br><span class="line"><span class="string">                                  save_steps=800,# after # steps model is saved</span></span><br><span class="line"><span class="string">                                  warmup_steps=500,# number of warmup steps for learning rate scheduler</span></span><br><span class="line"><span class="string">trainer = Trainer(</span></span><br><span class="line"><span class="string">        model=model,</span></span><br><span class="line"><span class="string">        args=training_args,</span></span><br><span class="line"><span class="string">        data_collator=data_collator.</span></span><br><span class="line"><span class="string">        train_dataset=train_dataset.</span></span><br><span class="line"><span class="string">        eval_dataset=test_dataset,</span></span><br><span class="line"><span class="string">)</span></span><br></pre></td></tr></table></figure>

<h3 id="利用-trl-模块的-SFTTrainer-class-实现-Finetuning"><a href="#利用-trl-模块的-SFTTrainer-class-实现-Finetuning" class="headerlink" title="利用 trl 模块的 SFTTrainer class 实现 Finetuning"></a>利用 trl 模块的 SFTTrainer class 实现 Finetuning</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLMfrom datasets <span class="keyword">import</span> load dataset</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line">model = AutoModelForCausalLM.<span class="keyword">from</span> pretrained(<span class="string">&quot;&lt;YOUR MODEL&gt;&quot;</span>)</span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model,</span><br><span class="line">	train_dataset=train_dataset,</span><br><span class="line">	evaluation_dataset=evaluation_dataset,</span><br><span class="line">	data_collator=collator</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<h3 id><a href="#" class="headerlink" title></a></h3><h2 id="使用LoRA-微调-Llama-2"><a href="#使用LoRA-微调-Llama-2" class="headerlink" title="使用LoRA 微调 Llama 2"></a>使用LoRA 微调 Llama 2</h2><h3 id="量化配置"><a href="#量化配置" class="headerlink" title="量化配置"></a>量化配置</h3><p>在使用 LoRA（低秩适应）训练机器学习模型的背景下，有几个参数发挥作用。以下是每个内容的简化解释：</p>
<p>LoRA 特定参数</p>
<ul>
<li><p>**Dropout Rate (lora_dropout)**：这是训练期间每个神经元的输出设置为零的概率，用于防止过度拟合。</p>
</li>
<li><p><strong>Rank (r)：</strong> Rank 本质上是衡量原始权重矩阵如何分解为更简单、更小的矩阵的指标。这减少了计算要求和内存消耗。较低的排名使模型更快，但可能会牺牲性能。最初的 LoRA 论文建议从 8 开始，但对于 QLoRA，需要 64 开始。</p>
</li>
<li><p><strong>lora_alpha</strong>：此参数控制低秩近似的缩放。这就像原始模型和低阶近似之间的平衡行为。较高的值可能会使近似值在微调过程中影响更大，从而影响性能和计算成本。一般是r的2倍。</p>
</li>
</ul>
<p>通过调整这些参数，尤其是 lora_alpha 和 r，可以观察模型的性能和资源消耗变化，找到特定任务的最佳设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line">    AutoModelForCausalLM,</span><br><span class="line">    AutoTokenizer,</span><br><span class="line">    BitsAndBytesConfig,</span><br><span class="line">    TrainingArguments,</span><br><span class="line">    pipeline</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataset</span></span><br><span class="line">data_name = <span class="string">&quot;mlabonne/guanaco-llama2-1k&quot;</span></span><br><span class="line">training_data = load_dataset(data_name, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model and tokenizer names</span></span><br><span class="line">base_model_name = <span class="string">&quot;NousResearch/Llama-2-7b-chat-hf&quot;</span></span><br><span class="line">refined_model = <span class="string">&quot;llama-2-7b-mlabonne-enhanced&quot;</span> <span class="comment">#You can give it your own name</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenizer</span></span><br><span class="line">llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">llama_tokenizer.pad_token = llama_tokenizer.eos_token</span><br><span class="line">llama_tokenizer.padding_side = <span class="string">&quot;right&quot;</span>  <span class="comment"># Fix for fp16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Quantization Config</span></span><br><span class="line">quant_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">    bnb_4bit_compute_dtype=torch.float16,</span><br><span class="line">    bnb_4bit_use_double_quant=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model</span></span><br><span class="line">base_model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    base_model_name,</span><br><span class="line">    quantization_config=quant_config,</span><br><span class="line">    device_map=&#123;<span class="string">&quot;&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">)</span><br><span class="line">base_model.config.use_cache = <span class="literal">False</span></span><br><span class="line">base_model.config.pretraining_tp = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># LoRA Config</span></span><br><span class="line">peft_parameters = LoraConfig(</span><br><span class="line">    lora_alpha=<span class="number">16</span>,</span><br><span class="line">    lora_dropout=<span class="number">0.1</span>,</span><br><span class="line">    r=<span class="number">8</span>,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training Params</span></span><br><span class="line">train_params = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./results_modified&quot;</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    gradient_accumulation_steps=<span class="number">1</span>,</span><br><span class="line">    optim=<span class="string">&quot;paged_adamw_32bit&quot;</span>,</span><br><span class="line">    save_steps=<span class="number">25</span>,</span><br><span class="line">    logging_steps=<span class="number">25</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-4</span>,</span><br><span class="line">    weight_decay=<span class="number">0.001</span>,</span><br><span class="line">    fp16=<span class="literal">False</span>,</span><br><span class="line">    bf16=<span class="literal">False</span>,</span><br><span class="line">    max_grad_norm=<span class="number">0.3</span>,</span><br><span class="line">    max_steps=-<span class="number">1</span>,</span><br><span class="line">    warmup_ratio=<span class="number">0.03</span>,</span><br><span class="line">    group_by_length=<span class="literal">True</span>,</span><br><span class="line">    lr_scheduler_type=<span class="string">&quot;constant&quot;</span>,</span><br><span class="line">    report_to=<span class="string">&quot;tensorboard&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trainer</span></span><br><span class="line">fine_tuning = SFTTrainer(</span><br><span class="line">    model=base_model,</span><br><span class="line">    train_dataset=training_data,</span><br><span class="line">    peft_config=peft_parameters,</span><br><span class="line">    dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">    tokenizer=llama_tokenizer,</span><br><span class="line">    args=train_params</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">fine_tuning.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save Model</span></span><br><span class="line">fine_tuning.model.save_pretrained(refined_model)</span><br></pre></td></tr></table></figure>

<p><img data-src="./../images/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93%E8%AE%B0%E5%BD%95/image-20240402163925722.png" alt="image-20240402163925722"></p>
<p>可以看到已经有模型保存了</p>
<p><img data-src="./../images/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93%E8%AE%B0%E5%BD%95/image-20240402164027598.png" alt="image-20240402164027598"></p>
<h1 id="一些经典开源语料数据集"><a href="#一些经典开源语料数据集" class="headerlink" title="一些经典开源语料数据集"></a>一些经典开源语料数据集</h1><ul>
<li><a href="https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations">GPT-4all</a> 数据集： GPT-4all（成对，英文，400k 条目）–由 OIG、P3 和 Stackoverflow 的一些子集组合而成，涵盖一般 QA 和定制的创意问题。</li>
<li><a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T">RedPajama-Data-1T</a>：RedPajama（PT，主要为英语，1.2T 词条，5TB）–完全开放的预训练数据集，遵循 LLaMA 的方法。</li>
<li><a href="https://huggingface.co/datasets/OpenAssistant/oasst1">OASST1</a>： OpenAssistant（配对、对话、多语言、66,497 个对话树）–一个大型、人工编写、人工标注的高质量对话数据集，旨在改进 LLM 响应。</li>
<li><a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k">databricks-dolly-15k</a>： Dolly2.0（成对，英语，1.5 万+条目）–一个由人工撰写的提示和回复数据集，以问题解答和总结等任务为特色。</li>
<li><a href="https://github.com/gururise/AlpacaDataCleaned">AlpacaDataCleaned</a>： 一些 Alpaca/ LLaMA-like 模型（成对，英文） - Alpaca、GPT_LLM 和 GPTeacher 的清理版本。</li>
<li><a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM">GPT-4-LLM</a> 数据集： 一些类似 Alpaca 的模型（Pairs、RLHF、英语、汉语，52K 条英语和汉语条目，9K 条非自然指令条目）- 由 GPT-4 和其他 LLM 生成的数据集，用于改进 Pairs 和 RLHF，包括指令和比较数据。</li>
<li><a href="https://github.com/teknium1/GPTeacher">GPTeacher</a>：（Pairs，英语，20K 条目）- 由 GPT-4 生成的目标数据集，包括来自 Alpaca 的种子任务和角色扮演等新任务。</li>
<li><a href="https://github.com/tatsu-lab/stanford_alpaca#data-release">Alpaca</a> 数据： Alpaca, ChatGLM-fine-tune-LoRA, Koala (Dialog, Pairs, English, 52K entries, 21.4MB) - 由 text-davinci-003 生成的数据集，用于增强语言模型遵循人类指令的能力。</li>
</ul>
]]></content>
      <categories>
        <category>大模型学习笔记</category>
      </categories>
      <tags>
        <tag>大模型 Fine-tuning Training</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络专有名词理解笔记</title>
    <url>/post/eb6a0ea3.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>本文将在此列出深度学习一些术语，并进行具体描述，希望对大家有所帮助。</p>

</blockquote>
<span id="more"></span>

<p>先看几张图像</p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/image-1712130112683-3.png" alt="img"></p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/image.png" alt="img"></p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/image-1712130160745-6.png" alt="YOLO v5"></p>
<h1 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h1><ul>
<li>原始图像</li>
<li>经过数据预处理（数据增强、堆叠或者其他变换）的图像</li>
<li>图像的块</li>
</ul>
<h1 id="Backbone"><a href="#Backbone" class="headerlink" title="Backbone"></a><strong>Backbone</strong></h1><ul>
<li>将输入转换为特征图的部分</li>
<li>代表性的例子包括 VGG 和 ResNet50，它们是使用 ImageNet 数据集进行预训练的。</li>
<li>简单来说，将输入经过几个卷积层会产生一个特征图（每次经过每一层都会出现一个特征图。通常，当层经过时，会以这种方式提取特征：边缘 - 部分 - …）</li>
</ul>
<h1 id="Neck"><a href="#Neck" class="headerlink" title="Neck"></a>Neck</h1><ul>
<li><p>适当协调从主干提取的特征（也可以看作是更精确地调整特征图的过程）</p>
</li>
<li><p>代表性的例子有FPN、PANet、BiFPN等。</p>
</li>
<li><p>通过对先前的图进行上采样来增加尺寸，并使用 concat 等方法在主干中反映特征图。</p>
</li>
<li><p>自上而下和自下而上两种方法都存在</p>
</li>
</ul>
<h1 id="Head"><a href="#Head" class="headerlink" title="Head"></a>Head</h1><ul>
<li>执行定位和分类</li>
<li>头部由特定任务的层组成，旨在根据由骨干和颈部提取的信息产生最终预测或推断。</li>
</ul>
<h1 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a><strong>Baseline</strong></h1><ul>
<li><p>基准模型是一种简单的模型，可作为起点或比较点。</p>
</li>
<li><p>基准模型通常被用作评估更先进或更复杂模型或技术有效性的基准。</p>
</li>
</ul>
<h1 id="Backbone-vs-Baseline"><a href="#Backbone-vs-Baseline" class="headerlink" title="Backbone vs Baseline"></a>Backbone vs Baseline</h1><p>模型架构不一样，用途不一样：</p>
<ul>
<li><p>基准模型是一个简单的参考模型，用于比较 ;</p>
</li>
<li><p>骨干模型是一个更复杂的架构，负责特征提取。</p>
</li>
<li><p>基准模型作为评估的起点，而骨干模型提供了特定任务解决所需的特征表示。</p>
</li>
</ul>
<h1 id="Backbone-vs-Neck"><a href="#Backbone-vs-Neck" class="headerlink" title="Backbone vs Neck"></a>Backbone vs Neck</h1><ul>
<li><p>骨干负责从输入数据中进行初级特征提取</p>
</li>
<li><p>颈部则增强并合并这些特征，以提高模型的性能。</p>
</li>
</ul>
<h1 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h1><p>在神经网络中，瓶颈层就是指比下面或上面的层神经元数量少的一层。有这样一层的存在让网络可以将特征压缩以尽可能适应空间变化。</p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/main-qimg-23264282c4634e252d8e97504632316f-pjlq.jpeg" alt="img"></p>
<h1 id="Residual-Block"><a href="#Residual-Block" class="headerlink" title="Residual Block"></a>Residual Block</h1><p>一个残差块是一个层堆叠，排列得使得一个层的输出被取出并添加到块中更深的另一个层。</p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/1zShqrle2Gp_RiFkOTmvxEg.jpeg" alt="img"></p>
<p>残差的作用是可以让网络变得更深，假如有的神经节点梯度消失不更新了，那可以直接不管当前这个节点，下一节点因为接收了和上一节点同样的输入，后面的节点和层还可以继续训练。</p>
<h1 id="Skip-Connection"><a href="#Skip-Connection" class="headerlink" title="Skip Connection"></a>Skip Connection</h1><p>跳跃连接是一种快捷方式，将一个层的输出连接到相邻层的输入。</p>
<p>对比一下跳跃连接和残差连接的区别</p>
<ul>
<li>跳跃连接是一个通用概念，指的是层之间的任何形式的直接连接</li>
<li>而残差连接是ResNet架构中常用的一种特定类型的跳跃连接</li>
<li>残差连接的主要目的是让网络学习变化，而不是直接学习整个转换过程。</li>
</ul>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/sensors-19-03929-g001.png" alt="img"></p>
<h1 id="Downsampling"><a href="#Downsampling" class="headerlink" title="Downsampling"></a>Downsampling</h1><p>从CNN的第一层提取特征后，如果直接将输出传递到第二层，那么这个过程会变得计算成本高昂。为了减小输出的大小，我们提取最小效果的特征并传递给下一层。这个过程旨在减小输出大小而不丢失重要信息，被称为下采样。最常见的下采样方法是最大池化。</p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/15XZK2yePcXF2VwcIVq_Pxw.webp" alt="img"></p>
<p>有时它与图像压缩相混淆，图像压缩是在图像颜色、编码、像素上做不同的事情，并且具有和下采样完全不同的用途。这里我们只关心图像的缩小。降采样本质上意味着丢弃一些信息。下采样的各种技术中使用了多种算法，即：</p>
<ul>
<li>[Mipmap](<a href="http://number-none.com/product/Mipmapping">http://number-none.com/product/Mipmapping</a>, Part 1/index.html)</li>
<li><a href="https://scholarworks.rit.edu/cgi/viewcontent.cgi?article=10864&context=theses">Box Sampling</a></li>
<li><a href="https://www.nayuki.io/page/sinc-based-image-resampler">Sinc</a></li>
</ul>
<h1 id="Upsampling"><a href="#Upsampling" class="headerlink" title="Upsampling"></a>Upsampling</h1><p>上采样是下采样的相反目标：增加图像的行数和/或列数（尺寸）。有多种实现方式，</p>
<ul>
<li><p>例如 GAN（生成对抗网络）根据随机向量样本构建图像，模仿来自真实分布的图像。</p>
</li>
<li><p>以某种方式增加图像的尺寸并填充间隙（列/行）。假设将原始图像上采样 3 倍，一种方法是重复原始图像中的每一列/行。</p>
</li>
</ul>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/1D0HFma1Nb7D5_jBV3LPy-w.webp" alt="img"></p>
<p>这样的结果是原始图像和生成的图像即使不完全相同，但是看起来也非常相似。本质是没有在生成的图像中创建任何“新”数据。由于重复的行和列是完全冗余的，因此该方法没有任何用处，并且它不提供任何新信息。</p>
<p>添加新列的明智方法是在行/列之间插入新数据，这使用一些高级数学生成提供相当准确的中间值。</p>
<p>其中一些算法的示例是：</p>
<ul>
<li><p><a href="https://theailearner.com/2018/12/29/image-processing-nearest-neighbour-interpolation/">最近邻插值法</a></p>
</li>
<li><p><a href="https://theailearner.com/2018/12/29/image-processing-bilinear-interpolation/">双线性插值</a></p>
</li>
<li><p>双三次样条插值</p>
</li>
<li><p>广义双三次插值</p>
</li>
</ul>
<h1 id="1-x-1-Convolution"><a href="#1-x-1-Convolution" class="headerlink" title="1 x 1 Convolution"></a>1 x 1 Convolution</h1><ul>
<li>降维/增维</li>
</ul>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/13kgQ1HJvVOGK_LWS_ANoBA.png" alt="img"></p>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/1C2ei51Og0WMpoEesMFEvcA.png" alt="img"></p>
<ul>
<li>减少运算量提高计算效率</li>
<li>网络设计</li>
</ul>
<p><img data-src="./../images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%93%E6%9C%89%E5%90%8D%E8%AF%8D%E7%90%86%E8%A7%A3%E7%AC%94%E8%AE%B0/1Unx7sioMBJXPT6otlYY5ww.png" alt="img"></p>
]]></content>
      <categories>
        <category>目标检测学习笔记</category>
      </categories>
      <tags>
        <tag>目标检测 神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>记录Hexo博客成功迁移</title>
    <url>/post/f16bee1a.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>换工作新换了电脑，要写文档，正好就把hexo博客迁移过来，所以把自己成功迁移的整个过程记录下来，也方便有同样需求的小伙伴进行参考</p>

</blockquote>

<span id="more"></span>

<h2 id="配置基础环境"><a href="#配置基础环境" class="headerlink" title="配置基础环境"></a><strong>配置基础环境</strong></h2><h3 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install git</span><br><span class="line"><span class="comment">#查看版本确认是否安装成功</span></span><br><span class="line">git --version</span><br></pre></td></tr></table></figure>

<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-c8384a33e43326b800f6eecb0aae724b_r.jpg"></p>
<h3 id="配置Git"><a href="#配置Git" class="headerlink" title="配置Git"></a><strong>配置Git</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#配置GitHub的用户名与邮箱</span></span><br><span class="line">git config --global user.name <span class="string">&quot;yourname&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;youremail&quot;</span></span><br><span class="line"><span class="comment">#查看config确认是否配置成功</span></span><br><span class="line">git config --list</span><br></pre></td></tr></table></figure>

<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-69e02e628a34d1fb55988b131a035d70_b.png"></p>
<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-b376c04fbfd9a541edd2d10a1dabe35c_b.jpg"></p>
<h3 id="生成密钥"><a href="#生成密钥" class="headerlink" title="生成密钥"></a><strong>生成密钥</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#生成密钥</span></span><br><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;youremail&quot;</span></span><br><span class="line"><span class="comment">#显示密钥信息，下一步要用</span></span><br><span class="line"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>

<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-1faeb6dda5d80d882ac77f1db6662f36_b.jpg"></p>
<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-4de712c228ee0943544b50b6d75bfdd7_r.png"></p>
<h3 id="配置密钥"><a href="#配置密钥" class="headerlink" title="配置密钥"></a><strong>配置密钥</strong></h3><p>点击GitHub头像选择setting</p>
<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-6fbea960c7d4f55edec4fe217fc7d32b_b.jpg"></p>
<p>选择SSH and GPG keys新建SSH keys,这块名字任意取，key的内容将上面一步显示的key信息填进去</p>
<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-2e9870098d7db694d610f0825e702404_r.jpg"></p>
<h3 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a><strong>安装Node.js</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt install nodejs</span><br></pre></td></tr></table></figure>

<h3 id="安装npm"><a href="#安装npm" class="headerlink" title="安装npm"></a><strong>安装npm</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install npm</span><br></pre></td></tr></table></figure>

<h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a><strong>安装Hexo</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<h3 id="迁移相关文件"><a href="#迁移相关文件" class="headerlink" title="迁移相关文件"></a><strong>迁移相关文件</strong></h3><p><font color="red">新建blog文件夹将原先blog文件夹下的所有文件拷贝过来即可</font></p>
<h3 id="新电脑下重新部署"><a href="#新电脑下重新部署" class="headerlink" title="新电脑下重新部署"></a><strong>新电脑下重新部署</strong></h3><h3 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a><strong>安装插件</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> Bella_Blog</span><br><span class="line"><span class="comment">#安装原始插件列表</span></span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>

<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-142c9675ab35090fa83f9818d7244d6f_r.jpg"></p>
<h3 id="生成并部署"><a href="#生成并部署" class="headerlink" title="生成并部署"></a><strong>生成并部署</strong></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-c009914f7bd05ba6d585720fe349e23b_r.jpg"></p>
<p><img data-src="C:\Users\72766\Documents\blog_pics\v2-35463f7facbfd393b6030699802b7184_r.jpg"></p>
<p>迁移成功！</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a><strong>参考链接</strong></h3><p><a href="https://link.zhihu.com/?target=https://swayye.xyz/2020/01/10/hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB/">hexo博客迁移</a></p>
]]></content>
      <categories>
        <category>小白学搭Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>解决双系统Ubuntu检测不到NVIDIA驱动</title>
    <url>/post/4b9525f5.html</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>昨天换到windows下写个文档顺手用电脑管家清理了下垃圾，然后再切回Ubuntu的时候发现分辨率一下降到老人机模式，再运行加载cuda的代码的时候竟然说cudainit 失败，没有可用的显卡，用nvidia-smi自查一下，凉凉，折腾了整整一天呐，现在就把解决结果记录下来。</p>

</blockquote>

<span id="more"></span>

<h2 id="nvidia-smi"><a href="#nvidia-smi" class="headerlink" title="nvidia-smi"></a>nvidia-smi</h2><p><font color="#0000dd"> NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running</font></p>
<h2 id="nvidia-settings"><a href="#nvidia-settings" class="headerlink" title="nvidia-settings"></a>nvidia-settings</h2><p><font color="#0000dd"> <strong>ERROR</strong>: NVIDIA driver <strong>is</strong> <strong>not</strong> loaded </font></p>
<p><font color="#0000dd"> <strong>ERROR</strong>: Unable <strong>to</strong> <strong>load</strong> info <strong>from</strong> <strong>any</strong> available <strong>system</strong></font></p>
<div class="note info"><p>在网上搜索解决办法的时候，搜过error, 搜过那个关机出现的PCIe Bus Error, 根据搜到的解决内容看，问题是出在nvidia-drive 驱动坏了，依照那些解决办法添加源，安装驱动，刷新再重启，还是没能解决，最后终于心一横，卸载所有nvidia*，再重装驱动，重启，结果意外还成功了，看到熟悉的界面，内牛满面啊</p></div>

<p><img data-src="../images/%E8%A7%A3%E5%86%B3%E5%8F%8C%E7%B3%BB%E7%BB%9FUbuntu%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%88%B0NVIDIA%E9%A9%B1%E5%8A%A8/0924_6.jpg"></p>
<p><img data-src="../images/%E8%A7%A3%E5%86%B3%E5%8F%8C%E7%B3%BB%E7%BB%9FUbuntu%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%88%B0NVIDIA%E9%A9%B1%E5%8A%A8/0924_2.jpg"></p>
<p><img data-src="../images/%E8%A7%A3%E5%86%B3%E5%8F%8C%E7%B3%BB%E7%BB%9FUbuntu%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%88%B0NVIDIA%E9%A9%B1%E5%8A%A8/0924_4.jpg"></p>
<p><img data-src="../images/%E8%A7%A3%E5%86%B3%E5%8F%8C%E7%B3%BB%E7%BB%9FUbuntu%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%88%B0NVIDIA%E9%A9%B1%E5%8A%A8/0924_5.jpg"></p>
<h2 id="解决步骤"><a href="#解决步骤" class="headerlink" title="解决步骤"></a>解决步骤</h2><h3 id="卸载清理以前所有的nvidia"><a href="#卸载清理以前所有的nvidia" class="headerlink" title="卸载清理以前所有的nvidia*"></a>卸载清理以前所有的nvidia*</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure>

<h3 id="添加PPA源"><a href="#添加PPA源" class="headerlink" title="添加PPA源"></a>添加PPA源</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers</span><br></pre></td></tr></table></figure>

<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>

<h3 id="预览驱动列表"><a href="#预览驱动列表" class="headerlink" title="预览驱动列表"></a>预览驱动列表</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ubuntu-drivers devices</span><br></pre></td></tr></table></figure>

<h3 id="安装推荐的驱动"><a href="#安装推荐的驱动" class="headerlink" title="安装推荐的驱动"></a>安装推荐的驱动</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install nvidia-driver-&lt;version&gt;</span><br></pre></td></tr></table></figure>

<h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>

<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<p><img data-src="../images/%E8%A7%A3%E5%86%B3%E5%8F%8C%E7%B3%BB%E7%BB%9FUbuntu%E6%A3%80%E6%B5%8B%E4%B8%8D%E5%88%B0NVIDIA%E9%A9%B1%E5%8A%A8/Screenshot%20from%202020-09-24%2010-29-46.png"></p>
]]></content>
      <categories>
        <category>教你玩转Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
</search>
