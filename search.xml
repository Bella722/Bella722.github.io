<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ubuntu20.04下成功配置Qv2ray</title>
    <url>/post/a231f91f.html</url>
    <content><![CDATA[<blockquote>
<p><strong>对于一名码农来说，经常需要解决bug, 加上有时还需要对最新paper方向的掌握，也都需要上网查资料获取，尤其是深度学习方向最新的一些数据集以及模型的下载，都需要合适的网络环境，所以在这里我把自己在Ubuntu下解决这一问题的过程记录下来，希望能够帮助到和我有同样需求的小伙伴</strong></p>
</blockquote>
<a id="more"></a>

<h3 id="1-安装客户端"><a href="#1-安装客户端" class="headerlink" title="1. 安装客户端"></a>1. 安装客户端</h3><p>​    软件中心搜索qv2ray安装</p>
<p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-03-10.png" alt="qv2ray安装"></p>
<h3 id="2-配置客户端"><a href="#2-配置客户端" class="headerlink" title="2. 配置客户端"></a>2. 配置客户端</h3><h4 id="1-从应用列表将app右键添加到主页最常用应用栏"><a href="#1-从应用列表将app右键添加到主页最常用应用栏" class="headerlink" title="(1) 从应用列表将app右键添加到主页最常用应用栏"></a>(1) 从应用列表将app右键添加到主页最常用应用栏</h4><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-17-24.png" alt="添加到常用"></p>
<h4 id="2-打开Qv2ray-会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹"><a href="#2-打开Qv2ray-会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹" class="headerlink" title="(2) 打开Qv2ray, 会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹"></a>(2) 打开Qv2ray, 会在主文件夹下的snap下自动生成一个名为qv2ray的文件夹</h4><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-03-42.png" alt="查看文件夹内容"></p>
<h4 id="3-先配置语言，点击preferences进入设置，语言栏选中中文并确定"><a href="#3-先配置语言，点击preferences进入设置，语言栏选中中文并确定" class="headerlink" title="(3) 先配置语言，点击preferences进入设置，语言栏选中中文并确定"></a>(3) 先配置语言，点击preferences进入设置，语言栏选中中文并确定</h4><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-03-59.png" alt="语言配置"></p>
<h4 id="4-核心core文件配置"><a href="#4-核心core文件配置" class="headerlink" title="(4) 核心core文件配置"></a>(4) 核心core文件配置</h4><h5 id="a-进入https-github-com-v2ray-v2ray-core-releases根据自己的系统下载相应的核心文件"><a href="#a-进入https-github-com-v2ray-v2ray-core-releases根据自己的系统下载相应的核心文件" class="headerlink" title="a. 进入https://github.com/v2ray/v2ray-core/releases根据自己的系统下载相应的核心文件"></a>a. 进入<a href="https://github.com/v2ray/v2ray-core/releases%E6%A0%B9%E6%8D%AE%E8%87%AA%E5%B7%B1%E7%9A%84%E7%B3%BB%E7%BB%9F%E4%B8%8B%E8%BD%BD%E7%9B%B8%E5%BA%94%E7%9A%84%E6%A0%B8%E5%BF%83%E6%96%87%E4%BB%B6">https://github.com/v2ray/v2ray-core/releases根据自己的系统下载相应的核心文件</a></h5><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/FireShot%20Capture%20019%20-%20Releases%20%C2%B7%20v2ray_v2ray-core%20-%20github.com.png" alt="核心文件下载"></p>
<h5 id="b-在-home-xxx-snap-qv2ray-2733-config-qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl-h才能显示隐藏的-config文件夹，这里注意即可。"><a href="#b-在-home-xxx-snap-qv2ray-2733-config-qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl-h才能显示隐藏的-config文件夹，这里注意即可。" class="headerlink" title="b. 在/home/xxx/snap/qv2ray/2733/.config/qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl+h才能显示隐藏的.config文件夹，这里注意即可。"></a>b. 在/home/xxx/snap/qv2ray/2733/.config/qv2ray文件夹下新建vcore文件夹，并将之前下载的核心文件去全部拷贝到vcore文件夹内。注意这里的2733版本号是不固定的，根据你自己的来就好。另外就是你可能需要ctrl+h才能显示隐藏的.config文件夹，这里注意即可。</h5><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-06-18.png" alt="配置核心文件1"><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-06-52.png" alt="配置核心文件2"><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-07-13.png" alt="配置核心文件3"></p>
<h5 id="c-验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功"><a href="#c-验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功" class="headerlink" title="c. 验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功"></a>c. 验证核心文件。设置里查看内核设置下的文件目录都对应不，不对应的需要手动更改。查看无误点击检查核心设置按钮，出现检查通过即为成功</h5><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-07-30.png" alt="验证核心文件1"><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-07-34.png" alt="验证核心文件2"></p>
<h3 id="3-回到app首页配置入网config文件。选择新建下的手动输入开始录入信息"><a href="#3-回到app首页配置入网config文件。选择新建下的手动输入开始录入信息" class="headerlink" title="3. 回到app首页配置入网config文件。选择新建下的手动输入开始录入信息"></a>3. 回到app首页配置入网config文件。选择新建下的手动输入开始录入信息</h3><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-08-27.png" alt="配置账户信息1"></p>
<p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-08-55.png" alt="配置账户信息2"></p>
<blockquote>
<p><strong>以下是我经常获取free acounts的两个网址：<br>link 1:  <a href="http://tr1.freeair888.club/v2ray%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/">http://tr1.freeair888.club/v2ray%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7/</a><br>link 2: <a href="https://view.freev2ray.org/">https://view.freev2ray.org/</a><br>ink 2的accounts info每12H 会更新一次，只要删除旧连接添加另一个新连接就哦了</strong></p>
</blockquote>
<h3 id="4-最后主页右键选中线路连接就搞定啦"><a href="#4-最后主页右键选中线路连接就搞定啦" class="headerlink" title="4. 最后主页右键选中线路连接就搞定啦"></a>4. 最后主页右键选中线路连接就搞定啦</h3><p><img data-src="../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AEQv2ray/Screenshot%20from%202020-09-08%2014-09-20.png" alt="完成连接"><br>&emsp;</p>
<blockquote>
<p><em>写在最后：请在合理合法的范围内使用。希望大家都好好珍惜这些资源，不然使用不当造成账号被封是大家都不愿意看到的事。</em></p>
</blockquote>
]]></content>
      <categories>
        <category>教你玩转Ubuntu</category>
      </categories>
      <tags>
        <tag>Qv2ray</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu20.04下成功配置TensorFlow Object Detection API 教程</title>
    <url>/post/1a71c089.html</url>
    <content><![CDATA[<h3 id="1-新建一个名为TensorFlow的文件夹"><a href="#1-新建一个名为TensorFlow的文件夹" class="headerlink" title="1.新建一个名为TensorFlow的文件夹"></a>1.新建一个名为TensorFlow的文件夹</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir TensorFlow</span><br></pre></td></tr></table></figure>

<h3 id="2-打开终端，cd进入TensorFlow"><a href="#2-打开终端，cd进入TensorFlow" class="headerlink" title="2.打开终端，cd进入TensorFlow"></a>2.打开终端，cd进入TensorFlow</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> TensorFlow</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h3 id="3-克隆TensorFlow-Models"><a href="#3-克隆TensorFlow-Models" class="headerlink" title="3.克隆TensorFlow Models"></a>3.克隆TensorFlow Models</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/tensorflow/models.git</span><br></pre></td></tr></table></figure>

<p>现在你的TensorFlow文件夹应该如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">models/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line">   <span class="string">└──</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h3 id="4-配置Protobuf"><a href="#4-配置Protobuf" class="headerlink" title="4.配置Protobuf"></a>4.配置Protobuf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install protobuf</span><br><span class="line"><span class="built_in">cd</span> models/research/</span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>

<h3 id="5-配置COCO-API"><a href="#5-配置COCO-API" class="headerlink" title="5.配置COCO API"></a>5.配置COCO API</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/cocodataset/cocoapi.git</span><br><span class="line"><span class="built_in">cd</span> cocoapi/PythonAPI</span><br><span class="line">make</span><br><span class="line">cp -r pycocotools &lt;PATH_TO_TF&gt;/TensorFlow/models/research/</span><br></pre></td></tr></table></figure>

<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2016-04-34-1598871276938.png" alt="配置1"></p>
<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2016-05-05-1598871293831.png" alt="配置2"></p>
<h3 id="6-安装Object-Detection-API"><a href="#6-安装Object-Detection-API" class="headerlink" title="6.安装Object Detection API"></a>6.安装Object Detection API</h3><p>这里需要注意一点，先要确认你的tensorflow版本，我的是tf1.x，所以这里我要拷贝的是tf1的setup,如果你的是tf2.x,那就拷贝tf2的setup.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#确保你当前在TensorFlow/models/research/文件夹下</span></span><br><span class="line">cp object_detection/packages/tf2/setup.py .</span><br><span class="line">python -m pip install .</span><br></pre></td></tr></table></figure>

<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2016-05-18-1598871310225.png" alt="配置3"></p>
<h3 id="7-测试Object-Detection-API是否安装成功"><a href="#7-测试Object-Detection-API是否安装成功" class="headerlink" title="7.测试Object Detection API是否安装成功"></a>7.测试Object Detection API是否安装成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python object_detection/builders/model_builder_tf1_test.py</span><br></pre></td></tr></table></figure>

<p>注意这里也是要和你自己的tensorflow版本对上。</p>
<p>测试通过则说明安装无误。</p>
<p><img data-src="/../images/Ubuntu20-04%E4%B8%8B%E6%88%90%E5%8A%9F%E9%85%8D%E7%BD%AETensorFlow-Object-Detection-API-%E6%95%99%E7%A8%8B/Screenshot%20from%202020-08-31%2018-03-06-1598871325137.png" alt="配置4"></p>
]]></content>
      <categories>
        <category>Ubuntu下TensorFlow Object Detection API实战</category>
      </categories>
      <tags>
        <tag>TensorFlow Object Detection API</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下为AppImage应用添加图标并添加到应用</title>
    <url>/post/3c4ff36.html</url>
    <content><![CDATA[<h3 id="1-准备好图标文件"><a href="#1-准备好图标文件" class="headerlink" title="1. 准备好图标文件"></a>1. 准备好图标文件</h3><p>这里建议下载的时候搜索xx图标或者xx icon进行下载，这样之后生成的图标能美观点</p>
<h3 id="2-创建xx-desktop"><a href="#2-创建xx-desktop" class="headerlink" title="2. 创建xx.desktop"></a>2. 创建xx.desktop</h3><p>在任意位置新建一个名为xx.desktop的文件，并写入如下内容：</p>
<a id="more"></a>

<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line">[<span class="string">Desktop</span> <span class="string">Entry</span>]</span><br><span class="line"><span class="string">Name=DiffChecker</span></span><br><span class="line"><span class="string">Exec=/home/xxx/Downloads/Diffchecker-3.7.2.AppImage</span></span><br><span class="line"><span class="string">Icon=/home/xxx/Downloads/Diffchecker.png</span></span><br><span class="line"><span class="string">Type=Application</span></span><br><span class="line"><span class="string">StartupNotify=true</span></span><br></pre></td></tr></table></figure>

<p>Name：快捷方式的名称<br>Exec：AppImage所在的文件路径<br>icon：要为其添加的图标的文件路径</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-23-27.png" alt="新建desktop文件"></p>
<p>保存xx.desktop后右键属性,在权限目录下允许作为程序执行文件上打钩。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-51-52.png" alt="添加应用权限"></p>
<h3 id="3-添加到应用"><a href="#3-添加到应用" class="headerlink" title="3. 添加到应用"></a>3. 添加到应用</h3><p>打开终端，输入sudo nautilus</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo nautilus</span><br></pre></td></tr></table></figure>

<p>然后在弹出的文件窗口定位到/usr/share/applications，再将xx.desktop复制过来</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-17-49.png" alt="添加到系统应用"></p>
<p>关闭终端</p>
<h3 id="4-添加到快捷应用栏"><a href="#4-添加到快捷应用栏" class="headerlink" title="4. 添加到快捷应用栏"></a>4. 添加到快捷应用栏</h3><p>现在在应用列表里就可以看到已经更换好图标的应用了，选中然后右键选择添加到常用，最后在快捷应用栏就可以看到我们的应用啦，验证以下使用也正常无误。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-25-30.png" alt="查看应用列表"><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-25-52.png" alt="添加到最常应用"><img data-src="../images/Ubuntu%E4%B8%8B%E4%B8%BAAppImage%E5%BA%94%E7%94%A8%E6%B7%BB%E5%8A%A0%E5%9B%BE%E6%A0%87%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%BA%94%E7%94%A8/Screenshot%20from%202020-09-03%2015-26-08.png" alt="验证无误"></p>
]]></content>
      <categories>
        <category>教你玩转Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下利用TensorFlow Object Detection API测试训练的模型</title>
    <url>/post/e88b7107.html</url>
    <content><![CDATA[<p>经过之前的训练后，会在workspace/training_demo/models/my_ssd_inception_v2保存最终生成的模型文件。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-34-14.png" alt="训练得到的模型列表"></p>
<p>准备好你要测试的图像文件，接下来我们开始测试。</p>
<a id="more"></a>

<h3 id="1-ckpt模型转换pb模型"><a href="#1-ckpt模型转换pb模型" class="headerlink" title="1. ckpt模型转换pb模型"></a>1. ckpt模型转换pb模型</h3><h4 id="1-1-打开终端，激活虚拟环境"><a href="#1-1-打开终端，激活虚拟环境" class="headerlink" title="1.1 打开终端，激活虚拟环境"></a>1.1 打开终端，激活虚拟环境</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> activate python370</span><br></pre></td></tr></table></figure>

<h4 id="1-2-复制TensorFlow-models-research-object-detection-export-inference-graph-py文件到training-demo文件夹"><a href="#1-2-复制TensorFlow-models-research-object-detection-export-inference-graph-py文件到training-demo文件夹" class="headerlink" title="1.2 复制TensorFlow/models/research/object_detection/export_inference_graph.py文件到training_demo文件夹"></a>1.2 复制TensorFlow/models/research/object_detection/export_inference_graph.py文件到training_demo文件夹</h4><p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-43-07.png" alt="导入export_inference_graph.py"></p>
<h4 id="1-3-找出模型文件夹下step最小的ckpt"><a href="#1-3-找出模型文件夹下step最小的ckpt" class="headerlink" title="1.3 找出模型文件夹下step最小的ckpt"></a>1.3 找出模型文件夹下step最小的ckpt</h4><p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-46-00.png" alt="找出最先生成的ckpt"></p>
<h4 id="1-4-在终端cd到training-demo文件夹，运行下面的命令"><a href="#1-4-在终端cd到training-demo文件夹，运行下面的命令" class="headerlink" title="1.4 在终端cd到training_demo文件夹，运行下面的命令"></a>1.4 在终端cd到training_demo文件夹，运行下面的命令</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python export_inference_graph.py --input_type image_tensor --pipeline_config_path models/my_ssd_inception_v2/pipeline.config --trained_checkpoint_prefix models/my_ssd_inception_v2/model.ckpt-194120 --output_directory trained-inference-graphs/output_inference_graph_v1.pb</span><br></pre></td></tr></table></figure>

<p>运行后在生成的trained-inference-graphs/output_inference_graph_v1.pb文件夹下可以看到结果。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/Screenshot%20from%202020-09-02%2015-54-23.png" alt="生成frozen graph"></p>
<h3 id="2-测试pb模型得到结果"><a href="#2-测试pb模型得到结果" class="headerlink" title="2. 测试pb模型得到结果"></a>2. 测试pb模型得到结果</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> six.moves.urllib <span class="keyword">as</span> urllib</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">MODEL_NAME = <span class="string">&#x27;workspace/training_demo/trained-inference-graphs/output_inference_graph_v1.pb&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Path to frozen detection graph. This is the actual model that is used for the object detection.</span></span><br><span class="line">PATH_TO_CKPT = MODEL_NAME + <span class="string">&#x27;/frozen_inference_graph.pb&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List of the strings that is used to add correct label for each box.</span></span><br><span class="line">PATH_TO_LABELS = <span class="string">&#x27;workspace/training_demo/annotations/label_map.pbtxt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of classes to detect</span></span><br><span class="line">NUM_CLASSES = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load a (frozen) Tensorflow model into memory.</span></span><br><span class="line">detection_graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">    od_graph_def = tf.compat.v1.GraphDef()</span><br><span class="line">    <span class="keyword">with</span> tf.io.gfile.GFile(PATH_TO_CKPT, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        serialized_graph = fid.read()</span><br><span class="line">        od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">        tf.import_graph_def(od_graph_def, name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loading label map</span></span><br><span class="line"><span class="comment"># Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine</span></span><br><span class="line">label_map = label_map_util.load_labelmap(PATH_TO_LABELS)</span><br><span class="line">categories = label_map_util.convert_label_map_to_categories(</span><br><span class="line">    label_map, max_num_classes=NUM_CLASSES, use_display_name=<span class="literal">True</span>)</span><br><span class="line">category_index = label_map_util.create_category_index(categories)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;workspace/training_demo/test_data&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Detection</span></span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">    <span class="keyword">with</span> tf.compat.v1.Session(graph=detection_graph) <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(data_dir):</span><br><span class="line">            image_np = np.array(Image.open(os.path.join(data_dir, filename)))</span><br><span class="line">            <span class="comment"># Expand dimensions since the model expects images to have shape: [1, None, None, 3]</span></span><br><span class="line">            image_np_expanded = np.expand_dims(image_np, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># Extract image tensor</span></span><br><span class="line">            image_tensor = detection_graph.get_tensor_by_name(<span class="string">&#x27;image_tensor:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract detection boxes</span></span><br><span class="line">            boxes = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_boxes:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract detection scores</span></span><br><span class="line">            scores = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_scores:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract detection classes</span></span><br><span class="line">            classes = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_classes:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Extract number of detectionsd</span></span><br><span class="line">            num_detections = detection_graph.get_tensor_by_name(</span><br><span class="line">                <span class="string">&#x27;num_detections:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Actual detection.</span></span><br><span class="line">            (boxes, scores, classes, num_detections) = sess.run(</span><br><span class="line">                [boxes, scores, classes, num_detections],</span><br><span class="line">                feed_dict=&#123;image_tensor: image_np_expanded&#125;)</span><br><span class="line">            <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">            vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">                image_np,</span><br><span class="line">                np.squeeze(boxes),</span><br><span class="line">                np.squeeze(classes).astype(np.int32),</span><br><span class="line">                np.squeeze(scores),</span><br><span class="line">                category_index,</span><br><span class="line">                use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">                line_thickness=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Display output</span></span><br><span class="line">            <span class="comment"># cv2.imshow(&#x27;object detection&#x27;, cv2.resize(image_np, (800, 600)))</span></span><br><span class="line">            cv2.imwrite(filename, image_np)</span><br></pre></td></tr></table></figure>

<p>只需要把里面涉及到路径的内容改成你自己的，就可以看到最终的测试结果啦！测试py文件可以<a href="/download/model_infer.py">在此下载</a></p>
<p>最后贴出我的一些测试结果。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/1.bmp" alt="测试结果1"><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E6%B5%8B%E8%AF%95%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B/3.bmp" alt="测试结果2"></p>
]]></content>
      <categories>
        <category>Ubuntu下TensorFlow Object Detection API实战</category>
      </categories>
      <tags>
        <tag>TensorFlow Object Detection API</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/post/4a17b156.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<a id="more"></a>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>小白学搭Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下利用TensorFlow Object Detection API训练自己的数据集</title>
    <url>/post/bb2ec196.html</url>
    <content><![CDATA[<p>如果你是跟着我之前的教程配置过来的，那相信你目前已经有一个名为Tensorflow的文件夹了，且包含的内容具体如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">models/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line">   <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line">   <span class="string">└─</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>接下来我们就直入主题开始训练步骤。</p>
<a id="more"></a>

<h3 id="1-在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training-demo文件夹"><a href="#1-在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training-demo文件夹" class="headerlink" title="1. 在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training_demo文件夹"></a>1. 在Tensorflow文件夹下新建workspace的文件夹，在workspace下再新建training_demo文件夹</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">...</span></span><br><span class="line"><span class="string">└─</span> <span class="string">workspace/</span></span><br><span class="line">   <span class="string">└─</span> <span class="string">training_demo/</span></span><br></pre></td></tr></table></figure>

<p>对于training_demo文件夹，主要存放数据集，训练输出的模型以及预训练模型。最终的具体形式如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">training_demo/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">annotations/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">exported-models/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">images/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">test/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">train/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">pre-trained-models/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">README.md</span></span><br></pre></td></tr></table></figure>

<h3 id="2-准备数据集"><a href="#2-准备数据集" class="headerlink" title="2. 准备数据集"></a>2. 准备数据集</h3><p>这里需要说明的是，如果你现在还没有标注或者准备好要训练的数据集，那么建议你只需要新建除test以及train之外的相应位置的文件夹，把你需要标注的所有图像放在images下，然后用诸如labelImg的工具完成标注工作，将最终的xml注释文件全部置于annotations文件夹下。至于labelImg的具体使用方法可以自行搜索，非常简单。</p>
<p>接下来比较重要的一步是进行训练与测试的划分，即将数据集按照一定比例划分为训练集与测试集，通常的比例是9：1。如果你的数据集只有一类目标，那么可以直接用下面的代码自动生成test与train文件夹。 <a href="/download/partition_dataset.py">点击下载代码</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; usage: partition_dataset.py [-h] [-i IMAGEDIR] [-o OUTPUTDIR] [-r RATIO] [-x]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Partition dataset of images into training and testing sets</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help            show this help message and exit</span></span><br><span class="line"><span class="string">  -i IMAGEDIR, --imageDir IMAGEDIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the image dataset is stored. If not specified, the CWD will be used.</span></span><br><span class="line"><span class="string">  -o OUTPUTDIR, --outputDir OUTPUTDIR</span></span><br><span class="line"><span class="string">                        Path to the output folder where the train and test dirs should be created. Defaults to the same directory as IMAGEDIR.</span></span><br><span class="line"><span class="string">  -r RATIO, --ratio RATIO</span></span><br><span class="line"><span class="string">                        The ratio of the number of test images over the total number of images. The default is 0.1.</span></span><br><span class="line"><span class="string">  -x, --xml             Set this flag if you want the xml annotation files to be processed and copied over.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copyfile</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iterate_dir</span>(<span class="params">source, dest, ratio, copy_xml</span>):</span></span><br><span class="line">    source = source.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    dest = dest.replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>)</span><br><span class="line">    train_dir = os.path.join(dest, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    test_dir = os.path.join(dest, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(train_dir):</span><br><span class="line">        os.makedirs(train_dir)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(test_dir):</span><br><span class="line">        os.makedirs(test_dir)</span><br><span class="line"></span><br><span class="line">    images = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(source)</span><br><span class="line">              <span class="keyword">if</span> re.search(<span class="string">r&#x27;([a-zA-Z0-9\s_\\.\-\(\):])+(.jpg|.jpeg|.png)$&#x27;</span>, f)]</span><br><span class="line"></span><br><span class="line">    num_images = len(images)</span><br><span class="line">    num_test_images = math.ceil(ratio*num_images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_test_images):</span><br><span class="line">        idx = random.randint(<span class="number">0</span>, len(images)<span class="number">-1</span>)</span><br><span class="line">        filename = images[idx]</span><br><span class="line">        copyfile(os.path.join(source, filename),</span><br><span class="line">                 os.path.join(test_dir, filename))</span><br><span class="line">        <span class="keyword">if</span> copy_xml:</span><br><span class="line">            xml_filename = os.path.splitext(filename)[<span class="number">0</span>]+<span class="string">&#x27;.xml&#x27;</span></span><br><span class="line">            copyfile(os.path.join(source, xml_filename),</span><br><span class="line">                     os.path.join(test_dir,xml_filename))</span><br><span class="line">        images.remove(images[idx])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> images:</span><br><span class="line">        copyfile(os.path.join(source, filename),</span><br><span class="line">                 os.path.join(train_dir, filename))</span><br><span class="line">        <span class="keyword">if</span> copy_xml:</span><br><span class="line">            xml_filename = os.path.splitext(filename)[<span class="number">0</span>]+<span class="string">&#x27;.xml&#x27;</span></span><br><span class="line">            copyfile(os.path.join(source, xml_filename),</span><br><span class="line">                     os.path.join(train_dir, xml_filename))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initiate argument parser</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&quot;Partition dataset of images into training and testing sets&quot;</span>,</span><br><span class="line">                                     formatter_class=argparse.RawTextHelpFormatter)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-i&#x27;</span>, <span class="string">&#x27;--imageDir&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;Path to the folder where the image dataset is stored. If not specified, the CWD will be used.&#x27;</span>,</span><br><span class="line">        type=str,</span><br><span class="line">        default=os.getcwd()</span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;--outputDir&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;Path to the output folder where the train and test dirs should be created. &#x27;</span></span><br><span class="line">             <span class="string">&#x27;Defaults to the same directory as IMAGEDIR.&#x27;</span>,</span><br><span class="line">        type=str,</span><br><span class="line">        default=<span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-r&#x27;</span>, <span class="string">&#x27;--ratio&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;The ratio of the number of test images over the total number of images. The default is 0.1.&#x27;</span>,</span><br><span class="line">        default=<span class="number">0.1</span>,</span><br><span class="line">        type=float)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;-x&#x27;</span>, <span class="string">&#x27;--xml&#x27;</span>,</span><br><span class="line">        help=<span class="string">&#x27;Set this flag if you want the xml annotation files to be processed and copied over.&#x27;</span>,</span><br><span class="line">        action=<span class="string">&#x27;store_true&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.outputDir <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        args.outputDir = args.imageDir</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Now we are ready to start the iteration</span></span><br><span class="line">    iterate_dir(args.imageDir, args.outputDir, args.ratio, args.xml)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>这里建议在TensorFlow主文件夹下新建scripts/preprocessing文件夹，用来存放这些自动化的py文件。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">TensorFlow/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">community/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">official/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">orbit/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">├─</span> <span class="string">research/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">...</span></span><br><span class="line"><span class="string">├─</span> <span class="string">scripts/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">preprocessing/</span></span><br><span class="line"><span class="string">└─</span> <span class="string">workspace/</span></span><br><span class="line">   <span class="string">└─</span> <span class="string">training_demo/</span></span><br></pre></td></tr></table></figure>

<p>运行的时候只要在TensorFlow/scripts/preprocessing文件夹下运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python partition_dataset.py -x -i [PATH_TO_IMAGES_FOLDER] -r 0.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># For example</span></span><br><span class="line"><span class="comment"># python partition_dataset.py -x -i C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images -r 0.1</span></span><br></pre></td></tr></table></figure>

<p>就会在training_demo/images下新建training_demo/images/train和training_demo/images/test这两个文件夹，并且在train和test下可以看到既有图像文件又有xml注释文件，并且train与test文件数目比为9：1.</p>
<blockquote>
<p><strong>这里提醒一点：当你的数据集是包含两种及以上类别的目标时，建议不要直接这么操作，原因是样本可能会不被均匀非配，这样造成的后果就是你在之后训练的时候可能出现训练集主要是A目标，而测试集主要是B目标，所以可想而知，模型的效果会有多差，所以在这种情况下建议以样本均衡为原则进行分配，保证训练集与测试集的统一与均衡。</strong></p>
</blockquote>
<h3 id="3-创建-Label-Map"><a href="#3-创建-Label-Map" class="headerlink" title="3. 创建 Label Map"></a>3. 创建 Label Map</h3><p>在training_demo/annotations下新建label_map.pbtxt文件，内容为：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;dirty&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">2</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;oil&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;pit&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">4</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;scratch&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">item</span> &#123;</span><br><span class="line">    <span class="attr">id:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&#x27;wire_drawing&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-生成TensorFlow-Records文件"><a href="#4-生成TensorFlow-Records文件" class="headerlink" title="4. 生成TensorFlow Records文件"></a>4. 生成TensorFlow Records文件</h3><p>之前生成的training_demo/images/train与training_demo/images/test文件夹下的xml可通过以下代码转换成record文件<a href="download/generate_tfrecord.py">点击下载转换代码</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Sample TensorFlow XML-to-TFRecord converter</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">optional arguments:</span></span><br><span class="line"><span class="string">  -h, --help            show this help message and exit</span></span><br><span class="line"><span class="string">  -x XML_DIR, --xml_dir XML_DIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the input .xml files are stored.</span></span><br><span class="line"><span class="string">  -l LABELS_PATH, --labels_path LABELS_PATH</span></span><br><span class="line"><span class="string">                        Path to the labels (.pbtxt) file.</span></span><br><span class="line"><span class="string">  -o OUTPUT_PATH, --output_path OUTPUT_PATH</span></span><br><span class="line"><span class="string">                        Path of output TFRecord (.record) file.</span></span><br><span class="line"><span class="string">  -i IMAGE_DIR, --image_dir IMAGE_DIR</span></span><br><span class="line"><span class="string">                        Path to the folder where the input image files are stored. Defaults to the same directory as XML_DIR.</span></span><br><span class="line"><span class="string">  -c CSV_PATH, --csv_path CSV_PATH</span></span><br><span class="line"><span class="string">                        Path of output .csv file. If none provided, then no file will be written.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span>    <span class="comment"># Suppress TensorFlow logging (1)</span></span><br><span class="line"><span class="keyword">import</span> tensorflow.compat.v1 <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> dataset_util, label_map_util</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initiate argument parser</span></span><br><span class="line">parser = argparse.ArgumentParser(</span><br><span class="line">    description=<span class="string">&quot;Sample TensorFlow XML-to-TFRecord converter&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-x&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--xml_dir&quot;</span>,</span><br><span class="line">                    help=<span class="string">&quot;Path to the folder where the input .xml files are stored.&quot;</span>,</span><br><span class="line">                    type=str)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-l&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--labels_path&quot;</span>,</span><br><span class="line">                    help=<span class="string">&quot;Path to the labels (.pbtxt) file.&quot;</span>, type=str)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-o&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--output_path&quot;</span>,</span><br><span class="line">                    help=<span class="string">&quot;Path of output TFRecord (.record) file.&quot;</span>, type=str)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-i&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--image_dir&quot;</span>,</span><br><span class="line">                    help=<span class="string">&quot;Path to the folder where the input image files are stored. &quot;</span></span><br><span class="line">                         <span class="string">&quot;Defaults to the same directory as XML_DIR.&quot;</span>,</span><br><span class="line">                    type=str, default=<span class="literal">None</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;-c&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;--csv_path&quot;</span>,</span><br><span class="line">                    help=<span class="string">&quot;Path of output .csv file. If none provided, then no file will be &quot;</span></span><br><span class="line">                         <span class="string">&quot;written.&quot;</span>,</span><br><span class="line">                    type=str, default=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.image_dir <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    args.image_dir = args.xml_dir</span><br><span class="line"></span><br><span class="line">label_map = label_map_util.load_labelmap(args.labels_path)</span><br><span class="line">label_map_dict = label_map_util.get_label_map_dict(label_map)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml_to_csv</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Iterates through all .xml files (generated by labelImg) in a given directory and combines</span></span><br><span class="line"><span class="string">    them in a single Pandas dataframe.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    path : str</span></span><br><span class="line"><span class="string">        The path containing the .xml files</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    Pandas DataFrame</span></span><br><span class="line"><span class="string">        The produced dataframe</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">&#x27;/*.xml&#x27;</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">            value = (root.find(<span class="string">&#x27;filename&#x27;</span>).text,</span><br><span class="line">                     int(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">0</span>].text),</span><br><span class="line">                     int(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">1</span>].text),</span><br><span class="line">                     member[<span class="number">0</span>].text,</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;width&#x27;</span>, <span class="string">&#x27;height&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;xmin&#x27;</span>, <span class="string">&#x27;ymin&#x27;</span>, <span class="string">&#x27;xmax&#x27;</span>, <span class="string">&#x27;ymax&#x27;</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">class_text_to_int</span>(<span class="params">row_label</span>):</span></span><br><span class="line">    <span class="keyword">return</span> label_map_dict[row_label]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split</span>(<span class="params">df, group</span>):</span></span><br><span class="line">    data = namedtuple(<span class="string">&#x27;data&#x27;</span>, [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;object&#x27;</span>])</span><br><span class="line">    gb = df.groupby(group)</span><br><span class="line">    <span class="keyword">return</span> [data(filename, gb.get_group(x)) <span class="keyword">for</span> filename, x <span class="keyword">in</span> zip(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tf_example</span>(<span class="params">group, path</span>):</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(os.path.join(path, <span class="string">&#x27;&#123;&#125;&#x27;</span>.format(group.filename)), <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        encoded_jpg = fid.read()</span><br><span class="line">    encoded_jpg_io = io.BytesIO(encoded_jpg)</span><br><span class="line">    image = Image.open(encoded_jpg_io)</span><br><span class="line">    width, height = image.size</span><br><span class="line"></span><br><span class="line">    filename = group.filename.encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">    image_format = <span class="string">b&#x27;jpg&#x27;</span></span><br><span class="line">    xmins = []</span><br><span class="line">    xmaxs = []</span><br><span class="line">    ymins = []</span><br><span class="line">    ymaxs = []</span><br><span class="line">    classes_text = []</span><br><span class="line">    classes = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> group.object.iterrows():</span><br><span class="line">        xmins.append(row[<span class="string">&#x27;xmin&#x27;</span>] / width)</span><br><span class="line">        xmaxs.append(row[<span class="string">&#x27;xmax&#x27;</span>] / width)</span><br><span class="line">        ymins.append(row[<span class="string">&#x27;ymin&#x27;</span>] / height)</span><br><span class="line">        ymaxs.append(row[<span class="string">&#x27;ymax&#x27;</span>] / height)</span><br><span class="line">        classes_text.append(row[<span class="string">&#x27;class&#x27;</span>].encode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        classes.append(class_text_to_int(row[<span class="string">&#x27;class&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        <span class="string">&#x27;image/height&#x27;</span>: dataset_util.int64_feature(height),</span><br><span class="line">        <span class="string">&#x27;image/width&#x27;</span>: dataset_util.int64_feature(width),</span><br><span class="line">        <span class="string">&#x27;image/filename&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/source_id&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/encoded&#x27;</span>: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        <span class="string">&#x27;image/format&#x27;</span>: dataset_util.bytes_feature(image_format),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmin&#x27;</span>: dataset_util.float_list_feature(xmins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmax&#x27;</span>: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymin&#x27;</span>: dataset_util.float_list_feature(ymins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymax&#x27;</span>: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/class/text&#x27;</span>: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        <span class="string">&#x27;image/object/class/label&#x27;</span>: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    <span class="keyword">return</span> tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">_</span>):</span></span><br><span class="line"></span><br><span class="line">    writer = tf.python_io.TFRecordWriter(args.output_path)</span><br><span class="line">    path = os.path.join(args.image_dir)</span><br><span class="line">    examples = xml_to_csv(args.xml_dir)</span><br><span class="line">    grouped = split(examples, <span class="string">&#x27;filename&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> grouped:</span><br><span class="line">        tf_example = create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.SerializeToString())</span><br><span class="line">    writer.close()</span><br><span class="line">    print(<span class="string">&#x27;Successfully created the TFRecord file: &#123;&#125;&#x27;</span>.format(args.output_path))</span><br><span class="line">    <span class="keyword">if</span> args.csv_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        examples.to_csv(args.csv_path, index=<span class="literal">None</span>)</span><br><span class="line">        print(<span class="string">&#x27;Successfully created the CSV file: &#123;&#125;&#x27;</span>.format(args.csv_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>

<p>具体使用方法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create train data:</span></span><br><span class="line">python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create test data:</span></span><br><span class="line">python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/<span class="built_in">test</span> -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/test.record</span><br><span class="line"></span><br><span class="line"><span class="comment"># For example</span></span><br><span class="line"><span class="comment"># python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/train -l C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/train.record</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/test -l C:/Users/sglvladi/Documents/Tensorflow2/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/test.record</span></span><br></pre></td></tr></table></figure>

<p>之后会在training_demo/annotations文件夹下生成test.record 和 train.record 即为转换成功。</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-05-28.png" alt="生成record"></p>
<h3 id="5-下载预训练模型"><a href="#5-下载预训练模型" class="headerlink" title="5. 下载预训练模型"></a>5. 下载预训练模型</h3><p>这里我以ssd_inception_v2为例。</p>
<blockquote>
<p><strong>下载预训练模型这里需要注意一点：tf版本。<br>如果你是tf1.x<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md">就进入进行下载</a>。<br>如果你是tf2.x<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">就进入进行下载</a>。</strong></p>
</blockquote>
<p>将下载好的模型解压到pre-trained-models下。形式如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">training_demo/</span></span><br><span class="line"><span class="string">├─</span> <span class="string">...</span></span><br><span class="line"><span class="string">├─</span> <span class="string">pre-trained-models/</span></span><br><span class="line"><span class="string">│</span>  <span class="string">└─</span> <span class="string">ssd_inception_v2_coco_2018_01_28/</span></span><br><span class="line"><span class="string">│</span>     <span class="string">├─</span> <span class="string">saved_model/</span></span><br><span class="line"><span class="string">│</span>       <span class="string">├─</span> <span class="string">pipeline.config</span></span><br><span class="line"><span class="string">│</span>     <span class="string">└─</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h3 id="6-设置训练Pipeline"><a href="#6-设置训练Pipeline" class="headerlink" title="6. 设置训练Pipeline"></a>6. 设置训练Pipeline</h3><p>首先在training_demo/models下创建文件夹my_ssd_inception_v2;</p>
<p>然后复制training_demo/pre-trained-models/ssd_inception_v2_coco_2018_01_28/pipeline.config到training_demo/models/my_ssd_inception_v2；</p>
<p>接着打开training_demo/models/my_ssd_inception_v2下的pipeline.config；</p>
<figure class="highlight diff"><figcaption><span>/home/xxx/TensorFlow/workspace/training_demo/models/my_ssd_inception_v2/pipeline.config</span></figcaption><table><tr><td class="code"><pre><span class="line">model &#123;</span><br><span class="line">  ssd &#123;</span><br><span class="line">    +num_classes: 5</span><br><span class="line">    image_resizer &#123;</span><br><span class="line">      fixed_shape_resizer &#123;</span><br><span class="line">        height: 300</span><br><span class="line">        width: 300</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    feature_extractor &#123;</span><br><span class="line">      type: &quot;ssd_inception_v2&quot;</span><br><span class="line">      depth_multiplier: 1.0</span><br><span class="line">      min_depth: 16</span><br><span class="line">      conv_hyperparams &#123;</span><br><span class="line">        regularizer &#123;</span><br><span class="line">          l2_regularizer &#123;</span><br><span class="line">            weight: 3.99999989895e-05</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        initializer &#123;</span><br><span class="line">          truncated_normal_initializer &#123;</span><br><span class="line">            mean: 0.0</span><br><span class="line">            stddev: 0.0299999993294</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        activation: RELU_6</span><br><span class="line">        batch_norm &#123;</span><br><span class="line">          decay: 0.999700009823</span><br><span class="line">          center: true</span><br><span class="line">          scale: true</span><br><span class="line">          epsilon: 0.0010000000475</span><br><span class="line">          train: true</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      +override_base_feature_extractor_hyperparams: true</span><br><span class="line">    &#125;</span><br><span class="line">    box_coder &#123;</span><br><span class="line">      faster_rcnn_box_coder &#123;</span><br><span class="line">        y_scale: 10.0</span><br><span class="line">        x_scale: 10.0</span><br><span class="line">        height_scale: 5.0</span><br><span class="line">        width_scale: 5.0</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    matcher &#123;</span><br><span class="line">      argmax_matcher &#123;</span><br><span class="line">        matched_threshold: 0.5</span><br><span class="line">        unmatched_threshold: 0.5</span><br><span class="line">        ignore_thresholds: false</span><br><span class="line">        negatives_lower_than_unmatched: true</span><br><span class="line">        force_match_for_each_row: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    similarity_calculator &#123;</span><br><span class="line">      iou_similarity &#123;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    box_predictor &#123;</span><br><span class="line">      convolutional_box_predictor &#123;</span><br><span class="line">        conv_hyperparams &#123;</span><br><span class="line">          regularizer &#123;</span><br><span class="line">            l2_regularizer &#123;</span><br><span class="line">              weight: 3.99999989895e-05</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          initializer &#123;</span><br><span class="line">            truncated_normal_initializer &#123;</span><br><span class="line">              mean: 0.0</span><br><span class="line">              stddev: 0.0299999993294</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          activation: RELU_6</span><br><span class="line">        &#125;</span><br><span class="line">        min_depth: 0</span><br><span class="line">        max_depth: 0</span><br><span class="line">        num_layers_before_predictor: 0</span><br><span class="line">        use_dropout: false</span><br><span class="line">        dropout_keep_probability: 0.800000011921</span><br><span class="line">        kernel_size: 3</span><br><span class="line">        box_code_size: 4</span><br><span class="line">        apply_sigmoid_to_scores: false</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    anchor_generator &#123;</span><br><span class="line">      ssd_anchor_generator &#123;</span><br><span class="line">        num_layers: 6</span><br><span class="line">        min_scale: 0.20000000298</span><br><span class="line">        max_scale: 0.949999988079</span><br><span class="line">        aspect_ratios: 1.0</span><br><span class="line">        aspect_ratios: 2.0</span><br><span class="line">        aspect_ratios: 0.5</span><br><span class="line">        aspect_ratios: 3.0</span><br><span class="line">        aspect_ratios: 0.333299994469</span><br><span class="line">        reduce_boxes_in_lowest_layer: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    post_processing &#123;</span><br><span class="line">      batch_non_max_suppression &#123;</span><br><span class="line">        score_threshold: 0.300000011921</span><br><span class="line">        iou_threshold: 0.600000023842</span><br><span class="line">        max_detections_per_class: 100</span><br><span class="line">        max_total_detections: 100</span><br><span class="line">      &#125;</span><br><span class="line">      score_converter: SIGMOID</span><br><span class="line">    &#125;</span><br><span class="line">    normalize_loss_by_num_matches: true</span><br><span class="line">    loss &#123;</span><br><span class="line">      localization_loss &#123;</span><br><span class="line">        weighted_smooth_l1 &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      classification_loss &#123;</span><br><span class="line">        weighted_sigmoid &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      hard_example_miner &#123;</span><br><span class="line">        num_hard_examples: 3000</span><br><span class="line">        iou_threshold: 0.990000009537</span><br><span class="line">        loss_type: CLASSIFICATION</span><br><span class="line">        max_negatives_per_positive: 3</span><br><span class="line">        min_negatives_per_image: 0</span><br><span class="line">      &#125;</span><br><span class="line">      classification_weight: 1.0</span><br><span class="line">      localization_weight: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">train_config &#123;</span><br><span class="line">  +batch_size: 24</span><br><span class="line">  data_augmentation_options &#123;</span><br><span class="line">    random_horizontal_flip &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  data_augmentation_options &#123;</span><br><span class="line">    ssd_random_crop &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  optimizer &#123;</span><br><span class="line">    rms_prop_optimizer &#123;</span><br><span class="line">      learning_rate &#123;</span><br><span class="line">        exponential_decay_learning_rate &#123;</span><br><span class="line">          initial_learning_rate: 0.00400000018999</span><br><span class="line">          decay_steps: 800720</span><br><span class="line">          decay_factor: 0.949999988079</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      momentum_optimizer_value: 0.899999976158</span><br><span class="line">      decay: 0.899999976158</span><br><span class="line">      epsilon: 1.0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  +fine_tune_checkpoint: &quot;pre-trained-models/ssd_inception_v2_coco_2018_01_28/model.ckpt&quot;</span><br><span class="line">  from_detection_checkpoint: true</span><br><span class="line">  +num_steps: 200000</span><br><span class="line">&#125;</span><br><span class="line">train_input_reader &#123;</span><br><span class="line">  +label_map_path: &quot;annotations/label_map.pbtxt&quot;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    +input_path: &quot;annotations/train.record&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">eval_config &#123;</span><br><span class="line">  num_examples: 8000</span><br><span class="line">  max_evals: 10</span><br><span class="line">  use_moving_averages: false</span><br><span class="line">&#125;</span><br><span class="line">eval_input_reader &#123;</span><br><span class="line">  +label_map_path: &quot;annotations/label_map.pbtxt&quot;</span><br><span class="line">  shuffle: false</span><br><span class="line">  num_readers: 1</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    +input_path: &quot;annotations/test.record&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="7-开始训练"><a href="#7-开始训练" class="headerlink" title="7. 开始训练"></a>7. 开始训练</h3><blockquote>
<p><strong>tf1.x版本的复制TensorFlow/models/research/object_detection/model_main.py到training_demo文件夹<br>tf2.x版本的复制TensorFlow/models/research/object_detection/model_main_tf2.py到training_demo文件夹</strong></p>
</blockquote>
<p>定位到training_demo文件夹，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python model_main.py --model_dir=models/my_ssd_inception_v2 --pipeline_config_path=models/my_ssd_inception_v2/pipeline.config</span><br></pre></td></tr></table></figure>

<p>如果遇到如下error,则是忘了加上override_base_feature_extractor_hyperparams: true    #####这个位置加上这句#####</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-05-36.png" alt="开始训练"></p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-05-59.png" alt="错误1"><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-08-31%2016-09-45.png" alt="解决办法"></p>
<p>训练成功则如下：</p>
<p><img data-src="../images/Ubuntu%E4%B8%8B%E5%88%A9%E7%94%A8TensorFlow-Object-Detection-API%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/Screenshot%20from%202020-09-01%2014-19-16.png" alt="训练正常"></p>
]]></content>
      <categories>
        <category>Ubuntu下TensorFlow Object Detection API实战</category>
      </categories>
      <tags>
        <tag>TensorFlow Object Detection API</tag>
      </tags>
  </entry>
</search>
